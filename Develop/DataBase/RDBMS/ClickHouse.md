---
title: ClickHouse - ê³ ì„±ëŠ¥ ì»¬ëŸ¼í˜• ë¶„ì„ ë°ì´í„°ë² ì´ìŠ¤
tags: [database, rdbms, clickhouse, olap, analytics, columnar-database, sql]
updated: 2025-11-01
---

# ClickHouse

## ğŸ“‹ ëª©ì°¨

1. [ClickHouseë€ ë¬´ì—‡ì¸ê°€?](#clickhouseë€-ë¬´ì—‡ì¸ê°€)
2. [í•µì‹¬ ì•„í‚¤í…ì²˜](#í•µì‹¬-ì•„í‚¤í…ì²˜)
3. [ì»¬ëŸ¼í˜• ìŠ¤í† ë¦¬ì§€ì˜ ì›ë¦¬](#ì»¬ëŸ¼í˜•-ìŠ¤í† ë¦¬ì§€ì˜-ì›ë¦¬)
4. [í…Œì´ë¸” ì—”ì§„](#í…Œì´ë¸”-ì—”ì§„)
5. [ë°ì´í„° íƒ€ì…ê³¼ í•¨ìˆ˜](#ë°ì´í„°-íƒ€ì…ê³¼-í•¨ìˆ˜)
6. [ì¿¼ë¦¬ ìµœì í™”](#ì¿¼ë¦¬-ìµœì í™”)
7. [ë¶„ì‚° ì²˜ë¦¬ì™€ ë³µì œ](#ë¶„ì‚°-ì²˜ë¦¬ì™€-ë³µì œ)
8. [ì‹¤ë¬´ í™œìš© ì‚¬ë¡€](#ì‹¤ë¬´-í™œìš©-ì‚¬ë¡€)
9. [ì„±ëŠ¥ íŠœë‹ ì „ëµ](#ì„±ëŠ¥-íŠœë‹-ì „ëµ)
10. [ìš´ì˜ ë° ëª¨ë‹ˆí„°ë§](#ìš´ì˜-ë°-ëª¨ë‹ˆí„°ë§)
11. [ì°¸ê³  ìë£Œ](#ì°¸ê³ -ìë£Œ)

---

## ClickHouseë€ ë¬´ì—‡ì¸ê°€?

ClickHouseëŠ” **ì´ˆê³ ì† OLAP(Online Analytical Processing) ë¶„ì„ì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ ì»¬ëŸ¼í˜•(Columnar) ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤**ì…ë‹ˆë‹¤. SQLì„ ì‚¬ìš©í•˜ë©°, ìˆ˜ì‹­ì–µ ê±´ì˜ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì§‘ê³„í•˜ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „í†µì ì¸ OLTP RDBMSë³´ë‹¤ 100~1000ë°° ë¹ ë¥¸ ì¿¼ë¦¬ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

### ClickHouseì˜ ë¶„ë¥˜

**ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ (RDBMS)**
- SQL ì¿¼ë¦¬ ì–¸ì–´ ì‚¬ìš©
- í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ
- JOIN, GROUP BY ë“± ê´€ê³„í˜• ì—°ì‚° ì§€ì›
- ACID íŠ¹ì„± ë¶€ë¶„ ì§€ì›

**í•˜ì§€ë§Œ ì „í†µì  OLTP RDBMSì™€ëŠ” ë‹¤ë¥¸ íŠ¹ì§•:**
- ì»¬ëŸ¼í˜• ìŠ¤í† ë¦¬ì§€ (í–‰í˜•ì´ ì•„ë‹Œ)
- OLAPì— ìµœì í™” (OLTPê°€ ì•„ë‹Œ)
- ë°°ì¹˜ ì‚½ì… ê¶Œì¥ (ê°œë³„ íŠ¸ëœì­ì…˜ ë¹„íš¨ìœ¨ì )
- UPDATE/DELETE ì œí•œì  (ê¶Œì¥ ì•ˆ í•¨)

### ClickHouseì˜ íƒ„ìƒ ë°°ê²½

**Yandexì˜ ê³¼ì œ**

2016ë…„, ëŸ¬ì‹œì•„ì˜ ê²€ìƒ‰ ì—”ì§„ ê¸°ì—… YandexëŠ” ìì‚¬ì˜ ì›¹ ë¶„ì„ ì„œë¹„ìŠ¤ì¸ **Yandex.Metrica**ë¥¼ ìš´ì˜í•˜ë©´ì„œ ì‹¬ê°í•œ ì„±ëŠ¥ ë¬¸ì œì— ì§ë©´í–ˆìŠµë‹ˆë‹¤:

```
ë¬¸ì œ ìƒí™©:
- ì¼ì¼ 200ì–µ ê±´ ì´ìƒì˜ ì´ë²¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘
- ìˆ˜ì¡° ê±´ì˜ íˆìŠ¤í† ë¦¬ ë°ì´í„° ë¶„ì„ í•„ìš”
- ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ìš”êµ¬ì‚¬í•­ (1ì´ˆ ì´ë‚´ ì‘ë‹µ)
- ê¸°ì¡´ RDBMSëŠ” ìˆ˜ì‹­ ë¶„~ìˆ˜ ì‹œê°„ ì†Œìš”
```

**ê¸°ì¡´ ì†”ë£¨ì…˜ì˜ í•œê³„**

- **MySQL/PostgreSQL**: ëŒ€ê·œëª¨ ì§‘ê³„ ì¿¼ë¦¬ì—ì„œ ì„±ëŠ¥ í•œê³„
- **MongoDB**: ë³µì¡í•œ ë¶„ì„ ì¿¼ë¦¬ ì§€ì› ë¶€ì¡±
- **Hadoop/Hive**: ë°°ì¹˜ ì²˜ë¦¬ì—ëŠ” ì í•©í•˜ë‚˜ ì‹¤ì‹œê°„ ì¿¼ë¦¬ ë¶ˆê°€
- **ìƒìš© ì†”ë£¨ì…˜**: ë†’ì€ ë¼ì´ì„¼ìŠ¤ ë¹„ìš©ê³¼ í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

**ClickHouseì˜ ì„¤ê³„ ëª©í‘œ**

```
1. ì´ˆê³ ì† ì§‘ê³„ ì¿¼ë¦¬ (ìˆ˜ì‹­ì–µ ê±´ì„ 1ì´ˆ ì´ë‚´)
2. ì„ í˜•ì  í™•ì¥ì„± (ì„œë²„ ì¶”ê°€ ì‹œ ì„±ëŠ¥ ë¹„ë¡€ ì¦ê°€)
3. ì‹¤ì‹œê°„ ë°ì´í„° ì‚½ì… (ë°°ì¹˜ ì—†ì´ ì¦‰ì‹œ ì¿¼ë¦¬ ê°€ëŠ¥)
4. SQL í˜¸í™˜ì„± (í•™ìŠµ ê³¡ì„  ìµœì†Œí™”)
5. í•˜ë“œì›¨ì–´ íš¨ìœ¨ì„± (ì¼ë°˜ ì„œë²„ì—ì„œ ë™ì‘)
```

### ClickHouseì˜ í•µì‹¬ ì² í•™

**"ë¹ ë¦„ì„ ìœ„í•œ ëª¨ë“  ê²ƒ"**

ClickHouseì˜ ëª¨ë“  ì„¤ê³„ ê²°ì •ì€ **ì„±ëŠ¥ ìµœìš°ì„ **ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤:

```
ì»¬ëŸ¼í˜• ìŠ¤í† ë¦¬ì§€: ë¶„ì„ ì¿¼ë¦¬ì— ìµœì í™”
ë²¡í„°í™” ì²˜ë¦¬: CPU SIMD ëª…ë ¹ì–´ í™œìš©
ë°ì´í„° ì••ì¶•: I/O ìµœì†Œí™”
ë³‘ë ¬ ì²˜ë¦¬: ëª¨ë“  CPU ì½”ì–´ í™œìš©
ë¶„ì‚° ì²˜ë¦¬: ìˆ˜ë°± ëŒ€ ì„œë²„ë¡œ í™•ì¥
```

### ClickHouse vs ì „í†µì  OLTP RDBMS

ClickHouseëŠ” **OLAPì— íŠ¹í™”ëœ ì»¬ëŸ¼í˜• RDBMS**ì´ê³ , MySQL/PostgreSQLì€ **OLTPì— íŠ¹í™”ëœ í–‰í˜• RDBMS**ì…ë‹ˆë‹¤.

| íŠ¹ì„± | ClickHouse (OLAP) | MySQL/PostgreSQL (OLTP) |
|------|-------------------|------------------------|
| **ë°ì´í„°ë² ì´ìŠ¤ ìœ í˜•** | ê´€ê³„í˜• (SQL ì‚¬ìš©) | ê´€ê³„í˜• (SQL ì‚¬ìš©) |
| **ì €ì¥ ë°©ì‹** | ì»¬ëŸ¼í˜• (Columnar) | í–‰í˜• (Row-based) |
| **ìµœì í™” ëŒ€ìƒ** | ì½ê¸°/ë¶„ì„ (OLAP) | íŠ¸ëœì­ì…˜ (OLTP) |
| **ì¿¼ë¦¬ ì„±ëŠ¥** | ìˆ˜ì‹­ì–µ ê±´ì„ ì´ˆ ë‹¨ìœ„ | ìˆ˜ë°±ë§Œ ê±´ì´ í•œê³„ |
| **ì“°ê¸° ë°©ì‹** | ë°°ì¹˜ ì‚½ì… ê¶Œì¥ | ê°œë³„ íŠ¸ëœì­ì…˜ ìµœì í™” |
| **UPDATE/DELETE** | ë¹„íš¨ìœ¨ì  (ê¶Œì¥ ì•ˆ í•¨) | íš¨ìœ¨ì  (ACID ë³´ì¥) |
| **JOIN ì„±ëŠ¥** | ì œí•œì  | ìš°ìˆ˜ |
| **ì••ì¶•ë¥ ** | 10:1 ~ 100:1 | 3:1 ~ 5:1 |
| **í™•ì¥ì„±** | ìˆ˜í‰ í™•ì¥ (ì„ í˜•) | ìˆ˜ì§ í™•ì¥ ì£¼ë¡œ |
| **íŠ¸ëœì­ì…˜** | ì œí•œì  | ì™„ì „í•œ ACID |

**í•µì‹¬ ì°¨ì´:**
```
OLTP (MySQL, PostgreSQL):
- ê°œë³„ í–‰ CRUD ìµœì í™”
- íŠ¸ëœì­ì…˜ ë³´ì¥ (ACID)
- ì •ê·œí™”ëœ ìŠ¤í‚¤ë§ˆ
- ì˜ˆ: ì£¼ë¬¸ ì²˜ë¦¬, ì‚¬ìš©ì ê´€ë¦¬

OLAP (ClickHouse):
- ëŒ€ëŸ‰ ì§‘ê³„ ìµœì í™”
- ë¹„ì •ê·œí™”ëœ ìŠ¤í‚¤ë§ˆ
- ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ì‹¬
- ì˜ˆ: ë¡œê·¸ ë¶„ì„, BI ëŒ€ì‹œë³´ë“œ
```

### ì–¸ì œ ClickHouseë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ê°€?

**âœ… ClickHouseê°€ ì í•©í•œ ê²½ìš°**

```
1. ëŒ€ê·œëª¨ ë¡œê·¸ ë¶„ì„
   - ì›¹ ì„œë²„ ë¡œê·¸ (ì¼ ìˆ˜ì–µ ê±´)
   - ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ë²¤íŠ¸ ë¡œê·¸
   - ë³´ì•ˆ ê°ì‚¬ ë¡œê·¸

2. ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
   - ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ (BI)
   - ì‚¬ìš©ì í–‰ë™ ë¶„ì„
   - ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì§‘ê³„

3. ì‹œê³„ì—´ ë°ì´í„°
   - IoT ì„¼ì„œ ë°ì´í„°
   - ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­
   - ê¸ˆìœµ ì‹œê³„ì—´ ë°ì´í„°

4. ëŒ€ê·œëª¨ ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤
   - ìˆ˜ì¡° ê±´ì˜ íˆìŠ¤í† ë¦¬ ë°ì´í„°
   - ë³µì¡í•œ ì§‘ê³„ ì¿¼ë¦¬
   - Ad-hoc ë¶„ì„
```

**âŒ ClickHouseê°€ ë¶€ì í•©í•œ ê²½ìš°**

```
1. íŠ¸ëœì­ì…˜ ì²˜ë¦¬ (OLTP)
   - ì˜¨ë¼ì¸ ë±…í‚¹ ì‹œìŠ¤í…œ
   - ì „ììƒê±°ë˜ ì£¼ë¬¸ ì²˜ë¦¬
   - ë¹ˆë²ˆí•œ UPDATE/DELETE í•„ìš”

2. Key-Value ì¡°íšŒ
   - ë‹¨ì¼ í–‰ ì¡°íšŒê°€ ì£¼
   - ìºì‹±ì´ ë” ì í•©
   - Redis, Memcached ê¶Œì¥

3. ë³µì¡í•œ JOIN
   - ë‹¤ì¤‘ í…Œì´ë¸” ì¡°ì¸ì´ ë§ìŒ
   - ì •ê·œí™”ëœ ìŠ¤í‚¤ë§ˆ
   - ì „í†µì  RDBMS ê¶Œì¥

4. ì†Œê·œëª¨ ë°ì´í„°
   - ë°ì´í„°ê°€ ìˆ˜ë°±ë§Œ ê±´ ì´í•˜
   - ë³µì¡ë„ ëŒ€ë¹„ ì´ì  ì—†ìŒ
   - PostgreSQL ë“±ìœ¼ë¡œ ì¶©ë¶„
```

---

## í•µì‹¬ ì•„í‚¤í…ì²˜

### ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°

ClickHouseëŠ” ë‹¨ìˆœí•˜ë©´ì„œë„ ê°•ë ¥í•œ ì•„í‚¤í…ì²˜ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Client Applications         â”‚
â”‚  (JDBC, ODBC, HTTP, CLI, Python)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Query Parser & Analyzer      â”‚
â”‚     (SQL â†’ AST â†’ Logical Plan)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Query Optimizer              â”‚
â”‚   (Cost-based, Rule-based)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Distributed Execution        â”‚
â”‚  (Parallel Processing, Sharding)    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  Storage   â”‚        â”‚  Storage   â”‚
â”‚  Engine    â”‚        â”‚  Engine    â”‚
â”‚ (MergeTree)â”‚   ...  â”‚ (MergeTree)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Columnar Data Storage          â”‚
â”‚    (Compressed, Partitioned)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë‹¨ì¼ ì„œë²„ ì•„í‚¤í…ì²˜

**í”„ë¡œì„¸ìŠ¤ êµ¬ì¡°:**

```
clickhouse-server (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤)
â”œâ”€ TCP Handler (9000 í¬íŠ¸)
â”‚  â””â”€ ë„¤ì´í‹°ë¸Œ í”„ë¡œí† ì½œ ì²˜ë¦¬
â”œâ”€ HTTP Handler (8123 í¬íŠ¸)
â”‚  â””â”€ REST API, ì›¹ UI
â”œâ”€ Query Processor
â”‚  â”œâ”€ Parser
â”‚  â”œâ”€ Optimizer
â”‚  â””â”€ Executor (ë©€í‹°ìŠ¤ë ˆë“œ)
â”œâ”€ Storage Manager
â”‚  â”œâ”€ Table Engines
â”‚  â””â”€ Parts ê´€ë¦¬
â””â”€ Background Tasks
   â”œâ”€ Merge (ë°ì´í„° ë³‘í•©)
   â”œâ”€ Mutation (ì—…ë°ì´íŠ¸/ì‚­ì œ)
   â””â”€ Replication (ë³µì œ)
```

**ë©”ëª¨ë¦¬ êµ¬ì¡°:**

```
RAM ì‚¬ìš©:
â”œâ”€ Query Memory (ì¿¼ë¦¬ ì‹¤í–‰)
â”‚  â””â”€ max_memory_usage: ì¿¼ë¦¬ë‹¹ ë©”ëª¨ë¦¬ ì œí•œ
â”œâ”€ Mark Cache (ì¸ë±ìŠ¤ ìºì‹œ)
â”‚  â””â”€ ê¸°ë³¸ê°’: 5GB
â”œâ”€ Uncompressed Cache (ë°ì´í„° ìºì‹œ)
â”‚  â””â”€ ê¸°ë³¸ê°’: 0 (ë¹„í™œì„±í™”)
â””â”€ Background Merge Memory
   â””â”€ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìš©
```

### ë°ì´í„° ì €ì¥ êµ¬ì¡°

**ë””ë ‰í† ë¦¬ ë ˆì´ì•„ì›ƒ:**

```
/var/lib/clickhouse/
â”œâ”€ data/
â”‚  â””â”€ database_name/
â”‚     â””â”€ table_name/
â”‚        â”œâ”€ 20240101_1_1_0/  (íŒŒí‹°ì…˜)
â”‚        â”‚  â”œâ”€ primary.idx   (ê¸°ë³¸í‚¤ ì¸ë±ìŠ¤)
â”‚        â”‚  â”œâ”€ column1.bin   (ì••ì¶•ëœ ì»¬ëŸ¼ ë°ì´í„°)
â”‚        â”‚  â”œâ”€ column1.mrk2  (ë§ˆí¬ íŒŒì¼)
â”‚        â”‚  â”œâ”€ column2.bin
â”‚        â”‚  â”œâ”€ column2.mrk2
â”‚        â”‚  â””â”€ checksums.txt (ì²´í¬ì„¬)
â”‚        â”œâ”€ 20240101_2_2_0/
â”‚        â””â”€ 20240102_3_3_0/
â”œâ”€ metadata/
â”‚  â””â”€ database_name.sql
â”‚     â””â”€ table_name.sql
â””â”€ tmp/
   â””â”€ ì„ì‹œ íŒŒì¼
```

**íŒŒí‹°ì…˜ê³¼ íŒŒíŠ¸:**

```
ê°œë… ì´í•´:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Table: web_logs              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Partition: 2024-01-01               â”‚
â”‚  â”œâ”€ Part: 20240101_1_1_0 (100ë§Œ ê±´) â”‚
â”‚  â”œâ”€ Part: 20240101_2_2_0 (100ë§Œ ê±´) â”‚
â”‚  â””â”€ Part: 20240101_3_3_0 (100ë§Œ ê±´) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Partition: 2024-01-02               â”‚
â”‚  â”œâ”€ Part: 20240102_4_4_0 (100ë§Œ ê±´) â”‚
â”‚  â””â”€ Part: 20240102_5_5_0 (100ë§Œ ê±´) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ë°±ê·¸ë¼ìš´ë“œ ë³‘í•©:
20240101_1_1_0 + 20240101_2_2_0
        â†“
20240101_1_2_1 (200ë§Œ ê±´)
```

---

## ì»¬ëŸ¼í˜• ìŠ¤í† ë¦¬ì§€ì˜ ì›ë¦¬

### í–‰í˜• vs ì»¬ëŸ¼í˜• ìŠ¤í† ë¦¬ì§€

**í–‰í˜• ìŠ¤í† ë¦¬ì§€ (Row-based)**

ì „í†µì ì¸ RDBMS ë°©ì‹ì…ë‹ˆë‹¤:

```
ë””ìŠ¤í¬ ì €ì¥:
Row 1: [id=1, name='Alice', age=25, city='Seoul']
Row 2: [id=2, name='Bob', age=30, city='Busan']
Row 3: [id=3, name='Charlie', age=35, city='Seoul']

ì¿¼ë¦¬: SELECT AVG(age) FROM users WHERE city = 'Seoul';

ì½ì–´ì•¼ í•˜ëŠ” ë°ì´í„°:
âœ“ id, name, age, city (ëª¨ë“  ì»¬ëŸ¼)
âœ— ageì™€ cityë§Œ í•„ìš”í•œë° ì „ì²´ ì½ìŒ
```

**ì»¬ëŸ¼í˜• ìŠ¤í† ë¦¬ì§€ (Columnar)**

ClickHouseì˜ ë°©ì‹ì…ë‹ˆë‹¤:

```
ë””ìŠ¤í¬ ì €ì¥:
id    ì»¬ëŸ¼: [1, 2, 3]
name  ì»¬ëŸ¼: ['Alice', 'Bob', 'Charlie']
age   ì»¬ëŸ¼: [25, 30, 35]
city  ì»¬ëŸ¼: ['Seoul', 'Busan', 'Seoul']

ì¿¼ë¦¬: SELECT AVG(age) FROM users WHERE city = 'Seoul';

ì½ì–´ì•¼ í•˜ëŠ” ë°ì´í„°:
âœ“ age ì»¬ëŸ¼ë§Œ
âœ“ city ì»¬ëŸ¼ë§Œ
âœ— id, name ì»¬ëŸ¼ ì½ì§€ ì•ŠìŒ â†’ I/O 50% ì ˆê°
```

### ì»¬ëŸ¼í˜• ìŠ¤í† ë¦¬ì§€ì˜ ì¥ì 

**1. I/O íš¨ìœ¨ì„±**

```
ì˜ˆì‹œ: 100ê°œ ì»¬ëŸ¼ ì¤‘ 5ê°œë§Œ ì¡°íšŒ

í–‰í˜• ìŠ¤í† ë¦¬ì§€:
- 100ê°œ ì»¬ëŸ¼ ëª¨ë‘ ì½ìŒ
- ë””ìŠ¤í¬ I/O: 100GB

ì»¬ëŸ¼í˜• ìŠ¤í† ë¦¬ì§€:
- 5ê°œ ì»¬ëŸ¼ë§Œ ì½ìŒ
- ë””ìŠ¤í¬ I/O: 5GB (95% ì ˆê°)
```

**2. ì••ì¶• íš¨ìœ¨ì„±**

ì»¬ëŸ¼ ë°ì´í„°ëŠ” ê°™ì€ íƒ€ì…ì´ ì—°ì†ë˜ì–´ ë†’ì€ ì••ì¶•ë¥ ì„ ë³´ì…ë‹ˆë‹¤:

```
í–‰í˜• ì••ì¶•:
[1, 'Alice', 25, 'Seoul', 2, 'Bob', 30, 'Busan', ...]
â†’ ì••ì¶•ë¥ : 3:1

ì»¬ëŸ¼í˜• ì••ì¶•:
id:   [1, 2, 3, 4, 5, ...] â†’ Delta ì¸ì½”ë”©
age:  [25, 30, 35, 25, 40, ...] â†’ ê°’ ë²”ìœ„ê°€ ì¢ìŒ
city: ['Seoul', 'Busan', 'Seoul', ...] â†’ Dictionary ì¸ì½”ë”©
â†’ ì••ì¶•ë¥ : 10:1 ~ 100:1
```

**3. CPU ìºì‹œ ì¹œí™”ì„±**

```
ë²¡í„°í™” ì²˜ë¦¬:
SUM(age) FROM users

ì»¬ëŸ¼í˜•:
ages = [25, 30, 35, 25, 40, ...]
â†’ CPU SIMD ëª…ë ¹ì–´ë¡œ í•œ ë²ˆì— ì²˜ë¦¬
â†’ 8ê°œ ê°’ì„ ë™ì‹œì— ë”í•¨

í–‰í˜•:
ê° í–‰ì„ ìˆœíšŒí•˜ë©° age ì¶”ì¶œ
â†’ ìºì‹œ ë¯¸ìŠ¤ ë¹ˆë²ˆ
â†’ í•˜ë‚˜ì”© ì²˜ë¦¬
```

**4. ë³‘ë ¬ ì²˜ë¦¬**

```
ê° ì»¬ëŸ¼ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬:

Thread 1: age ì»¬ëŸ¼ ì§‘ê³„
Thread 2: city ì»¬ëŸ¼ í•„í„°ë§
Thread 3: name ì»¬ëŸ¼ ì •ë ¬
...

â†’ ëª¨ë“  CPU ì½”ì–´ í™œìš©
â†’ ì„ í˜•ì  ì„±ëŠ¥ í–¥ìƒ
```

### ì••ì¶• ì•Œê³ ë¦¬ì¦˜

ClickHouseëŠ” ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ìë™ìœ¼ë¡œ ìµœì ì˜ ì••ì¶• ë°©ì‹ì„ ì„ íƒí•©ë‹ˆë‹¤:

**1. LZ4 (ê¸°ë³¸ê°’)**

```
íŠ¹ì§•:
- ë¹ ë¥¸ ì••ì¶•/í•´ì œ ì†ë„
- ì¤‘ê°„ ìˆ˜ì¤€ ì••ì¶•ë¥  (2:1 ~ 5:1)
- CPU ë¶€í•˜ ë‚®ìŒ

ì í•©í•œ ê²½ìš°:
- ì‹¤ì‹œê°„ ì¿¼ë¦¬ ì„±ëŠ¥ì´ ì¤‘ìš”
- ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸/ìˆ«ì ë°ì´í„°
```

**2. ZSTD**

```
íŠ¹ì§•:
- ë†’ì€ ì••ì¶•ë¥  (5:1 ~ 15:1)
- ì•½ê°„ ëŠë¦° ì†ë„
- ì••ì¶• ë ˆë²¨ ì¡°ì • ê°€ëŠ¥

ì í•©í•œ ê²½ìš°:
- ìŠ¤í† ë¦¬ì§€ ë¹„ìš© ì ˆê°ì´ ì¤‘ìš”
- ì½œë“œ ë°ì´í„° (ìì£¼ ì¡°íšŒ ì•ˆ ë¨)
```

**3. Delta ì¸ì½”ë”©**

```
ì‹œê³„ì—´ ë°ì´í„°ì— íš¨ê³¼ì :

ì›ë³¸: [1000, 1001, 1002, 1003, 1004]
Delta: [1000, +1, +1, +1, +1]
ì••ì¶•ë¥ : 10:1 ì´ìƒ

íƒ€ì„ìŠ¤íƒ¬í”„, ì¦ê°€í•˜ëŠ” IDì— ìµœì 
```

**4. Dictionary ì¸ì½”ë”©**

```
ì¹´ë””ë„ë¦¬í‹°ê°€ ë‚®ì€ ë°ì´í„°:

ì›ë³¸: ['Seoul', 'Seoul', 'Busan', 'Seoul', 'Busan']
Dictionary: {1: 'Seoul', 2: 'Busan'}
Encoded: [1, 1, 2, 1, 2]
ì••ì¶•ë¥ : 20:1 ì´ìƒ

êµ­ê°€, ë„ì‹œ, ìƒíƒœ ì½”ë“œì— ìµœì 
```

---

## í…Œì´ë¸” ì—”ì§„

ClickHouseì˜ ê°€ì¥ ë…íŠ¹í•œ íŠ¹ì§•ì€ **ë‹¤ì–‘í•œ í…Œì´ë¸” ì—”ì§„**ì„ ì œê³µí•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. í…Œì´ë¸” ì—”ì§„ì€ ë°ì´í„°ê°€ ì €ì¥ë˜ê³  ì¡°íšŒë˜ëŠ” ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤.

### MergeTree ê³„ì—´ (í•µì‹¬)

#### 1. MergeTree - ê¸°ë³¸ ì—”ì§„

**íŠ¹ì§•:**
- ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë²”ìš© í…Œì´ë¸” ì—”ì§„
- ìë™ ë°ì´í„° ì •ë ¬ ë° ë³‘í•©
- íŒŒí‹°ì…”ë‹ ì§€ì›
- ê¸°ë³¸í‚¤ ì¸ë±ìŠ¤ ì§€ì›

**ìƒì„± ì˜ˆì‹œ:**

```sql
CREATE TABLE web_logs
(
    event_time DateTime,
    user_id UInt32,
    page_url String,
    country String,
    duration UInt32
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(event_time)
ORDER BY (country, user_id, event_time)
SETTINGS index_granularity = 8192;
```

**íŒŒí‹°ì…”ë‹:**

```
ëª©ì : ì¿¼ë¦¬ ì„±ëŠ¥ í–¥ìƒ ë° ë°ì´í„° ê´€ë¦¬ ìš©ì´

PARTITION BY toYYYYMM(event_time)
â†’ ì›”ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬

ì¥ì :
1. íŠ¹ì • ì›” ë°ì´í„°ë§Œ ì¡°íšŒ ì‹œ ë‹¤ë¥¸ íŒŒí‹°ì…˜ ë¬´ì‹œ
2. ì˜¤ë˜ëœ íŒŒí‹°ì…˜ ì‚­ì œ ìš©ì´ (DROP PARTITION)
3. íŒŒí‹°ì…˜ë³„ ë…ë¦½ì  ë³‘í•© ì‘ì—…
```

**ORDER BY (ì •ë ¬ í‚¤):**

```sql
ORDER BY (country, user_id, event_time)

íš¨ê³¼:
1. ë””ìŠ¤í¬ì— ì •ë ¬ë˜ì–´ ì €ì¥
2. ë²”ìœ„ ìŠ¤ìº” ìµœì í™”
3. ì••ì¶•ë¥  í–¥ìƒ (ê°™ì€ ê°’ë“¤ì´ ì—°ì†)

ì¿¼ë¦¬ ìµœì í™”:
-- âœ… ë¹ ë¦„ (ì •ë ¬ í‚¤ ì‚¬ìš©)
WHERE country = 'KR' AND user_id = 123

-- âš ï¸ ëŠë¦¼ (ì •ë ¬ í‚¤ ë¯¸ì‚¬ìš©)
WHERE duration > 100
```

**ì¸ë±ìŠ¤ Granularity:**

```
index_granularity = 8192 (ê¸°ë³¸ê°’)

ì˜ë¯¸:
- 8,192ê°œ í–‰ë§ˆë‹¤ ì¸ë±ìŠ¤ í¬ì¸íŠ¸ ìƒì„±
- ì‘ì„ìˆ˜ë¡: ì •í™•í•œ íƒìƒ‰, ë” ë§ì€ ë©”ëª¨ë¦¬
- í´ìˆ˜ë¡: ì ì€ ë©”ëª¨ë¦¬, ëœ ì •í™•í•œ íƒìƒ‰

ì˜ˆì‹œ:
1ì–µ ê±´ ë°ì´í„°
â†’ 8192 granularity: 12,207ê°œ ì¸ë±ìŠ¤ í¬ì¸íŠ¸
â†’ 4096 granularity: 24,414ê°œ ì¸ë±ìŠ¤ í¬ì¸íŠ¸
```

#### 2. ReplacingMergeTree - ì¤‘ë³µ ì œê±°

**íŠ¹ì§•:**
- ë³‘í•© ì‹œ ì¤‘ë³µëœ í–‰ ì œê±°
- ìµœì‹  ë²„ì „ë§Œ ìœ ì§€
- UPDATE ì‹œë®¬ë ˆì´ì…˜ ê°€ëŠ¥

**ì‚¬ìš© ì˜ˆì‹œ:**

```sql
CREATE TABLE user_profiles
(
    user_id UInt32,
    name String,
    email String,
    updated_at DateTime
)
ENGINE = ReplacingMergeTree(updated_at)
ORDER BY user_id;

-- ë°ì´í„° ì‚½ì… (UPDATE ëŒ€ì‹ )
INSERT INTO user_profiles VALUES (1, 'Alice', 'alice@old.com', '2024-01-01');
INSERT INTO user_profiles VALUES (1, 'Alice', 'alice@new.com', '2024-01-02');

-- ë³‘í•© ì „: ë‘ í–‰ ëª¨ë‘ ì¡´ì¬
SELECT * FROM user_profiles WHERE user_id = 1;
â”Œâ”€user_idâ”€â”¬â”€nameâ”€â”€â”¬â”€emailâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€updated_atâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1      â”‚ Alice â”‚ alice@old.com  â”‚ 2024-01-01 00:00:00 â”‚
â”‚  1      â”‚ Alice â”‚ alice@new.com  â”‚ 2024-01-02 00:00:00 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

-- ë³‘í•© í›„: ìµœì‹  í–‰ë§Œ ìœ ì§€
OPTIMIZE TABLE user_profiles FINAL;

SELECT * FROM user_profiles WHERE user_id = 1;
â”Œâ”€user_idâ”€â”¬â”€nameâ”€â”€â”¬â”€emailâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€updated_atâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1      â”‚ Alice â”‚ alice@new.com  â”‚ 2024-01-02 00:00:00 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

-- FINAL í‚¤ì›Œë“œë¡œ ì¦‰ì‹œ ì¤‘ë³µ ì œê±° (ì„±ëŠ¥ ì˜í–¥)
SELECT * FROM user_profiles FINAL WHERE user_id = 1;
```

**ì£¼ì˜ì‚¬í•­:**

```
1. ë³‘í•©ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
   â†’ ì¦‰ì‹œ ì¤‘ë³µ ì œê±° ì•ˆ ë¨

2. FINAL ì‚¬ìš© ì‹œ ì„±ëŠ¥ ì €í•˜
   â†’ ì‹¤ì‹œê°„ ì¿¼ë¦¬ì—ì„œëŠ” ê¶Œì¥ ì•ˆ í•¨

3. ORDER BY í‚¤ê°€ ë™ì¼í•´ì•¼ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
```

#### 3. SummingMergeTree - ìë™ ì§‘ê³„

**íŠ¹ì§•:**
- ë³‘í•© ì‹œ ìˆ«ì ì»¬ëŸ¼ ìë™ í•©ì‚°
- ì‚¬ì „ ì§‘ê³„ í…Œì´ë¸”ì— ì í•©
- ìŠ¤í† ë¦¬ì§€ ì ˆì•½

**ì‚¬ìš© ì˜ˆì‹œ:**

```sql
CREATE TABLE page_views_summary
(
    date Date,
    page_url String,
    views UInt64,
    unique_users UInt64
)
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (date, page_url);

-- ë°ì´í„° ì‚½ì…
INSERT INTO page_views_summary VALUES
    ('2024-01-01', '/home', 100, 50),
    ('2024-01-01', '/home', 200, 75);

-- ë³‘í•© ì „
SELECT * FROM page_views_summary WHERE page_url = '/home';
â”Œâ”€dateâ”€â”€â”€â”€â”€â”€â”€â”¬â”€page_urlâ”€â”¬â”€viewsâ”€â”¬â”€unique_usersâ”€â”
â”‚ 2024-01-01 â”‚ /home    â”‚ 100   â”‚ 50           â”‚
â”‚ 2024-01-01 â”‚ /home    â”‚ 200   â”‚ 75           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

-- ë³‘í•© í›„: ìë™ í•©ì‚°
OPTIMIZE TABLE page_views_summary;

SELECT * FROM page_views_summary WHERE page_url = '/home';
â”Œâ”€dateâ”€â”€â”€â”€â”€â”€â”€â”¬â”€page_urlâ”€â”¬â”€viewsâ”€â”¬â”€unique_usersâ”€â”
â”‚ 2024-01-01 â”‚ /home    â”‚ 300   â”‚ 125          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ì‹¤ì‹œê°„ ì§‘ê³„ ì¿¼ë¦¬:**

```sql
-- SUM í•¨ìˆ˜ë¡œ ì¦‰ì‹œ ì§‘ê³„
SELECT 
    date,
    page_url,
    SUM(views) AS total_views,
    SUM(unique_users) AS total_users
FROM page_views_summary
WHERE date >= '2024-01-01'
GROUP BY date, page_url;
```

#### 4. AggregatingMergeTree - ê³ ê¸‰ ì§‘ê³„

**íŠ¹ì§•:**
- ë³µì¡í•œ ì§‘ê³„ í•¨ìˆ˜ ì§€ì›
- ì¤‘ê°„ ìƒíƒœ ì €ì¥
- ë§¤ìš° íš¨ìœ¨ì ì¸ ì‚¬ì „ ì§‘ê³„

**ì‚¬ìš© ì˜ˆì‹œ:**

```sql
CREATE TABLE user_activity_agg
(
    date Date,
    page_url String,
    views SimpleAggregateFunction(sum, UInt64),
    unique_users AggregateFunction(uniq, UInt32),
    avg_duration AggregateFunction(avg, Float32)
)
ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (date, page_url);

-- ë°ì´í„° ì‚½ì… (ì§‘ê³„ ìƒíƒœë¡œ)
INSERT INTO user_activity_agg
SELECT 
    date,
    page_url,
    sumState(views) AS views,
    uniqState(user_id) AS unique_users,
    avgState(duration) AS avg_duration
FROM user_activity
GROUP BY date, page_url;

-- ì¡°íšŒ (ë³‘í•©ëœ ì§‘ê³„ ê°’)
SELECT 
    date,
    page_url,
    sum(views) AS total_views,
    uniqMerge(unique_users) AS unique_user_count,
    avgMerge(avg_duration) AS avg_duration_sec
FROM user_activity_agg
WHERE date >= '2024-01-01'
GROUP BY date, page_url;
```

**SimpleAggregateFunction vs AggregateFunction:**

```
SimpleAggregateFunction:
- ë‹¨ìˆœ ì§‘ê³„ (sum, min, max, any)
- ì¤‘ê°„ ìƒíƒœ ì €ì¥ ì•ˆ í•¨
- ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

AggregateFunction:
- ë³µì¡í•œ ì§‘ê³„ (uniq, quantile, groupArray)
- ì¤‘ê°„ ìƒíƒœ ì €ì¥
- HyperLogLog ë“± ê·¼ì‚¬ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
```

### Log ê³„ì—´ ì—”ì§„

#### TinyLog - ê°„ë‹¨í•œ í…Œì´ë¸”

```sql
CREATE TABLE test_logs
(
    timestamp DateTime,
    message String
)
ENGINE = TinyLog;

-- íŠ¹ì§•:
-- 1. ì¸ë±ìŠ¤ ì—†ìŒ
-- 2. ë³‘ë ¬ ì½ê¸° ë¶ˆê°€
-- 3. ì‘ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ìš©
-- 4. ë™ì‹œ ì“°ê¸° ì ê¸ˆ
```

### í†µí•© ì—”ì§„

#### Kafka - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬

```sql
CREATE TABLE kafka_source
(
    event_time DateTime,
    user_id UInt32,
    action String
)
ENGINE = Kafka()
SETTINGS 
    kafka_broker_list = 'localhost:9092',
    kafka_topic_list = 'events',
    kafka_group_name = 'clickhouse_consumer',
    kafka_format = 'JSONEachRow';

-- Materialized Viewë¡œ MergeTreeì— ì €ì¥
CREATE MATERIALIZED VIEW events_mv TO events AS
SELECT * FROM kafka_source;
```

#### MySQL - ì‹¤ì‹œê°„ ë™ê¸°í™”

```sql
CREATE TABLE mysql_users
(
    id UInt32,
    name String,
    email String
)
ENGINE = MySQL('mysql-host:3306', 'database', 'users', 'username', 'password');

-- ì‹¤ì‹œê°„ìœ¼ë¡œ MySQL ë°ì´í„° ì¡°íšŒ
SELECT * FROM mysql_users WHERE id > 1000;
```

---

## ë°ì´í„° íƒ€ì…ê³¼ í•¨ìˆ˜

### ê¸°ë³¸ ë°ì´í„° íƒ€ì…

#### ì •ìˆ˜í˜•

```sql
-- ë¶€í˜¸ ìˆëŠ” ì •ìˆ˜
Int8    -- -128 ~ 127 (1 byte)
Int16   -- -32,768 ~ 32,767 (2 bytes)
Int32   -- -2,147,483,648 ~ 2,147,483,647 (4 bytes)
Int64   -- 64ë¹„íŠ¸ ì •ìˆ˜ (8 bytes)

-- ë¶€í˜¸ ì—†ëŠ” ì •ìˆ˜ (ê¶Œì¥)
UInt8   -- 0 ~ 255
UInt16  -- 0 ~ 65,535
UInt32  -- 0 ~ 4,294,967,295
UInt64  -- 0 ~ 18,446,744,073,709,551,615

-- ì˜ˆì‹œ
CREATE TABLE counters
(
    user_id UInt32,        -- ì‚¬ìš©ì ID (40ì–µê¹Œì§€)
    page_views UInt64,     -- í˜ì´ì§€ë·° (í° ìˆ«ì)
    age UInt8              -- ë‚˜ì´ (0-255ë©´ ì¶©ë¶„)
)
ENGINE = MergeTree()
ORDER BY user_id;
```

#### ë¶€ë™ì†Œìˆ˜ì 

```sql
Float32  -- ë‹¨ì •ë°€ë„ (4 bytes)
Float64  -- ë°°ì •ë°€ë„ (8 bytes)

-- Decimal (ì •í™•í•œ ì†Œìˆ˜ì  ê³„ì‚°)
Decimal(P, S)  -- P: ì „ì²´ ìë¦¿ìˆ˜, S: ì†Œìˆ˜ì  ìë¦¿ìˆ˜
Decimal32(S)   -- 9ìë¦¬
Decimal64(S)   -- 18ìë¦¬
Decimal128(S)  -- 38ìë¦¬

-- ì˜ˆì‹œ: ê¸ˆìœµ ë°ì´í„°
CREATE TABLE transactions
(
    transaction_id UInt64,
    amount Decimal(18, 2),  -- 999,999,999,999,999.99ê¹Œì§€
    tax_rate Decimal(5, 4)  -- 99.9999%ê¹Œì§€
)
ENGINE = MergeTree()
ORDER BY transaction_id;
```

#### ë¬¸ìì—´

```sql
String          -- ê°€ë³€ ê¸¸ì´ ë¬¸ìì—´ (ê¶Œì¥)
FixedString(N)  -- ê³ ì • ê¸¸ì´ (N ë°”ì´íŠ¸)

-- ì˜ˆì‹œ
CREATE TABLE users
(
    user_id UInt32,
    name String,
    country_code FixedString(2),  -- 'KR', 'US' ë“±
    bio String
)
ENGINE = MergeTree()
ORDER BY user_id;
```

#### ë‚ ì§œ/ì‹œê°„

```sql
Date        -- ë‚ ì§œ (YYYY-MM-DD)
DateTime    -- íƒ€ì„ìŠ¤íƒ¬í”„ (ì´ˆ ë‹¨ìœ„)
DateTime64  -- íƒ€ì„ìŠ¤íƒ¬í”„ (ë°€ë¦¬ì´ˆ, ë§ˆì´í¬ë¡œì´ˆ)

-- ì˜ˆì‹œ
CREATE TABLE events
(
    event_time DateTime,                    -- ì´ˆ ë‹¨ìœ„
    precise_time DateTime64(3),             -- ë°€ë¦¬ì´ˆ (0.001ì´ˆ)
    event_date Date,                        -- ë‚ ì§œë§Œ
    event_timestamp UInt32                  -- Unix íƒ€ì„ìŠ¤íƒ¬í”„
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(event_date)
ORDER BY event_time;

-- ì‹œê°„ëŒ€ ì§€ì •
CREATE TABLE events_with_tz
(
    event_time DateTime('Asia/Seoul'),
    created_at DateTime64(3, 'UTC')
)
ENGINE = MergeTree()
ORDER BY event_time;
```

#### ë°°ì—´

```sql
Array(T)  -- T íƒ€ì…ì˜ ë°°ì—´

-- ì˜ˆì‹œ
CREATE TABLE user_tags
(
    user_id UInt32,
    tags Array(String),              -- ['sports', 'tech', 'music']
    visit_dates Array(Date),         -- [2024-01-01, 2024-01-05]
    scores Array(Float32)            -- [95.5, 87.2, 91.0]
)
ENGINE = MergeTree()
ORDER BY user_id;

-- ë°°ì—´ ì¡°íšŒ
SELECT 
    user_id,
    tags,
    arrayElement(tags, 1) AS first_tag,  -- ì²« ë²ˆì§¸ íƒœê·¸
    length(tags) AS tag_count,            -- íƒœê·¸ ê°œìˆ˜
    has(tags, 'sports') AS has_sports     -- íŠ¹ì • ê°’ í¬í•¨ ì—¬ë¶€
FROM user_tags;
```

#### Nested (ì¤‘ì²© êµ¬ì¡°)

```sql
-- ë³µì¡í•œ ì¤‘ì²© ë°ì´í„° êµ¬ì¡°
CREATE TABLE user_actions
(
    user_id UInt32,
    actions Nested(
        timestamp DateTime,
        action_type String,
        metadata String
    )
)
ENGINE = MergeTree()
ORDER BY user_id;

-- ë°ì´í„° ì‚½ì…
INSERT INTO user_actions VALUES
(
    1,
    [
        '2024-01-01 10:00:00', '2024-01-01 11:00:00'
    ],
    [
        'click', 'purchase'
    ],
    [
        '{"page": "home"}', '{"amount": 100}'
    ]
);

-- ì¡°íšŒ
SELECT 
    user_id,
    actions.timestamp,
    actions.action_type
FROM user_actions;
```

### ê³ ê¸‰ í•¨ìˆ˜

#### ì§‘ê³„ í•¨ìˆ˜

```sql
-- ê¸°ë³¸ ì§‘ê³„
SELECT
    COUNT() AS total_rows,
    COUNT(DISTINCT user_id) AS unique_users,
    SUM(amount) AS total_amount,
    AVG(amount) AS avg_amount,
    MIN(amount) AS min_amount,
    MAX(amount) AS max_amount
FROM transactions;

-- ê³ ê¸‰ ì§‘ê³„
SELECT
    -- ì¤‘ì•™ê°’
    quantile(0.5)(duration) AS median_duration,
    
    -- 90ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜
    quantile(0.9)(duration) AS p90_duration,
    
    -- ì—¬ëŸ¬ ë°±ë¶„ìœ„ìˆ˜ ë™ì‹œ ê³„ì‚°
    quantiles(0.5, 0.9, 0.95, 0.99)(duration) AS percentiles,
    
    -- í‘œì¤€í¸ì°¨
    stddevPop(duration) AS stddev,
    
    -- ë¶„ì‚°
    varPop(duration) AS variance
FROM page_loads
WHERE date >= today() - 7;
```

#### ë‚ ì§œ/ì‹œê°„ í•¨ìˆ˜

```sql
SELECT
    -- í˜„ì¬ ì‹œê°„
    now() AS current_time,
    today() AS current_date,
    yesterday() AS yesterday_date,
    
    -- ë‚ ì§œ ì¶”ì¶œ
    toYear(event_time) AS year,
    toMonth(event_time) AS month,
    toDayOfWeek(event_time) AS day_of_week,  -- 1=Monday, 7=Sunday
    toHour(event_time) AS hour,
    
    -- ë‚ ì§œ ë³€í™˜
    toYYYYMM(event_time) AS year_month,       -- 202401
    toStartOfMonth(event_time) AS month_start, -- 2024-01-01
    toStartOfWeek(event_time) AS week_start,
    toStartOfDay(event_time) AS day_start,
    
    -- ë‚ ì§œ ì—°ì‚°
    addDays(event_time, 7) AS next_week,
    subtractHours(event_time, 1) AS hour_ago,
    
    -- ë‚ ì§œ ì°¨ì´
    dateDiff('day', start_date, end_date) AS days_diff,
    dateDiff('hour', start_time, end_time) AS hours_diff
FROM events;
```

#### ë¬¸ìì—´ í•¨ìˆ˜

```sql
SELECT
    -- ê¸°ë³¸ ë¬¸ìì—´ ì¡°ì‘
    lower(name) AS lowercase,
    upper(name) AS uppercase,
    length(name) AS name_length,
    
    -- ë¶€ë¶„ ë¬¸ìì—´
    substring(email, 1, position(email, '@') - 1) AS username,
    splitByChar('@', email)[1] AS domain,
    
    -- íŒ¨í„´ ë§¤ì¹­
    match(url, 'https://.*\\.com') AS is_com_domain,
    extract(url, '/product/([0-9]+)') AS product_id,
    
    -- ë¬¸ìì—´ ë³€í™˜
    trim(both ' ' from text) AS trimmed,
    replace(text, 'old', 'new') AS replaced,
    concat(first_name, ' ', last_name) AS full_name
FROM users;
```

#### ë°°ì—´ í•¨ìˆ˜

```sql
SELECT
    -- ë°°ì—´ ìƒì„±
    [1, 2, 3] AS simple_array,
    range(10) AS numbers,  -- [0, 1, 2, ..., 9]
    
    -- ë°°ì—´ ì¡°ì‘
    arrayElement(tags, 1) AS first_tag,
    arraySlice(tags, 2, 3) AS middle_tags,
    arrayConcat(tags1, tags2) AS combined,
    
    -- ë°°ì—´ ê²€ìƒ‰
    has(tags, 'important') AS has_important,
    indexOf(tags, 'important') AS position,
    
    -- ë°°ì—´ ì§‘ê³„
    arraySum([1, 2, 3, 4, 5]) AS sum,
    arrayAvg([1, 2, 3, 4, 5]) AS avg,
    
    -- ë°°ì—´ í•„í„°ë§
    arrayFilter(x -> x > 10, numbers) AS filtered,
    arrayMap(x -> x * 2, numbers) AS doubled
FROM data;
```

#### JSON í•¨ìˆ˜

```sql
SELECT
    -- JSON íŒŒì‹±
    JSONExtractString(json_data, 'user', 'name') AS user_name,
    JSONExtractInt(json_data, 'user', 'age') AS user_age,
    
    -- JSON ë°°ì—´
    JSONExtractArrayRaw(json_data, 'items') AS items_array,
    
    -- ì „ì²´ JSON íŒŒì‹±
    JSONExtract(json_data, 'Tuple(name String, age UInt8)') AS user_tuple
FROM raw_logs;

-- JSON íƒ€ì… ì‚¬ìš©
CREATE TABLE json_logs
(
    event_time DateTime,
    data JSON  -- ì‹¤í—˜ì  ê¸°ëŠ¥
)
ENGINE = MergeTree()
ORDER BY event_time;
```

---

## ì¿¼ë¦¬ ìµœì í™”

### ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„

```sql
-- ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš í™•ì¸
EXPLAIN PLAN
SELECT 
    country,
    COUNT() AS user_count,
    AVG(age) AS avg_age
FROM users
WHERE registration_date >= '2024-01-01'
GROUP BY country
ORDER BY user_count DESC
LIMIT 10;

-- ê²°ê³¼ ì˜ˆì‹œ:
â”Œâ”€explainâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Expression (Projection)                 â”‚
â”‚   Limit (preliminary LIMIT)             â”‚
â”‚     Sorting (ORDER BY)                  â”‚
â”‚       Expression (Before ORDER BY)      â”‚
â”‚         Aggregating                     â”‚
â”‚           Expression (Before GROUP BY)  â”‚
â”‚             Filter (WHERE)              â”‚
â”‚               ReadFromMergeTree (users) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

-- ìƒì„¸ ì‹¤í–‰ ê³„íš
EXPLAIN indexes = 1, actions = 1
SELECT ...;
```

### ì¸ë±ìŠ¤ í™œìš©

#### ê¸°ë³¸í‚¤ ì¸ë±ìŠ¤ (Sparse Index)

ClickHouseëŠ” í¬ì†Œ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

```
ì „í†µì  RDBMS:
ëª¨ë“  í–‰ì— ëŒ€í•œ ì¸ë±ìŠ¤ í¬ì¸íŠ¸ ìƒì„±
1ì–µ ê±´ â†’ 1ì–µ ê°œ ì¸ë±ìŠ¤ ì—”íŠ¸ë¦¬

ClickHouse:
ì¼ì • ê°„ê²©(granularity)ë§ˆë‹¤ ì¸ë±ìŠ¤ í¬ì¸íŠ¸ ìƒì„±
1ì–µ ê±´ â†’ 12,207ê°œ ì¸ë±ìŠ¤ ì—”íŠ¸ë¦¬ (granularity=8192)

ë©”ëª¨ë¦¬ ì ˆì•½: 99.99%
```

**ì¸ë±ìŠ¤ ìµœì í™”:**

```sql
-- âœ… ì¢‹ì€ ì˜ˆ: ORDER BY í‚¤ ì‚¬ìš©
SELECT * FROM users WHERE country = 'KR' AND city = 'Seoul';
-- ORDER BY (country, city, user_id)

-- âŒ ë‚˜ìœ ì˜ˆ: ORDER BY í‚¤ ë¯¸ì‚¬ìš©
SELECT * FROM users WHERE age > 30;
-- ORDER BY (country, city, user_id) â†’ ageëŠ” ì •ë ¬ í‚¤ê°€ ì•„ë‹˜
```

#### Skip Index (ë³´ì¡° ì¸ë±ìŠ¤)

íŠ¹ì • ì¡°ê±´ì—ì„œ ë°ì´í„° ë¸”ë¡ì„ ê±´ë„ˆë›°ëŠ” ì¸ë±ìŠ¤:

```sql
-- Bloom Filter Index (ì§‘í•© ì—°ì‚°)
ALTER TABLE users ADD INDEX idx_email(email) TYPE bloom_filter GRANULARITY 4;

-- íš¨ê³¼ì ì¸ ì¿¼ë¦¬
SELECT * FROM users WHERE email = 'user@example.com';
-- Bloom filterê°€ í•´ë‹¹ ë¸”ë¡ì— ì´ë©”ì¼ì´ ì—†ë‹¤ê³  íŒë‹¨í•˜ë©´ ìŠ¤í‚µ

-- MinMax Index (ë²”ìœ„ ì¿¼ë¦¬)
ALTER TABLE orders ADD INDEX idx_amount(amount) TYPE minmax GRANULARITY 4;

-- íš¨ê³¼ì ì¸ ì¿¼ë¦¬
SELECT * FROM orders WHERE amount BETWEEN 1000 AND 5000;
-- MinMax ê°’ìœ¼ë¡œ ë²”ìœ„ ë°– ë¸”ë¡ ìŠ¤í‚µ

-- Set Index (ë‚®ì€ ì¹´ë””ë„ë¦¬í‹°)
ALTER TABLE logs ADD INDEX idx_status(status) TYPE set(100) GRANULARITY 4;

-- íš¨ê³¼ì ì¸ ì¿¼ë¦¬
SELECT * FROM logs WHERE status IN ('ERROR', 'WARNING');
-- Set indexë¡œ ë¹ ë¥¸ í•„í„°ë§
```

### ì¿¼ë¦¬ ìµœì í™” íŒ¨í„´

#### 1. PREWHERE vs WHERE

```sql
-- âŒ ë¹„íš¨ìœ¨ì 
SELECT *
FROM large_table
WHERE heavy_calculation(column1) > 100
  AND column2 = 'value';

-- âœ… íš¨ìœ¨ì 
SELECT *
FROM large_table
PREWHERE column2 = 'value'  -- ë¨¼ì € í•„í„°ë§ (ì ì€ ë°ì´í„°)
WHERE heavy_calculation(column1) > 100;  -- ì´í›„ ê³„ì‚° (ë§ì€ ë°ì´í„°)

-- PREWHERE:
-- 1. ì»¬ëŸ¼ ì¼ë¶€ë§Œ ì½ìŒ
-- 2. ë¹ ë¥¸ í•„í„°ë§
-- 3. ê²°ê³¼ í–‰ì— ëŒ€í•´ì„œë§Œ ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ ì½ìŒ
```

#### 2. Projection (ì‚¬ì „ ì§‘ê³„)

```sql
-- Projection ì •ì˜
ALTER TABLE sales ADD PROJECTION sales_by_region
(
    SELECT 
        region,
        SUM(amount) AS total_amount,
        COUNT() AS order_count
    GROUP BY region
);

-- Projection êµ¬ì²´í™”
ALTER TABLE sales MATERIALIZE PROJECTION sales_by_region;

-- ì¿¼ë¦¬ ì‹œ ìë™ìœ¼ë¡œ Projection ì‚¬ìš©
SELECT 
    region,
    SUM(amount),
    COUNT()
FROM sales
GROUP BY region;
-- â†’ sales_by_region projection ì‚¬ìš© (100ë°° ë¹ ë¦„)
```

#### 3. ìƒ˜í”Œë§

```sql
-- í…Œì´ë¸”ì— ìƒ˜í”Œë§ í‚¤ ì¶”ê°€
CREATE TABLE events
(
    event_time DateTime,
    user_id UInt32,
    action String
)
ENGINE = MergeTree()
ORDER BY (event_time, user_id)
SAMPLE BY user_id;

-- 10% ìƒ˜í”Œë§ ì¿¼ë¦¬
SELECT 
    action,
    COUNT() * 10 AS estimated_count  -- ìƒ˜í”Œ í¬ê¸°ë¡œ ë³´ì •
FROM events
SAMPLE 0.1
WHERE event_time >= today() - 7
GROUP BY action;

-- ë¹ ë¥¸ ê·¼ì‚¬ ê²°ê³¼, ì •í™•ë„ëŠ” ë‚®ìŒ
```

#### 4. ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”

```sql
-- ì„¤ì • ì¡°ì •
SET max_threads = 8;                    -- ìµœëŒ€ ìŠ¤ë ˆë“œ ìˆ˜
SET max_insert_threads = 4;             -- ì‚½ì… ìŠ¤ë ˆë“œ ìˆ˜
SET max_distributed_connections = 100;  -- ë¶„ì‚° ì—°ê²° ìˆ˜

-- ëŒ€ìš©ëŸ‰ ì¿¼ë¦¬
SELECT 
    date,
    COUNT() AS events
FROM large_table
WHERE date >= '2024-01-01'
GROUP BY date
SETTINGS max_threads = 16;  -- ì¿¼ë¦¬ë³„ ì„¤ì •
```

---

## ë¶„ì‚° ì²˜ë¦¬ì™€ ë³µì œ

### ë¶„ì‚° í…Œì´ë¸” (Distributed Table)

ë¶„ì‚° í…Œì´ë¸”ì€ ì—¬ëŸ¬ ì„œë²„ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ ì¡°íšŒí•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤:

```sql
-- ê° ì„œë²„ì— ë¡œì»¬ í…Œì´ë¸” ìƒì„±
CREATE TABLE events_local ON CLUSTER my_cluster
(
    event_time DateTime,
    user_id UInt32,
    action String
)
ENGINE = MergeTree()
ORDER BY (event_time, user_id);

-- ë¶„ì‚° í…Œì´ë¸” ìƒì„±
CREATE TABLE events_distributed ON CLUSTER my_cluster AS events_local
ENGINE = Distributed(
    my_cluster,      -- í´ëŸ¬ìŠ¤í„° ì´ë¦„
    default,         -- ë°ì´í„°ë² ì´ìŠ¤
    events_local,    -- ë¡œì»¬ í…Œì´ë¸”
    rand()           -- ìƒ¤ë”© í‚¤ (ëœë¤ ë¶„ì‚°)
);

-- ë¶„ì‚° í…Œì´ë¸”ë¡œ ì‚½ì… (ìë™ìœ¼ë¡œ ìƒ¤ë”©)
INSERT INTO events_distributed VALUES
    (now(), 123, 'click'),
    (now(), 456, 'purchase');
-- â†’ ìƒ¤ë”© í‚¤(rand())ì— ë”°ë¼ ê° ì„œë²„ì— ë¶„ì‚° ì €ì¥

-- ë¶„ì‚° í…Œì´ë¸”ë¡œ ì¡°íšŒ (ëª¨ë“  ì„œë²„ ë°ì´í„° í†µí•©)
SELECT 
    action,
    COUNT() AS count
FROM events_distributed
WHERE event_time >= today()
GROUP BY action;
-- â†’ ê° ì„œë²„ì—ì„œ ë¶€ë¶„ ì§‘ê³„ í›„ ìµœì¢… ë³‘í•©
```

**ìƒ¤ë”© ì „ëµ:**

```sql
-- 1. ëœë¤ ë¶„ì‚° (ê¸°ë³¸)
ENGINE = Distributed(my_cluster, default, events_local, rand());
-- ì¥ì : ê· ë“± ë¶„ì‚°
-- ë‹¨ì : ê´€ë ¨ ë°ì´í„°ê°€ í©ì–´ì§

-- 2. ì‚¬ìš©ì IDë¡œ ë¶„ì‚°
ENGINE = Distributed(my_cluster, default, events_local, user_id);
-- ì¥ì : ê°™ì€ ì‚¬ìš©ì ë°ì´í„°ê°€ ê°™ì€ ì„œë²„ì—
-- ë‹¨ì : ë°ì´í„° ë¶ˆê· í˜• ê°€ëŠ¥ì„±

-- 3. í•´ì‹œ í•¨ìˆ˜ ì‚¬ìš©
ENGINE = Distributed(my_cluster, default, events_local, sipHash64(user_id));
-- ì¥ì : ê· ë“±í•œ ë¶„ì‚° + ì¼ê´€ëœ í•´ì‹±
-- ê¶Œì¥: ëŒ€ë¶€ë¶„ì˜ ê²½ìš°
```

### ë³µì œ (Replication)

ë³µì œëŠ” ë°ì´í„°ì˜ ê³ ê°€ìš©ì„±ê³¼ ë‚´êµ¬ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤:

```sql
-- ReplicatedMergeTree ì‚¬ìš©
CREATE TABLE events_replicated ON CLUSTER my_cluster
(
    event_time DateTime,
    user_id UInt32,
    action String
)
ENGINE = ReplicatedMergeTree(
    '/clickhouse/tables/{shard}/events',  -- ZooKeeper ê²½ë¡œ
    '{replica}'                            -- ë³µì œë³¸ ì´ë¦„
)
ORDER BY (event_time, user_id);

-- ë³µì œ + ë¶„ì‚°
CREATE TABLE events_distributed_replicated ON CLUSTER my_cluster
AS events_replicated
ENGINE = Distributed(my_cluster, default, events_replicated, sipHash64(user_id));
```

**í´ëŸ¬ìŠ¤í„° êµ¬ì„±:**

```xml
<!-- /etc/clickhouse-server/config.xml -->
<remote_servers>
    <my_cluster>
        <!-- ìƒ¤ë“œ 1 -->
        <shard>
            <weight>1</weight>
            <internal_replication>true</internal_replication>
            <replica>
                <host>server1</host>
                <port>9000</port>
            </replica>
            <replica>
                <host>server2</host>
                <port>9000</port>
            </replica>
        </shard>
        
        <!-- ìƒ¤ë“œ 2 -->
        <shard>
            <weight>1</weight>
            <internal_replication>true</internal_replication>
            <replica>
                <host>server3</host>
                <port>9000</port>
            </replica>
            <replica>
                <host>server4</host>
                <port>9000</port>
            </replica>
        </shard>
    </my_cluster>
</remote_servers>
```

**ì•„í‚¤í…ì²˜:**

```
í´ë¼ì´ì–¸íŠ¸
    â†“
ë¶„ì‚° í…Œì´ë¸” (events_distributed_replicated)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Shard 1    â”‚   Shard 2    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Replica 1    â”‚ Replica 1    â”‚
â”‚ (server1)    â”‚ (server3)    â”‚
â”‚              â”‚              â”‚
â”‚ Replica 2    â”‚ Replica 2    â”‚
â”‚ (server2)    â”‚ (server4)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“              â†“
ZooKeeper (ë³µì œ ì¡°ì •)
```

---

## ì‹¤ë¬´ í™œìš© ì‚¬ë¡€

### 1. ì›¹ ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œ

**ìš”êµ¬ì‚¬í•­:**
- ì¼ 100ì–µ ê±´ì˜ ì›¹ ë¡œê·¸ ìˆ˜ì§‘
- ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ (1ì´ˆ ì´ë‚´ ì‘ë‹µ)
- ì‚¬ìš©ì í–‰ë™ ë¶„ì„
- íŠ¸ë˜í”½ ëª¨ë‹ˆí„°ë§

**í…Œì´ë¸” ì„¤ê³„:**

```sql
-- ì›ì‹œ ë¡œê·¸ í…Œì´ë¸”
CREATE TABLE web_logs
(
    timestamp DateTime,
    user_id UInt32,
    session_id FixedString(32),
    ip String,
    user_agent String,
    url String,
    referer String,
    country FixedString(2),
    city String,
    duration UInt32,  -- ë°€ë¦¬ì´ˆ
    status_code UInt16
)
ENGINE = MergeTree()
PARTITION BY toYYYYMMDD(timestamp)
ORDER BY (country, city, timestamp, user_id)
TTL timestamp + INTERVAL 90 DAY  -- 90ì¼ í›„ ìë™ ì‚­ì œ
SETTINGS index_granularity = 8192;

-- ì‹œê°„ë³„ ì§‘ê³„ í…Œì´ë¸” (Materialized View)
CREATE MATERIALIZED VIEW web_logs_hourly
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(hour)
ORDER BY (country, city, hour, url)
AS SELECT
    toStartOfHour(timestamp) AS hour,
    country,
    city,
    url,
    COUNT() AS page_views,
    uniq(user_id) AS unique_users,
    SUM(duration) AS total_duration,
    countIf(status_code >= 500) AS error_count
FROM web_logs
GROUP BY hour, country, city, url;
```

**ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ì¿¼ë¦¬:**

```sql
-- êµ­ê°€ë³„ ì‹¤ì‹œê°„ íŠ¸ë˜í”½
SELECT 
    country,
    SUM(page_views) AS total_views,
    SUM(unique_users) AS users,
    AVG(total_duration / page_views) AS avg_duration_ms
FROM web_logs_hourly
WHERE hour >= now() - INTERVAL 1 HOUR
GROUP BY country
ORDER BY total_views DESC
LIMIT 10;
-- ì‹¤í–‰ ì‹œê°„: ~100ms (100ì–µ ê±´ì—ì„œ)

-- ì¸ê¸° í˜ì´ì§€ TOP 20
SELECT 
    url,
    SUM(page_views) AS views,
    SUM(unique_users) AS users,
    views / users AS views_per_user
FROM web_logs_hourly
WHERE hour >= today()
GROUP BY url
ORDER BY views DESC
LIMIT 20;
-- ì‹¤í–‰ ì‹œê°„: ~50ms
```

### 2. IoT ì„¼ì„œ ë°ì´í„° í”Œë«í¼

**ìš”êµ¬ì‚¬í•­:**
- 100ë§Œ ê°œ ì„¼ì„œì—ì„œ ì´ˆë‹¹ 1000ë§Œ ê±´ ë°ì´í„° ìˆ˜ì§‘
- ì‹¤ì‹œê°„ ì´ìƒ íƒì§€
- ì‹œê³„ì—´ ë¶„ì„ ë° ì˜ˆì¸¡
- ì¥ê¸° íˆìŠ¤í† ë¦¬ ì €ì¥

**í…Œì´ë¸” ì„¤ê³„:**

```sql
-- ì„¼ì„œ ë°ì´í„° í…Œì´ë¸”
CREATE TABLE sensor_data
(
    timestamp DateTime64(3),  -- ë°€ë¦¬ì´ˆ ì •ë°€ë„
    sensor_id UInt32,
    device_id UInt32,
    location_id UInt16,
    temperature Decimal(5, 2),
    humidity Decimal(5, 2),
    pressure Decimal(7, 2),
    battery_level UInt8
)
ENGINE = MergeTree()
PARTITION BY toYYYYMMDD(timestamp)
ORDER BY (location_id, device_id, sensor_id, timestamp)
TTL timestamp + INTERVAL 2 YEAR  -- 2ë…„ ë³´ê´€
SETTINGS index_granularity = 8192;

-- ë¶„ë³„ ì§‘ê³„ (ì´ìƒ íƒì§€ìš©)
CREATE MATERIALIZED VIEW sensor_data_1min
ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMM(minute)
ORDER BY (location_id, device_id, sensor_id, minute)
AS SELECT
    toStartOfMinute(timestamp) AS minute,
    location_id,
    device_id,
    sensor_id,
    avgState(temperature) AS avg_temperature,
    minState(temperature) AS min_temperature,
    maxState(temperature) AS max_temperature,
    stddevPopState(temperature) AS stddev_temperature,
    avgState(humidity) AS avg_humidity,
    avgState(battery_level) AS avg_battery
FROM sensor_data
GROUP BY minute, location_id, device_id, sensor_id;
```

**ì´ìƒ íƒì§€ ì¿¼ë¦¬:**

```sql
-- ê¸‰ê²©í•œ ì˜¨ë„ ë³€í™” ê°ì§€
SELECT 
    location_id,
    device_id,
    sensor_id,
    minute,
    avgMerge(avg_temperature) AS avg_temp,
    maxMerge(max_temperature) - minMerge(min_temperature) AS temp_range,
    stddevPopMerge(stddev_temperature) AS temp_stddev
FROM sensor_data_1min
WHERE minute >= now() - INTERVAL 10 MINUTE
  AND temp_range > 10  -- 10ë„ ì´ìƒ ë³€í™”
GROUP BY location_id, device_id, sensor_id, minute
ORDER BY temp_range DESC;
-- ì‹¤í–‰ ì‹œê°„: ~50ms

-- ë°°í„°ë¦¬ ë¶€ì¡± ì„¼ì„œ ëª©ë¡
SELECT 
    location_id,
    device_id,
    sensor_id,
    avgMerge(avg_battery) AS battery_pct
FROM sensor_data_1min
WHERE minute >= now() - INTERVAL 1 HOUR
GROUP BY location_id, device_id, sensor_id
HAVING battery_pct < 20
ORDER BY battery_pct ASC;
```

### 3. ì‹¤ì‹œê°„ ê´‘ê³  ë¶„ì„ ì‹œìŠ¤í…œ

**ìš”êµ¬ì‚¬í•­:**
- ì´ˆë‹¹ 100ë§Œ ê±´ ê´‘ê³  ë…¸ì¶œ/í´ë¦­ ì´ë²¤íŠ¸
- ì‹¤ì‹œê°„ CTR ê³„ì‚°
- ìº í˜ì¸ ì„±ê³¼ ë¶„ì„
- ì´ìƒ íŠ¸ë˜í”½ íƒì§€

**í…Œì´ë¸” ì„¤ê³„:**

```sql
-- ê´‘ê³  ì´ë²¤íŠ¸ í…Œì´ë¸”
CREATE TABLE ad_events
(
    event_time DateTime,
    event_type Enum8('impression' = 1, 'click' = 2, 'conversion' = 3),
    ad_id UInt32,
    campaign_id UInt32,
    user_id UInt64,
    device_type LowCardinality(String),
    country FixedString(2),
    placement String,
    bid_price Decimal(10, 4),
    revenue Decimal(10, 4)
)
ENGINE = MergeTree()
PARTITION BY toYYYYMMDD(event_time)
ORDER BY (campaign_id, ad_id, event_time)
SETTINGS index_granularity = 8192;

-- 5ë¶„ë³„ ì§‘ê³„ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ìš©)
CREATE MATERIALIZED VIEW ad_stats_5min
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(period)
ORDER BY (campaign_id, ad_id, device_type, period)
AS SELECT
    toStartOfFiveMinutes(event_time) AS period,
    campaign_id,
    ad_id,
    device_type,
    country,
    countIf(event_type = 'impression') AS impressions,
    countIf(event_type = 'click') AS clicks,
    countIf(event_type = 'conversion') AS conversions,
    sumIf(bid_price, event_type = 'impression') AS total_cost,
    sumIf(revenue, event_type = 'conversion') AS total_revenue
FROM ad_events
GROUP BY period, campaign_id, ad_id, device_type, country;
```

**ì‹¤ì‹œê°„ ë¶„ì„ ì¿¼ë¦¬:**

```sql
-- ì‹¤ì‹œê°„ ìº í˜ì¸ ì„±ê³¼
SELECT 
    campaign_id,
    SUM(impressions) AS total_impressions,
    SUM(clicks) AS total_clicks,
    SUM(conversions) AS total_conversions,
    (total_clicks / total_impressions) * 100 AS ctr,  -- CTR %
    (total_conversions / total_clicks) * 100 AS cvr,  -- CVR %
    SUM(total_revenue) AS revenue,
    SUM(total_cost) AS cost,
    (revenue - cost) AS profit,
    (revenue / cost - 1) * 100 AS roi  -- ROI %
FROM ad_stats_5min
WHERE period >= now() - INTERVAL 1 HOUR
GROUP BY campaign_id
ORDER BY profit DESC
LIMIT 20;
-- ì‹¤í–‰ ì‹œê°„: ~100ms

-- ë””ë°”ì´ìŠ¤ë³„ ì„±ê³¼
SELECT 
    device_type,
    SUM(impressions) AS impressions,
    SUM(clicks) AS clicks,
    (clicks / impressions) * 100 AS ctr,
    SUM(total_revenue) / SUM(total_cost) AS roas  -- Return on Ad Spend
FROM ad_stats_5min
WHERE period >= today()
GROUP BY device_type
ORDER BY roas DESC;
```

---

## ì„±ëŠ¥ íŠœë‹ ì „ëµ

### í•˜ë“œì›¨ì–´ ìµœì í™”

**CPU:**
```
ê¶Œì¥:
- ì½”ì–´ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ìœ ë¦¬ (16+ ì½”ì–´)
- ë†’ì€ í´ëŸ­ ì†ë„ (3GHz+)
- AVX2/AVX-512 ì§€ì› (ë²¡í„°í™” ì²˜ë¦¬)

ì„¤ì •:
SET max_threads = <CPU ì½”ì–´ ìˆ˜>;
```

**ë©”ëª¨ë¦¬:**
```
ê¶Œì¥:
- ìµœì†Œ 32GB, ê¶Œì¥ 64GB+
- DDR4-3200 ì´ìƒ
- ECC ë©”ëª¨ë¦¬ (í”„ë¡œë•ì…˜)

ì„¤ì •:
max_memory_usage = <RAMì˜ 80%>
max_bytes_before_external_group_by = <RAMì˜ 50%>
```

**ìŠ¤í† ë¦¬ì§€:**
```
ê¶Œì¥:
- NVMe SSD (ì½ê¸°/ì“°ê¸° ì†ë„ ì¤‘ìš”)
- RAID 10 (ì„±ëŠ¥ + ì•ˆì •ì„±)
- ë³„ë„ì˜ ë””ìŠ¤í¬ë¡œ ë¡œê·¸ ë¶„ë¦¬

ë””ìŠ¤í¬ ë ˆì´ì•„ì›ƒ:
/data     - ë©”ì¸ ë°ì´í„° (NVMe)
/logs     - ë¡œê·¸ íŒŒì¼ (SATA)
/tmp      - ì„ì‹œ íŒŒì¼ (NVMe)
```

### ì¿¼ë¦¬ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

```sql
-- âœ… 1. PREWHERE í™œìš©
SELECT *
FROM large_table
PREWHERE simple_filter_column = value  -- ë¹ ë¥¸ í•„í„°ë§
WHERE complex_expression;              -- ëŠë¦° ê³„ì‚°

-- âœ… 2. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¡°íšŒ
SELECT user_id, timestamp, action  -- í•„ìš”í•œ ê²ƒë§Œ
FROM events
-- SELECT * ì§€ì–‘

-- âœ… 3. ORDER BY í‚¤ í™œìš©
WHERE country = 'KR'  -- ORDER BYì— í¬í•¨ëœ ì»¬ëŸ¼
  AND city = 'Seoul'

-- âœ… 4. ì§‘ê³„ ìµœì í™”
SELECT
    country,
    uniq(user_id)  -- uniqExactë³´ë‹¤ ë¹ ë¦„ (ê·¼ì‚¬ì¹˜)
FROM users
GROUP BY country;

-- âœ… 5. LIMIT ì‚¬ìš©
SELECT *
FROM large_table
WHERE condition
LIMIT 1000;  -- í•„ìš”í•œ ë§Œí¼ë§Œ

-- âœ… 6. ìƒ˜í”Œë§ í™œìš© (ê·¼ì‚¬ ë¶„ì„)
SELECT
    country,
    COUNT() * 10 AS estimated_count
FROM events
SAMPLE 0.1  -- 10% ìƒ˜í”Œë§
WHERE date >= today() - 7
GROUP BY country;

-- âœ… 7. Materialized View í™œìš©
-- ìì£¼ ì‹¤í–‰ë˜ëŠ” ì§‘ê³„ ì¿¼ë¦¬ëŠ” MVë¡œ ì‚¬ì „ ê³„ì‚°

-- âœ… 8. íŒŒí‹°ì…˜ í”„ë£¨ë‹
SELECT *
FROM events
WHERE date = '2024-01-01'  -- íŠ¹ì • íŒŒí‹°ì…˜ë§Œ
-- PARTITION BY toYYYYMMDD(date)
```

### ì‚½ì… ì„±ëŠ¥ ìµœì í™”

```sql
-- âŒ ë‚˜ìœ ì˜ˆ: ê°œë³„ INSERT
INSERT INTO events VALUES (1, 'data1');
INSERT INTO events VALUES (2, 'data2');
-- ... 1000íšŒ

-- âœ… ì¢‹ì€ ì˜ˆ: ë°°ì¹˜ INSERT
INSERT INTO events VALUES
    (1, 'data1'),
    (2, 'data2'),
    ...
    (1000, 'data1000');

-- âœ… ë” ì¢‹ì€ ì˜ˆ: ëŒ€ìš©ëŸ‰ INSERT
INSERT INTO events
SELECT * FROM input('row UInt32, data String')
FORMAT TSV
-- STDINìœ¼ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°

-- ë¹„ë™ê¸° INSERT (ClickHouse 21.11+)
SET async_insert = 1;
SET wait_for_async_insert = 0;

INSERT INTO events VALUES (1, 'data1');
-- ë‚´ë¶€ ë²„í¼ì— ì¶•ì  í›„ ë°°ì¹˜ë¡œ ì‚½ì…
```

### ìŠ¤í† ë¦¬ì§€ ìµœì í™”

```sql
-- íŒŒí‹°ì…˜ ê´€ë¦¬
-- ì˜¤ë˜ëœ íŒŒí‹°ì…˜ ì‚­ì œ
ALTER TABLE events DROP PARTITION '202301';

-- íŒŒí‹°ì…˜ ìµœì í™” (ìˆ˜ë™ ë³‘í•©)
OPTIMIZE TABLE events PARTITION '202401' FINAL;

-- TTL ì„¤ì • (ìë™ ì‚­ì œ)
ALTER TABLE events
MODIFY TTL timestamp + INTERVAL 90 DAY;

-- ì••ì¶• ì„¤ì •
ALTER TABLE events
MODIFY SETTING 
    min_compress_block_size = 65536,
    max_compress_block_size = 1048576;

-- ë°ì´í„° íƒ€ì… ìµœì í™”
-- UInt32 ëŒ€ì‹  UInt16 ì‚¬ìš© (ê°’ ë²”ìœ„ê°€ ì‘ìœ¼ë©´)
-- String ëŒ€ì‹  LowCardinality(String) (ì¹´ë””ë„ë¦¬í‹° ë‚®ìœ¼ë©´)
-- String ëŒ€ì‹  FixedString(N) (ê³ ì • ê¸¸ì´ë©´)
```

---

## ìš´ì˜ ë° ëª¨ë‹ˆí„°ë§

### ì£¼ìš” ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§

```sql
-- ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
SELECT *
FROM system.metrics;

-- CPU ì‚¬ìš©ë¥ 
SELECT
    event,
    value
FROM system.events
WHERE event LIKE '%CPU%';

-- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
SELECT
    formatReadableSize(value) AS memory
FROM system.metrics
WHERE metric = 'MemoryTracking';

-- ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
SELECT
    database,
    table,
    formatReadableSize(bytes_on_disk) AS size
FROM system.parts
WHERE active
ORDER BY bytes_on_disk DESC
LIMIT 20;

-- ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬
SELECT
    query_id,
    user,
    query,
    elapsed,
    formatReadableSize(memory_usage) AS memory,
    formatReadableSize(read_bytes) AS read_bytes
FROM system.processes
ORDER BY elapsed DESC;

-- ëŠë¦° ì¿¼ë¦¬ ë¶„ì„
SELECT
    query,
    query_duration_ms,
    read_rows,
    formatReadableSize(read_bytes) AS read_size,
    formatReadableSize(memory_usage) AS memory
FROM system.query_log
WHERE type = 'QueryFinish'
  AND query_duration_ms > 1000  -- 1ì´ˆ ì´ìƒ
ORDER BY query_duration_ms DESC
LIMIT 20;
```

### ë°±ì—… ë° ë³µêµ¬

```bash
# ë°±ì—… (clickhouse-backup ë„êµ¬)
clickhouse-backup create backup_20240101

# ì›ê²© ìŠ¤í† ë¦¬ì§€ë¡œ ì—…ë¡œë“œ
clickhouse-backup upload backup_20240101

# ë³µêµ¬
clickhouse-backup download backup_20240101
clickhouse-backup restore backup_20240101

# íŒŒí‹°ì…˜ë³„ ë°±ì—…
clickhouse-backup create --partitions=202401,202402 backup_202401_202402
```

### ì„¤ì • íŠœë‹

```xml
<!-- /etc/clickhouse-server/config.xml -->
<clickhouse>
    <!-- ë©”ëª¨ë¦¬ ì„¤ì • -->
    <max_server_memory_usage>64GB</max_server_memory_usage>
    <max_concurrent_queries>100</max_concurrent_queries>
    
    <!-- ë³‘ë ¬ ì²˜ë¦¬ -->
    <max_threads>16</max_threads>
    
    <!-- ë„¤íŠ¸ì›Œí¬ -->
    <max_connections>4096</max_connections>
    
    <!-- ë¡œê·¸ -->
    <logger>
        <level>information</level>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
        <size>100M</size>
        <count>10</count>
    </logger>
    
    <!-- ì••ì¶• -->
    <compression>
        <case>
            <method>lz4</method>
        </case>
    </compression>
</clickhouse>
```

### ë³´ì•ˆ ì„¤ì •

```xml
<!-- users.xml -->
<clickhouse>
    <users>
        <default>
            <password_sha256_hex>hash</password_sha256_hex>
            <networks>
                <ip>127.0.0.1</ip>
                <ip>10.0.0.0/8</ip>
            </networks>
            <profile>default</profile>
            <quota>default</quota>
        </default>
        
        <readonly_user>
            <password_sha256_hex>hash</password_sha256_hex>
            <networks>
                <ip>::/0</ip>
            </networks>
            <profile>readonly</profile>
            <quota>default</quota>
        </readonly_user>
    </users>
    
    <profiles>
        <default>
            <max_memory_usage>10000000000</max_memory_usage>
            <use_uncompressed_cache>0</use_uncompressed_cache>
            <load_balancing>random</load_balancing>
        </default>
        
        <readonly>
            <readonly>1</readonly>
        </readonly>
    </profiles>
    
    <quotas>
        <default>
            <interval>
                <duration>3600</duration>
                <queries>1000</queries>
                <errors>100</errors>
                <result_rows>1000000000</result_rows>
                <read_rows>1000000000</read_rows>
                <execution_time>3600</execution_time>
            </interval>
        </default>
    </quotas>
</clickhouse>
```

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ

- **ClickHouse ê³µì‹ ì‚¬ì´íŠ¸**: https://clickhouse.com/
- **ê³µì‹ ë¬¸ì„œ**: https://clickhouse.com/docs/
- **GitHub ì €ì¥ì†Œ**: https://github.com/ClickHouse/ClickHouse
- **ë¦´ë¦¬ìŠ¤ ë…¸íŠ¸**: https://clickhouse.com/docs/en/whats-new/changelog/

### ì»¤ë®¤ë‹ˆí‹° ë° ì§€ì›

- **ClickHouse Slack**: https://clickhouse.com/slack
- **Stack Overflow**: íƒœê·¸ `clickhouse`
- **Reddit**: r/ClickHouse
- **Telegram**: @clickhouse_en

### í•™ìŠµ ìë£Œ

- **ClickHouse Academy**: https://learn.clickhouse.com/
- **YouTube ê³µì‹ ì±„ë„**: https://www.youtube.com/@ClickHouseDB
- **ì›¨ë¹„ë‚˜ ì•„ì¹´ì´ë¸Œ**: https://clickhouse.com/company/events

### ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬

**í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬:**
- Python: `clickhouse-driver`, `clickhouse-connect`
- Java: `clickhouse-jdbc`
- Go: `clickhouse-go`
- Node.js: `@clickhouse/client`

**ê´€ë¦¬ ë„êµ¬:**
- **Tabix**: ì›¹ ê¸°ë°˜ SQL í´ë¼ì´ì–¸íŠ¸
- **DBeaver**: ë²”ìš© ë°ì´í„°ë² ì´ìŠ¤ ë„êµ¬
- **Grafana**: ëª¨ë‹ˆí„°ë§ ë° ì‹œê°í™”
- **clickhouse-backup**: ë°±ì—… ë„êµ¬

### ëª¨ë²” ì‚¬ë¡€ ë¬¸ì„œ

- **Performance Optimization Guide**: https://clickhouse.com/docs/en/operations/optimizing-performance/
- **Best Practices**: https://clickhouse.com/docs/en/operations/best-practices/
- **Schema Design**: https://clickhouse.com/docs/en/data-modeling/schema-design/

### ì‹¤ì œ ì‚¬ë¡€ ì—°êµ¬

- **Cloudflare**: ë¡œê·¸ ë¶„ì„ (ì¼ 60TB)
- **Uber**: ì‹¤ì‹œê°„ ë¶„ì„ í”Œë«í¼
- **eBay**: ì‚¬ìš©ì í–‰ë™ ë¶„ì„
- **Spotify**: ìŒì•… ì¶”ì²œ ì‹œìŠ¤í…œ
- **Yandex**: ì›¹ ë¶„ì„ (Yandex.Metrica)

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

- **ClickBench**: https://benchmark.clickhouse.com/
- **TPC-H ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼**
- **ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¹„êµ**: vs PostgreSQL, vs MongoDB, vs Druid

---


