---
title: ëŒ€ëŸ‰ì˜ APIë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•
tags: [network, 7-layer, application-layer, http, ëŒ€ëŸ‰ì˜-apië¥¼-ì²˜ë¦¬í•˜ëŠ”-ë°©ë²•, redis, caching, load-balancing, aws, ecs, rds-proxy, elasticache, alb]
updated: 2025-11-01
---

# ëŒ€ëŸ‰ì˜ APIë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•

## ğŸ“‹ ëª©ì°¨
- [ë°°ê²½](#ë°°ê²½)
- [ëŒ€ìš©ëŸ‰ API ì²˜ë¦¬ì˜ ë„ì „ ê³¼ì œ](#ëŒ€ìš©ëŸ‰-api-ì²˜ë¦¬ì˜-ë„ì „-ê³¼ì œ)
- [í´ëŸ¬ìŠ¤í„° ì•„í‚¤í…ì²˜](#í´ëŸ¬ìŠ¤í„°-ì•„í‚¤í…ì²˜)
- [Redis ì—†ì´ ì§ì ‘ API í˜¸ì¶œ ì‹œ ë¬¸ì œì ](#redis-ì—†ì´-ì§ì ‘-api-í˜¸ì¶œ-ì‹œ-ë¬¸ì œì )
- [Redisë¥¼ í™œìš©í•œ í•´ê²° ë°©ë²•](#redisë¥¼-í™œìš©í•œ-í•´ê²°-ë°©ë²•)
- [Redis ìºì‹± ì „ëµ](#redis-ìºì‹±-ì „ëµ)
- [Redis í´ëŸ¬ìŠ¤í„° êµ¬ì„±](#redis-í´ëŸ¬ìŠ¤í„°-êµ¬ì„±)
- [API Rate Limiting](#api-rate-limiting)
- [ë°°ì¹˜ ì²˜ë¦¬ ë°©ë²•](#ë°°ì¹˜-ì²˜ë¦¬-ë°©ë²•)
- [ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ](#ì‹¤ì œ-êµ¬í˜„-ì˜ˆì‹œ)
- [AWS ì¸í”„ë¼ë¥¼ í™œìš©í•œ ëŒ€ëŸ‰ API ì²˜ë¦¬](#aws-ì¸í”„ë¼ë¥¼-í™œìš©í•œ-ëŒ€ëŸ‰-api-ì²˜ë¦¬)
- [ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ìµœì í™”](#ëª¨ë‹ˆí„°ë§-ë°-ì„±ëŠ¥-ìµœì í™”)
- [ì‹¤ë¬´ ì‚¬ë¡€ ë° íŒ¨í„´](#ì‹¤ë¬´-ì‚¬ë¡€-ë°-íŒ¨í„´)
- [ì£¼ì˜ì‚¬í•­ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](#ì£¼ì˜ì‚¬í•­-ë°-ë² ìŠ¤íŠ¸-í”„ë™í‹°ìŠ¤)
- [ì°¸ê³  ìë£Œ](#ì°¸ê³ -ìë£Œ)

---

## ğŸ¯ ë°°ê²½

í˜„ëŒ€ì˜ ì›¹ ì„œë¹„ìŠ¤ëŠ” ì´ˆë‹¹ ìˆ˜ë§Œ, ìˆ˜ì‹­ë§Œ ê±´ì˜ API ìš”ì²­ì„ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ìƒí™©ì— ì§ë©´í•©ë‹ˆë‹¤.

### ğŸ“Œ ì‹¤ì œ ì‚¬ë¡€

| ì„œë¹„ìŠ¤ ìœ í˜• | ì²˜ë¦¬ ê·œëª¨ | ì£¼ìš” ë„ì „ ê³¼ì œ |
|------------|----------|--------------|
| **ì†Œì…œ ë¯¸ë””ì–´** | ìˆ˜ì–µ ëª… ë™ì‹œ ì ‘ì† | í”¼ë“œ ì¡°íšŒ, ì‹¤ì‹œê°„ ì•Œë¦¼ |
| **ì „ììƒê±°ë˜** | ì´ˆë‹¹ ìˆ˜ì‹­ë§Œ ê±´ ìš”ì²­ | ì„¸ì¼ ê¸°ê°„ íŠ¸ë˜í”½ ê¸‰ì¦ |
| **ê¸ˆìœµ ì„œë¹„ìŠ¤** | ì‹¤ì‹œê°„ ê±°ë˜ ì²˜ë¦¬ | ì •í™•ì„±ê³¼ ì†ë„ ë™ì‹œ ë³´ì¥ |
| **ê²Œì„ ì„œë²„** | ìˆ˜ë°±ë§Œ ëª… ë™ì‹œ í”Œë ˆì´ | ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš©, ë‚®ì€ ì§€ì—°ì‹œê°„ |

> ğŸ’¡ **í•µì‹¬:** ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¨ìˆœí•œ ì„œë²„ ì¦ì„¤ì„ ë„˜ì–´ **ì•„í‚¤í…ì²˜ ìˆ˜ì¤€ì˜ ìµœì í™”**ê°€ í•„ìš”í•©ë‹ˆë‹¤.

---

## âš ï¸ ëŒ€ìš©ëŸ‰ API ì²˜ë¦¬ì˜ ë„ì „ ê³¼ì œ

ëŒ€ê·œëª¨ API ì„œë¹„ìŠ¤ë¥¼ ìš´ì˜í•  ë•Œ ì§ë©´í•˜ëŠ” ì£¼ìš” ë¬¸ì œë“¤ì„ ì‚´í´ë´…ë‹ˆë‹¤.

### 1ï¸âƒ£ íŠ¸ë˜í”½ ê¸‰ì¦ (Traffic Spike)

**ğŸ“Š ë¬¸ì œ ìƒí™©:**

```
ì •ìƒ ìƒíƒœ: ì´ˆë‹¹ 1,000ê±´ ìš”ì²­
   â†“
ì´ë²¤íŠ¸ ë°œìƒ (ì˜ˆ: ì„¸ì¼, í‹°ì¼“íŒ…)
   â†“
ê¸‰ì¦: ì´ˆë‹¹ 100,000ê±´ ìš”ì²­ âš¡ (100ë°°!)
```

**ğŸ’¥ ë°œìƒí•˜ëŠ” ë¬¸ì œ:**

| ë¬¸ì œ | ì¦ìƒ | ì˜í–¥ |
|------|------|------|
| **ì‘ë‹µ ì§€ì—°** | 100ms â†’ 10,000ms | ì‚¬ìš©ì ê²½í—˜ ì €í•˜ |
| **ì—°ê²° ê±°ë¶€** | Connection Refused | ì„œë¹„ìŠ¤ ì´ìš© ë¶ˆê°€ |
| **íƒ€ì„ì•„ì›ƒ** | Request Timeout | ì‚¬ìš©ì ì´íƒˆ ì¦ê°€ |
| **ì„œë²„ ë‹¤ìš´** | 500 Internal Error | ì „ì²´ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ |

---

### 2ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ë³‘ëª© í˜„ìƒ

**ğŸ”„ ì¼ë°˜ì ì¸ ì‹œë‚˜ë¦¬ì˜¤:**

```
ì‚¬ìš©ì ìš”ì²­ â†’ API ì„œë²„ â†’ ë°ì´í„°ë² ì´ìŠ¤
                â†“           â†“
          ì‘ë‹µ ë¹ ë¦„      ì‘ë‹µ ëŠë¦¼ (ë³‘ëª©!)
```

**âš¡ ì„±ëŠ¥ ì°¨ì´:**

| ì €ì¥ì†Œ íƒ€ì… | ì‘ë‹µ ì‹œê°„ | ìƒëŒ€ì  ì†ë„ |
|------------|----------|------------|
| **ë©”ëª¨ë¦¬ (RAM)** | 0.1Î¼s | ê¸°ì¤€ |
| **SSD** | 0.1ms | 1,000ë°° ëŠë¦¼ |
| **HDD** | 5-10ms | 50,000~100,000ë°° ëŠë¦¼ |

---

### 3ï¸âƒ£ ì™¸ë¶€ API ì˜ì¡´ì„±

**ğŸ”— ë°œìƒí•˜ëŠ” ë¬¸ì œ:**

```
ë‚´ë¶€ API â†’ ì™¸ë¶€ API í˜¸ì¶œ
    â†“           â†“
  ë¹ ë¦„      ëŠë¦¬ê±°ë‚˜ ì¥ì• 
    â†“
ì „ì²´ ì„œë¹„ìŠ¤ ì§€ì—°/ì¥ì• 
```

**ì£¼ìš” ë¦¬ìŠ¤í¬:**

- ğŸŒ **ë„¤íŠ¸ì›Œí¬ ì§€ì—°**: 50-200ms ì¶”ê°€ ì§€ì—°
- ğŸš« **Rate Limit**: API í˜¸ì¶œ íšŸìˆ˜ ì œí•œ
- ğŸ’” **ì¥ì•  ì „íŒŒ**: ì™¸ë¶€ API ë‹¤ìš´ â†’ ì „ì²´ ì„œë¹„ìŠ¤ ì˜í–¥
- ğŸ’° **ë¹„ìš© ì¦ê°€**: í˜¸ì¶œ íšŸìˆ˜ì— ë”°ë¥¸ ê³¼ê¸ˆ

---

### 4ï¸âƒ£ ë™ì‹œì„± ë¬¸ì œ (Race Condition)

**âš”ï¸ ì „í˜•ì ì¸ ì˜ˆì‹œ:**

```
ì‹œê°„ì¶• â†’

T1: ì‚¬ìš©ì Aê°€ ì¬ê³  í™•ì¸ (ì¬ê³ : 1ê°œ)
T2: ì‚¬ìš©ì Bê°€ ì¬ê³  í™•ì¸ (ì¬ê³ : 1ê°œ) â† ì•„ì§ Aê°€ ì°¨ê° ì „
T3: ì‚¬ìš©ì A ì£¼ë¬¸ ì™„ë£Œ (ì¬ê³ : 0ê°œ)
T4: ì‚¬ìš©ì B ì£¼ë¬¸ ì™„ë£Œ (ì¬ê³ : -1ê°œ) âŒ ë¬¸ì œ ë°œìƒ!
```

**í•´ê²° ë°©ë²•:**
- ğŸ”’ ë¶„ì‚° ë½ (Distributed Lock) ì‚¬ìš©
- âš›ï¸ ì›ìì  ì—°ì‚° (Atomic Operation) í™œìš©
- ğŸ”„ ë‚™ê´€ì  ì ê¸ˆ (Optimistic Locking) êµ¬í˜„

---

## ğŸ—ï¸ í´ëŸ¬ìŠ¤í„° ì•„í‚¤í…ì²˜

ì—¬ëŸ¬ ëŒ€ì˜ ì»´í“¨í„°(ë…¸ë“œ)ë¥¼ ê²°í•©í•˜ì—¬ ë‹¨ì¼ ì‹œìŠ¤í…œì²˜ëŸ¼ ë™ì‘í•˜ê²Œ ë§Œë“œëŠ” ë¶„ì‚° ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ğŸ“Œ í´ëŸ¬ìŠ¤í„°ì˜ í•µì‹¬ ê°€ì¹˜

| íŠ¹ì§• | ì„¤ëª… | íš¨ê³¼ |
|------|------|------|
| **ê³ ê°€ìš©ì„±** | ì‹œìŠ¤í…œ ì¥ì•  ì‹œì—ë„ ì„œë¹„ìŠ¤ ì§€ì† | 99.99% ê°€ë™ë¥  |
| **í™•ì¥ì„±** | í•„ìš”ì— ë”°ë¼ ë…¸ë“œ ì¶”ê°€/ì œê±° | ìœ ì—°í•œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ |
| **ì„±ëŠ¥ í–¥ìƒ** | ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì „ì²´ ì„±ëŠ¥ í–¥ìƒ | ì²˜ë¦¬ëŸ‰ Në°° ì¦ê°€ |

---

### 1ï¸âƒ£ ê³ ê°€ìš©ì„± êµ¬ì„± ë°©ì‹

#### ğŸ”„ Active-Active êµ¬ì„±

```
          ë¡œë“œ ë°¸ëŸ°ì„œ
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚         â”‚
  ì„œë²„1     ì„œë²„2     ì„œë²„3
  (Active) (Active) (Active)
   100%     100%     100%
```

**âœ… ì¥ì :**
- ëª¨ë“  ì„œë²„ê°€ ë™ì‹œì— íŠ¸ë˜í”½ ì²˜ë¦¬
- í•œ ì„œë²„ ì¥ì•  ì‹œ ë‹¤ë¥¸ ì„œë²„ë¡œ ìë™ ì „í™˜
- ìµœëŒ€ ë¦¬ì†ŒìŠ¤ í™œìš© (100% í™œìš©ë¥ )

**âŒ ë‹¨ì :**
- ì„¸ì…˜ ê³µìœ  í•„ìš”
- ë°ì´í„° ë™ê¸°í™” ë³µì¡

---

#### â¸ï¸ Active-Standby êµ¬ì„±

```
  Primary Server    Standby Server
      (Active)        (ëŒ€ê¸° ì¤‘)
       100%              0%
         â”‚                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       (Heartbeat ì²´í¬)
```

**âœ… ì¥ì :**
- ì¦‰ì‹œ ì¥ì•  ë³µêµ¬
- ë°ì´í„° ì¼ê´€ì„± ìœ ì§€ ìš©ì´
- ì•ˆì •ì ì¸ Failover

**âŒ ë‹¨ì :**
- ë¦¬ì†ŒìŠ¤ ë‚­ë¹„ (Standby ì„œë²„ ìœ íœ´)
- ë¹„ìš© ì¦ê°€

---

### 2ï¸âƒ£ í™•ì¥ ì „ëµ

#### ğŸ“Š ìˆ˜ì§ í™•ì¥ vs ìˆ˜í‰ í™•ì¥

| ë¹„êµ í•­ëª© | ìˆ˜ì§ í™•ì¥ (Scale Up) | ìˆ˜í‰ í™•ì¥ (Scale Out) |
|----------|-------------------|---------------------|
| **ë°©ë²•** | CPU/RAM ì—…ê·¸ë ˆì´ë“œ | ì„œë²„ ëŒ€ìˆ˜ ì¦ê°€ |
| **ë¹„ìš©** | ë¹„ì„ í˜• ì¦ê°€ ğŸ’°ğŸ’°ğŸ’° | ì„ í˜• ì¦ê°€ ğŸ’° |
| **í•œê³„** | ë¬¼ë¦¬ì  í•œê³„ ìˆìŒ | ê±°ì˜ ë¬´ì œí•œ |
| **ìœ ì—°ì„±** | ë‚®ìŒ (êµì²´ í•„ìš”) | ë†’ìŒ (ì¶”ê°€/ì œê±° ììœ ) |
| **ë³µì¡ë„** | ë‚®ìŒ | ë†’ìŒ (ë¶„ì‚° ì²˜ë¦¬) |

#### ğŸ“ˆ ìˆ˜í‰ í™•ì¥ ì‹œë‚˜ë¦¬ì˜¤

```
ğŸ“ ì´ˆê¸°
[ì„œë²„1] 
ì²˜ë¦¬ëŸ‰: 1,000 req/s
   â†“
ğŸ“ íŠ¸ë˜í”½ 3ë°° ì¦ê°€
[ì„œë²„1][ì„œë²„2][ì„œë²„3]
ì²˜ë¦¬ëŸ‰: 3,000 req/s (3ë°°)
   â†“
ğŸ“ ì¶”ê°€ í™•ì¥
[ì„œë²„1][ì„œë²„2][ì„œë²„3][ì„œë²„4][ì„œë²„5]
ì²˜ë¦¬ëŸ‰: 5,000 req/s (5ë°°)
```

> ğŸ’¡ **ê²°ë¡ :** ëŒ€ë¶€ë¶„ì˜ í˜„ëŒ€ ì›¹ ì„œë¹„ìŠ¤ëŠ” **ìˆ˜í‰ í™•ì¥**ì„ ì„ í˜¸í•©ë‹ˆë‹¤.

---

### 3ï¸âƒ£ ìƒ¤ë”© (Sharding)

ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ë…¸ë“œì— ë¶„ì‚° ì €ì¥í•˜ì—¬ ë¶€í•˜ë¥¼ ë¶„ì‚°ì‹œí‚µë‹ˆë‹¤.

```javascript
// í•´ì‹œ ê¸°ë°˜ ìƒ¤ë”©
function getShardKey(userId) {
  return userId % 4; // 4ê°œì˜ ìƒ¤ë“œë¡œ ë¶„ì‚°
}

// ì‚¬ìš©ì IDê°€ 123ì¸ ê²½ìš°
const shardKey = 123 % 4; // = 3
// â†’ Shard 3ì— ë°ì´í„° ì €ì¥
```

#### ğŸ“‹ ìƒ¤ë”© ì „ëµ ë¹„êµ

| ì „ëµ | ë°©ì‹ | ì¥ì  | ë‹¨ì  | ì í•©í•œ ê²½ìš° |
|------|------|------|------|------------|
| **í•´ì‹œ ìƒ¤ë”©** | `userId % N` | ê· ë“± ë¶„ì‚° | í™•ì¥ ì‹œ ì¬ë°°ì¹˜ | ê· ë“±í•œ ë¶„ì‚°ì´ ì¤‘ìš”í•œ ê²½ìš° |
| **ë²”ìœ„ ìƒ¤ë”©** | `0-1000`, `1001-2000` | ê°„ë‹¨í•œ êµ¬í˜„ | í•«ìŠ¤íŒŸ ìœ„í—˜ | ìˆœì°¨ì  ë°ì´í„° |
| **ì§€ì—­ ê¸°ë°˜** | ì§€ë¦¬ì  ìœ„ì¹˜ | ë‚®ì€ ì§€ì—°ì‹œê°„ | ë¶ˆê· ë“± ë¶„ì‚° | ê¸€ë¡œë²Œ ì„œë¹„ìŠ¤ |

---

## âŒ Redis ì—†ì´ ì§ì ‘ API í˜¸ì¶œ ì‹œ ë¬¸ì œì 

ìºì‹± ì—†ì´ ì§ì ‘ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ì™¸ë¶€ APIë¥¼ í˜¸ì¶œí•  ë•Œ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤ì„ ì‚´í´ë´…ë‹ˆë‹¤.

### 1. ë¶€í•˜ ì§‘ì¤‘ ë° ì„œë²„ ê³¼ë¶€í•˜

**ì‹œë‚˜ë¦¬ì˜¤:**
```
1,000ëª…ì˜ ì‚¬ìš©ìê°€ ë™ì‹œì— ê°™ì€ ìƒí’ˆ ì •ë³´ ìš”ì²­
  â†“
API ì„œë²„ê°€ 1,000ë²ˆ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
  â†“
ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê³ ê°ˆ (Connection Pool Exhausted)
  â†“
ì„œë²„ íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ë‹¤ìš´
```

**ì‹¤ì œ ì˜í–¥:**
- **ì‘ë‹µ ì‹œê°„**: 100ms â†’ 10,000ms (100ë°° ì¦ê°€)
- **CPU ì‚¬ìš©ë¥ **: 30% â†’ 100%
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: ì •ìƒ â†’ OOM (Out of Memory)
- **ì—°ê²° ëŒ€ê¸°**: ìˆ˜ì²œ ê°œì˜ ìš”ì²­ì´ íì— ëŒ€ê¸°

### 2. í™•ì¥ì„± ì œí•œ

**ë¬¸ì œ:**
ì„œë²„ë¥¼ ì¦ì„¤í•´ë„ ë°ì´í„°ë² ì´ìŠ¤ê°€ ë³‘ëª©ì´ ë˜ë©´ íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤.

```
AS-IS:
[API ì„œë²„ 1ëŒ€] â†’ [DB] â† ë³‘ëª© ë°œìƒ

TO-BE (ë¹„íš¨ìœ¨ì ):
[API ì„œë²„ 10ëŒ€] â†’ [DB] â† ì—¬ì „íˆ ë³‘ëª©
```

**ë¹„ìš© ì¦ê°€:**
- ì„œë²„ 10ë°° ì¦ì„¤ â†’ ì„±ëŠ¥ì€ 2ë°°ë§Œ í–¥ìƒ
- ROI(íˆ¬ì ëŒ€ë¹„ íš¨ê³¼) ê¸‰ê²©íˆ ê°ì†Œ

### 3. ë°ì´í„° ë¶ˆì¼ì¹˜ ë¬¸ì œ

**ë™ì‹œì„± ë¬¸ì œ ì˜ˆì‹œ:**

```javascript
// ì‚¬ìš©ì Aì™€ Bê°€ ë™ì‹œì— í¬ì¸íŠ¸ ì°¨ê°
// í˜„ì¬ í¬ì¸íŠ¸: 1000

// ì‚¬ìš©ì Aì˜ ìš”ì²­
const pointsA = await db.query('SELECT points FROM users WHERE id = 1');
// pointsA = 1000
await sleep(100); // ì²˜ë¦¬ ì§€ì—°
await db.query('UPDATE users SET points = ? WHERE id = 1', [pointsA - 500]);
// ìµœì¢…: 500

// ì‚¬ìš©ì Bì˜ ìš”ì²­ (ë™ì‹œ ì§„í–‰)
const pointsB = await db.query('SELECT points FROM users WHERE id = 1');
// pointsB = 1000 (ì•„ì§ Aì˜ ì—…ë°ì´íŠ¸ ì „)
await db.query('UPDATE users SET points = ? WHERE id = 1', [pointsB - 300]);
// ìµœì¢…: 700 â† Bì˜ ì—…ë°ì´íŠ¸ê°€ Aë¥¼ ë®ì–´ì”€!

// ì‹¤ì œ ê²°ê³¼: 700 (ì˜ˆìƒ: 200)
```

### 4. ì¤‘ë³µ í˜¸ì¶œ ë° ë¹„ìš© ë‚­ë¹„

**ì™¸ë¶€ API í˜¸ì¶œ ì˜ˆì‹œ:**

```javascript
// í™˜ìœ¨ ì •ë³´ë¥¼ ì™¸ë¶€ APIì—ì„œ ì¡°íšŒ
// 100ëª…ì´ ë™ì‹œì— USD â†’ KRW í™˜ìœ¨ ì¡°íšŒ

for (let i = 0; i < 100; i++) {
  const rate = await externalAPI.getExchangeRate('USD', 'KRW');
  // ë™ì¼í•œ ë°ì´í„°ë¥¼ 100ë²ˆ ì¡°íšŒ!
}

// ë¬¸ì œì :
// 1. ì™¸ë¶€ API í˜¸ì¶œ ë¹„ìš©: $0.001 Ã— 100 = $0.10
// 2. ë„¤íŠ¸ì›Œí¬ ì§€ì—°: 200ms Ã— 100 = 20ì´ˆ
// 3. Rate Limit ë„ë‹¬ ìœ„í—˜
```

### 5. Thundering Herd ë¬¸ì œ

ìºì‹œê°€ ë§Œë£Œë˜ëŠ” ìˆœê°„ ëŒ€ëŸ‰ì˜ ìš”ì²­ì´ ë™ì‹œì— DBë¡œ ëª°ë¦¬ëŠ” í˜„ìƒ:

```
T=0: ìºì‹œ ë§Œë£Œ
T=0.001: 1000ê°œ ìš”ì²­ ë™ì‹œ ë„ì°©
         â†“
    ëª¨ë‘ ìºì‹œ ë¯¸ìŠ¤
         â†“
    1000ê°œ DB ì¿¼ë¦¬ ë™ì‹œ ì‹¤í–‰
         â†“
    ë°ì´í„°ë² ì´ìŠ¤ ê³¼ë¶€í•˜!
```

---

## âœ… Redisë¥¼ í™œìš©í•œ í•´ê²° ë°©ë²•

### ğŸ¯ Redisë€?

**Redis (REmote DIctionary Server)**ëŠ” ì¸ë©”ëª¨ë¦¬ ë°ì´í„° êµ¬ì¡° ì €ì¥ì†Œë¡œ, ëŒ€ëŸ‰ API ì²˜ë¦¬ì˜ í•µì‹¬ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

---

### ğŸ“Œ í•µì‹¬ íŠ¹ì§•

#### 1ï¸âƒ£ ì¸ë©”ëª¨ë¦¬ ê¸°ë°˜ - ì••ë„ì ì¸ ì†ë„

| ì €ì¥ì†Œ | ì²˜ë¦¬ëŸ‰ | ì‘ë‹µ ì‹œê°„ |
|--------|--------|----------|
| **ë””ìŠ¤í¬ DB** | 10,000 read/s | 5-10ms |
| **Redis** | 100,000+ read/s âš¡ | 0.1-1ms |

> ğŸ’¡ **10ë°° ì´ìƒì˜ ì„±ëŠ¥ ì°¨ì´!**

---

#### 2ï¸âƒ£ ë‹¤ì–‘í•œ ë°ì´í„° êµ¬ì¡°

| ë°ì´í„° êµ¬ì¡° | ìš©ë„ | ì‚¬ìš© ì˜ˆì‹œ |
|-----------|------|----------|
| **String** | ë‹¨ìˆœ í‚¤-ê°’ | ì„¸ì…˜, ìºì‹œ |
| **Hash** | ê°ì²´ ì €ì¥ | ì‚¬ìš©ì ì •ë³´ |
| **List** | í, ìŠ¤íƒ | ì‘ì—… í, ìµœê·¼ í•­ëª© |
| **Set** | ì¤‘ë³µ ì œê±° | ì¢‹ì•„ìš”, íƒœê·¸ |
| **Sorted Set** | ìˆœìœ„ | ë¦¬ë”ë³´ë“œ, ë­í‚¹ |
| **Bitmap** | ë¶ˆë¦° ë°°ì—´ | ì¶œì„ ì²´í¬, ìƒíƒœ í”Œë˜ê·¸ |
| **HyperLogLog** | ì¹´ë””ë„ë¦¬í‹° | ìˆœ ë°©ë¬¸ì ìˆ˜ ì¶”ì • |

---

#### 3ï¸âƒ£ ì›ìì  ì—°ì‚° (Atomic Operations)

```redis
# ë™ì‹œì„± ë¬¸ì œë¥¼ ì›ìì ìœ¼ë¡œ í•´ê²°
INCR counter              # ì›ìì  ì¦ê°€ (ì¡°íšŒìˆ˜, ì¢‹ì•„ìš”)
DECR counter              # ì›ìì  ê°ì†Œ (ì¬ê³  ì°¨ê°)
SETNX key value           # ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œë§Œ ì„¤ì • (ë¶„ì‚° ë½)
HINCRBY user:123 points 10 # íŠ¹ì • í•„ë“œë§Œ ì¦ê°€
```

### Redisê°€ ëŒ€ëŸ‰ API ì²˜ë¦¬ì— ì í•©í•œ ì´ìœ 

#### 1. ê·¹ë„ë¡œ ë¹ ë¥¸ ì‘ë‹µ ì†ë„

**ì„±ëŠ¥ ë¹„êµ:**
```
MySQL ì¿¼ë¦¬:     10-50ms
Redis ì¡°íšŒ:     0.1-1ms (10ë°° ~ 500ë°° ë¹ ë¦„)
```

**ì‹¤ì œ ì˜í–¥:**
```
1,000ê±´ ì¡°íšŒ ì‹œ:
MySQL: 10ms Ã— 1,000 = 10,000ms (10ì´ˆ)
Redis: 0.1ms Ã— 1,000 = 100ms (0.1ì´ˆ)
```

#### 2. ìºì‹±ì„ í†µí•œ ë¶€í•˜ ê°ì†Œ

**ìºì‹œ íˆíŠ¸ìœ¨ì— ë”°ë¥¸ íš¨ê³¼:**
```
ìºì‹œ íˆíŠ¸ìœ¨ 90% ê°€ì •:
  100,000 ìš”ì²­
    â†“
  90,000 ìš”ì²­ â†’ Redis (0.1ms)
  10,000 ìš”ì²­ â†’ DB (10ms)
    â†“
  ì´ ì²˜ë¦¬ ì‹œê°„: 90 + 100,000 = 100,090ms

ìºì‹œ ì—†ì´:
  100,000 ìš”ì²­ â†’ DB (10ms)
    â†“
  ì´ ì²˜ë¦¬ ì‹œê°„: 1,000,000ms (10ë°° ì´ìƒ ì°¨ì´!)
```

#### 3. ë¶„ì‚° ë½ (Distributed Lock)

**ë™ì‹œì„± ì œì–´:**
```javascript
// Redisë¥¼ ì‚¬ìš©í•œ ë¶„ì‚° ë½
const lock = await redis.set('lock:user:123', 'locked', 'NX', 'EX', 10);

if (lock) {
  try {
    // ì„ê³„ ì˜ì—­: ë™ì‹œì— í•œ í”„ë¡œì„¸ìŠ¤ë§Œ ì‹¤í–‰
    const points = await redis.get('user:123:points');
    await redis.set('user:123:points', points - 100);
  } finally {
    await redis.del('lock:user:123');
  }
}
```

#### 4. Pub/Subë¥¼ í†µí•œ ì‹¤ì‹œê°„ í†µì‹ 

**ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ:**
```javascript
// Publisher
await redis.publish('notifications', JSON.stringify({
  userId: 123,
  message: 'ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ë„ì°©í–ˆìŠµë‹ˆë‹¤'
}));

// Subscriber
await redis.subscribe('notifications', (message) => {
  const data = JSON.parse(message);
  sendPushNotification(data.userId, data.message);
});
```

#### 5. ë©”ì‹œì§€ íë¡œ í™œìš©

**ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬:**
```javascript
// ì‘ì—…ì„ íì— ì¶”ê°€
await redis.lpush('job:queue', JSON.stringify({
  type: 'sendEmail',
  to: 'user@example.com',
  subject: 'í™˜ì˜í•©ë‹ˆë‹¤'
}));

// ì›Œì»¤ê°€ ì‘ì—… ì²˜ë¦¬
while (true) {
  const job = await redis.brpop('job:queue', 0);
  await processJob(JSON.parse(job[1]));
}
```

---

## ğŸ’¾ Redis ìºì‹± ì „ëµ

ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ íŠ¹ì„±ì— ë§ëŠ” ìºì‹± ì „ëµì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

### ğŸ“Š ì „ëµ ë¹„êµí‘œ

| ì „ëµ | ì½ê¸° ì„±ëŠ¥ | ì“°ê¸° ì„±ëŠ¥ | ì¼ê´€ì„± | ë³µì¡ë„ | ì í•©í•œ ê²½ìš° |
|------|----------|----------|--------|--------|------------|
| **Cache-Aside** | â­â­â­ | â­â­â­ | â­â­ | â­ | ì½ê¸° ìœ„ì£¼ |
| **Write-Through** | â­â­â­ | â­â­ | â­â­â­ | â­â­ | ì¼ê´€ì„± ì¤‘ìš” |
| **Write-Behind** | â­â­â­ | â­â­â­â­â­ | â­ | â­â­â­ | ì“°ê¸° ë§ìŒ |
| **Refresh-Ahead** | â­â­â­â­ | â­â­â­ | â­â­â­ | â­â­â­ | ì˜ˆì¸¡ ê°€ëŠ¥ |

---

### 1ï¸âƒ£ Cache-Aside (Lazy Loading)

**ğŸ¯ ê°œë…:** ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ìºì‹œë¥¼ ì§ì ‘ ê´€ë¦¬í•˜ëŠ” ê°€ì¥ ì¼ë°˜ì ì¸ íŒ¨í„´ì…ë‹ˆë‹¤.

**ë™ì‘ íë¦„:**
```javascript
async function getUser(userId) {
  // 1. ìºì‹œ í™•ì¸
  let user = await redis.get(`user:${userId}`);
  
  if (user) {
    return JSON.parse(user); // ìºì‹œ íˆíŠ¸
  }
  
  // 2. ìºì‹œ ë¯¸ìŠ¤ - DB ì¡°íšŒ
  user = await db.query('SELECT * FROM users WHERE id = ?', [userId]);
  
  // 3. ìºì‹œì— ì €ì¥
  await redis.setex(`user:${userId}`, 3600, JSON.stringify(user));
  
  return user;
}
```

**âœ… ì¥ì :**
- êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì 
- í•„ìš”í•œ ë°ì´í„°ë§Œ ìºì‹œì— ì €ì¥ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
- ìºì‹œ ì¥ì•  ì‹œì—ë„ ì„œë¹„ìŠ¤ ê°€ëŠ¥ (DBë¡œ Fallback)

**âŒ ë‹¨ì :**
- ì²« ìš”ì²­ì€ ëŠë¦¼ (ìºì‹œ ë¯¸ìŠ¤)
- ìºì‹œì™€ DB ê°„ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±

**ğŸ’¡ ì í•©í•œ ê²½ìš°:**
- ì½ê¸°ê°€ ë§ì€ ì‹œìŠ¤í…œ
- ë°ì´í„° ë³€ê²½ì´ ìì£¼ ì—†ëŠ” ê²½ìš°
- ì˜ˆ: ìƒí’ˆ ì •ë³´, ê²Œì‹œê¸€ ì¡°íšŒ

---

### 2ï¸âƒ£ Write-Through

**ğŸ¯ ê°œë…:** ì“°ê¸° ì‹œ ìºì‹œì™€ DBë¥¼ ë™ì‹œì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

```javascript
async function updateUser(userId, data) {
  // 1. DB ì—…ë°ì´íŠ¸
  await db.query('UPDATE users SET name = ? WHERE id = ?', [data.name, userId]);
  
  // 2. ìºì‹œ ì—…ë°ì´íŠ¸
  await redis.setex(`user:${userId}`, 3600, JSON.stringify(data));
  
  return data;
}
```

**âœ… ì¥ì :**
- ìºì‹œì™€ DB ì¼ê´€ì„± ìœ ì§€
- ì½ê¸° ì„±ëŠ¥ ìµœì í™”
- ìºì‹œ ì›Œë° íš¨ê³¼

**âŒ ë‹¨ì :**
- ì“°ê¸° ì§€ì—° ì‹œê°„ ì¦ê°€ (ë‘ ë²ˆ ì €ì¥)
- ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë„ ìºì‹œì— ì €ì¥

**ğŸ’¡ ì í•©í•œ ê²½ìš°:**
- ë°ì´í„° ì¼ê´€ì„±ì´ ì¤‘ìš”í•œ ì‹œìŠ¤í…œ
- ì½ê¸° ë¹„ì¤‘ì´ ë§¤ìš° ë†’ì€ ê²½ìš°
- ì˜ˆ: ì„¤ì • ì •ë³´, ë©”íƒ€ë°ì´í„°

---

### 3ï¸âƒ£ Write-Behind (Write-Back)

**ğŸ¯ ê°œë…:** ìºì‹œì—ë§Œ ë¨¼ì € ì“°ê³ , ë‚˜ì¤‘ì— ë¹„ë™ê¸°ë¡œ DBì— ë°˜ì˜í•©ë‹ˆë‹¤.

```javascript
async function updateUserPoints(userId, points) {
  // 1. ìºì‹œì—ë§Œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
  await redis.incrby(`user:${userId}:points`, points);
  
  // 2. ë³€ê²½ ë‚´ì—­ì„ íì— ì¶”ê°€
  await redis.lpush('update:queue', JSON.stringify({
    type: 'updatePoints',
    userId,
    points
  }));
  
  // 3. ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ê°€ ì£¼ê¸°ì ìœ¼ë¡œ DB ì—…ë°ì´íŠ¸
}

// ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤
setInterval(async () => {
  const updates = await redis.lrange('update:queue', 0, 99);
  
  for (const update of updates) {
    const data = JSON.parse(update);
    await db.query('UPDATE users SET points = points + ? WHERE id = ?', 
                   [data.points, data.userId]);
  }
  
  await redis.ltrim('update:queue', updates.length, -1);
}, 5000); // 5ì´ˆë§ˆë‹¤ ì‹¤í–‰
```

**âœ… ì¥ì :**
- ì“°ê¸° ì„±ëŠ¥ ê·¹ëŒ€í™”
- ëŒ€ëŸ‰ ì—…ë°ì´íŠ¸ ì‹œ DB ë¶€í•˜ ê°ì†Œ (ë°°ì¹˜ ì²˜ë¦¬)
- ì¦‰ê°ì ì¸ ì‘ë‹µ

**âŒ ë‹¨ì :**
- ìºì‹œ ì¥ì•  ì‹œ ë°ì´í„° ì†ì‹¤ ìœ„í—˜
- êµ¬í˜„ ë³µì¡ë„ ë†’ìŒ
- ì¼ì‹œì  ë°ì´í„° ë¶ˆì¼ì¹˜

**ğŸ’¡ ì í•©í•œ ê²½ìš°:**
- ì“°ê¸°ê°€ ë§¤ìš° ë§ì€ ì‹œìŠ¤í…œ
- ì˜ˆ: ì¡°íšŒìˆ˜, ì¢‹ì•„ìš” ìˆ˜, ì‹¤ì‹œê°„ í†µê³„
- ì¼ì‹œì  ë°ì´í„° ì†ì‹¤ì„ í—ˆìš©í•  ìˆ˜ ìˆëŠ” ê²½ìš°

---

### 4ï¸âƒ£ Refresh-Ahead

**ğŸ¯ ê°œë…:** ìºì‹œ ë§Œë£Œ ì „ì— ë¯¸ë¦¬ ê°±ì‹ í•˜ì—¬ í•­ìƒ ìµœì‹  ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

```javascript
async function getProductWithRefresh(productId) {
  const cacheKey = `product:${productId}`;
  const ttl = await redis.ttl(cacheKey);
  
  let product = await redis.get(cacheKey);
  
  // TTLì´ 5ë¶„ ë¯¸ë§Œì´ë©´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê°±ì‹ 
  if (ttl < 300) {
    // ë¹„ë™ê¸°ë¡œ ê°±ì‹  (ìš”ì²­ì€ ì¦‰ì‹œ ë°˜í™˜)
    refreshCache(productId).catch(console.error);
  }
  
  if (!product) {
    product = await db.query('SELECT * FROM products WHERE id = ?', [productId]);
    await redis.setex(cacheKey, 3600, JSON.stringify(product));
  }
  
  return JSON.parse(product);
}

async function refreshCache(productId) {
  const product = await db.query('SELECT * FROM products WHERE id = ?', [productId]);
  await redis.setex(`product:${productId}`, 3600, JSON.stringify(product));
}
```

**âœ… ì¥ì :**
- Thundering Herd ë¬¸ì œ ë°©ì§€
- í•­ìƒ ìµœì‹  ë°ì´í„° ì œê³µ
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì„±ëŠ¥

**âŒ ë‹¨ì :**
- ì˜ˆì¸¡ ë¡œì§ í•„ìš” (ì–´ë–¤ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ê°±ì‹ í• ì§€)
- ë¶ˆí•„ìš”í•œ ê°±ì‹  ê°€ëŠ¥ì„±
- ì¶”ê°€ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©

**ğŸ’¡ ì í•©í•œ ê²½ìš°:**
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì•¡ì„¸ìŠ¤ íŒ¨í„´
- ìºì‹œ ë§Œë£Œë¡œ ì¸í•œ ì§€ì—°ì„ í”¼í•´ì•¼ í•˜ëŠ” ê²½ìš°
- ì˜ˆ: ì¸ê¸° ìƒí’ˆ, ì‹¤ì‹œê°„ ë­í‚¹

---

### 5ï¸âƒ£ Cache Stampede ë°©ì§€ ì „ëµ

**Stampede ë¬¸ì œ:**
```
ìºì‹œ ë§Œë£Œ ì‹œì ì— 1000ê°œ ìš”ì²­ ë™ì‹œ ë„ì°©
  â†“
ëª¨ë‘ DB ì ‘ê·¼ ì‹œë„
  â†“
DB ê³¼ë¶€í•˜!
```

**í•´ê²° ë°©ë²•: ë¶„ì‚° ë½ ì‚¬ìš©**
```javascript
async function getDataWithLock(key) {
  let data = await redis.get(key);
  
  if (data) {
    return JSON.parse(data);
  }
  
  // ë½ íšë“ ì‹œë„
  const lockKey = `lock:${key}`;
  const lockAcquired = await redis.set(lockKey, '1', 'NX', 'EX', 10);
  
  if (lockAcquired) {
    try {
      // ë½ì„ íšë“í•œ í”„ë¡œì„¸ìŠ¤ë§Œ DB ì¡°íšŒ
      data = await db.query('SELECT ...');
      await redis.setex(key, 3600, JSON.stringify(data));
      return data;
    } finally {
      await redis.del(lockKey);
    }
  } else {
    // ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°
    await sleep(100);
    return getDataWithLock(key); // ì¬ì‹œë„
  }
}
```

---

## Redis í´ëŸ¬ìŠ¤í„° êµ¬ì„±

### Redis í´ëŸ¬ìŠ¤í„°ì˜ í•„ìš”ì„±

**ë‹¨ì¼ Redis ì¸ìŠ¤í„´ìŠ¤ì˜ í•œê³„:**
- **ë©”ëª¨ë¦¬ ì œí•œ**: ë‹¨ì¼ ì„œë²„ì˜ RAM ìš©ëŸ‰ì— ì œí•œ
- **ë‹¨ì¼ ì¥ì• ì **: Redis ë‹¤ìš´ ì‹œ ì „ì²´ ì„œë¹„ìŠ¤ ì˜í–¥
- **ì²˜ë¦¬ëŸ‰ í•œê³„**: ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ì˜ ì²˜ë¦¬ ëŠ¥ë ¥ í•œê³„

### 1. Master-Slave ë³µì œ (Replication)

**ì•„í‚¤í…ì²˜:**
```
    Master (ì“°ê¸°)
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
   â”‚       â”‚
Slave1  Slave2 (ì½ê¸°)
```

**ì„¤ì •:**
```bash
# redis-master.conf
port 6379
bind 0.0.0.0

# redis-slave1.conf
port 6380
bind 0.0.0.0
replicaof 127.0.0.1 6379

# redis-slave2.conf
port 6381
bind 0.0.0.0
replicaof 127.0.0.1 6379
```

**ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ:**
```javascript
const Redis = require('ioredis');

// ì“°ê¸°ëŠ” Masterë¡œ
const masterClient = new Redis({
  host: 'redis-master',
  port: 6379
});

// ì½ê¸°ëŠ” Slaveë¡œ (Round Robin)
const slaves = [
  new Redis({ host: 'redis-slave1', port: 6380 }),
  new Redis({ host: 'redis-slave2', port: 6381 })
];

let slaveIndex = 0;

async function set(key, value) {
  await masterClient.set(key, value);
}

async function get(key) {
  const slave = slaves[slaveIndex];
  slaveIndex = (slaveIndex + 1) % slaves.length;
  return await slave.get(key);
}
```

**ì¥ì :**
- ì½ê¸° ì„±ëŠ¥ í–¥ìƒ (ë¶€í•˜ ë¶„ì‚°)
- ë°ì´í„° ë°±ì—… (Slaveê°€ Master ë³µì œ)
- ê³ ê°€ìš©ì„± (Slaveë¥¼ Masterë¡œ ìŠ¹ê²© ê°€ëŠ¥)

**ë‹¨ì :**
- Master ì¥ì•  ì‹œ ìˆ˜ë™ ê°œì… í•„ìš” (ìë™ Failover ì—†ìŒ)
- ì“°ê¸°ëŠ” ì—¬ì „íˆ ë‹¨ì¼ ì§€ì 

### 2. Redis Sentinel (ìë™ Failover)

**Sentinelì´ í•˜ëŠ” ì¼:**
- Master ìƒíƒœ ëª¨ë‹ˆí„°ë§
- Master ì¥ì•  ê°ì§€
- ìë™ìœ¼ë¡œ Slaveë¥¼ Masterë¡œ ìŠ¹ê²©
- í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ìƒˆë¡œìš´ Master ì£¼ì†Œ ì•Œë¦¼

**ì„¤ì •:**
```bash
# sentinel.conf
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 5000
sentinel failover-timeout mymaster 10000
sentinel parallel-syncs mymaster 1
```

**ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ:**
```javascript
const Redis = require('ioredis');

const client = new Redis({
  sentinels: [
    { host: 'sentinel1', port: 26379 },
    { host: 'sentinel2', port: 26379 },
    { host: 'sentinel3', port: 26379 }
  ],
  name: 'mymaster'
});

// ìë™ìœ¼ë¡œ í˜„ì¬ Masterì— ì—°ê²°
await client.set('key', 'value');
```

### 3. Redis Cluster (ë¶„ì‚° ì €ì¥)

**ë°ì´í„° ìƒ¤ë”©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì œí•œ ê·¹ë³µ:**

```
ìŠ¬ë¡¯ 0-5460    ìŠ¬ë¡¯ 5461-10922    ìŠ¬ë¡¯ 10923-16383
    â”‚               â”‚                   â”‚
  Node 1          Node 2              Node 3
  (Master)        (Master)            (Master)
     â”‚               â”‚                   â”‚
  Replica 1       Replica 2           Replica 3
```

**ì„¤ì •:**
```bash
# í´ëŸ¬ìŠ¤í„° ìƒì„±
redis-cli --cluster create \
  127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 \
  127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \
  --cluster-replicas 1
```

**ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ:**
```javascript
const Redis = require('ioredis');

const cluster = new Redis.Cluster([
  { host: '127.0.0.1', port: 7000 },
  { host: '127.0.0.1', port: 7001 },
  { host: '127.0.0.1', port: 7002 }
]);

// ìë™ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ë…¸ë“œë¡œ ë¼ìš°íŒ…
await cluster.set('user:123', 'data');
```

**ìŠ¬ë¡¯ ê³„ì‚°:**
```javascript
function getSlot(key) {
  const crc16 = require('crc').crc16xmodem;
  return crc16(key) % 16384;
}

// ì˜ˆì‹œ
getSlot('user:123');  // â†’ ìŠ¬ë¡¯ ë²ˆí˜¸
// í•´ë‹¹ ìŠ¬ë¡¯ì„ ë‹´ë‹¹í•˜ëŠ” ë…¸ë“œë¡œ ìë™ ì „ì†¡
```

**ì¥ì :**
- ë©”ëª¨ë¦¬ ì œí•œ ê·¹ë³µ (ìˆ˜í‰ í™•ì¥)
- ì²˜ë¦¬ëŸ‰ ì¦ê°€ (ì—¬ëŸ¬ ë…¸ë“œê°€ ë™ì‹œ ì²˜ë¦¬)
- ìë™ Failover
- ê³ ê°€ìš©ì„±

**ë‹¨ì :**
- ë©€í‹°í‚¤ ì—°ì‚° ì œí•œ (ë‹¤ë¥¸ ìŠ¬ë¡¯ì˜ í‚¤ëŠ” í•¨ê»˜ ì—°ì‚° ë¶ˆê°€)
- êµ¬ì„± ë° ìš´ì˜ ë³µì¡ë„ ì¦ê°€

---

## API Rate Limiting

### Rate Limitingì˜ í•„ìš”ì„±

**ë¬¸ì œ ìƒí™©:**
- ì•…ì˜ì ì¸ ì‚¬ìš©ìì˜ ê³¼ë„í•œ API í˜¸ì¶œ
- ë²„ê·¸ë¡œ ì¸í•œ ë¬´í•œ ë£¨í”„ API í˜¸ì¶œ
- DDoS ê³µê²©

**í•´ê²°:**
íŠ¹ì • ì‚¬ìš©ì/IPì˜ API í˜¸ì¶œì„ ì œí•œí•˜ì—¬ ì‹œìŠ¤í…œ ë³´í˜¸

### 1. ê³ ì • ìœˆë„ìš° ì¹´ìš´í„° (Fixed Window Counter)

**ê°œë…:**
ì¼ì • ì‹œê°„ ë™ì•ˆì˜ ìš”ì²­ ìˆ˜ë¥¼ ì¹´ìš´íŠ¸í•©ë‹ˆë‹¤.

```javascript
async function checkRateLimit(userId, limit = 100) {
  const key = `rate_limit:${userId}:${Math.floor(Date.now() / 60000)}`;
  const current = await redis.incr(key);
  
  if (current === 1) {
    await redis.expire(key, 60); // 1ë¶„ í›„ ë§Œë£Œ
  }
  
  return current <= limit;
}

// ì‚¬ìš© ì˜ˆì‹œ
app.get('/api/data', async (req, res) => {
  const allowed = await checkRateLimit(req.userId, 100);
  
  if (!allowed) {
    return res.status(429).json({ error: 'Too Many Requests' });
  }
  
  // ì •ìƒ ì²˜ë¦¬
});
```

**ì¥ì :**
- êµ¬í˜„ì´ ë§¤ìš° ê°„ë‹¨
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

**ë‹¨ì :**
- ìœˆë„ìš° ê²½ê³„ì—ì„œ burst íŠ¸ë˜í”½ ë°œìƒ ê°€ëŠ¥

```
09:59:30 - 100 requests
10:00:30 - 100 requests
â†’ 1ë¶„ ì•ˆì— 200 requests ê°€ëŠ¥!
```

### 2. ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë¡œê·¸ (Sliding Window Log)

**ì •í™•í•œ rate limiting**ì„ ì œê³µí•©ë‹ˆë‹¤.

```javascript
async function checkRateLimitSliding(userId, limit = 100, windowMs = 60000) {
  const key = `rate_limit:${userId}`;
  const now = Date.now();
  const windowStart = now - windowMs;
  
  // ë§Œë£Œëœ ë¡œê·¸ ì‚­ì œ
  await redis.zremrangebyscore(key, 0, windowStart);
  
  // í˜„ì¬ ìš”ì²­ ìˆ˜ í™•ì¸
  const count = await redis.zcard(key);
  
  if (count < limit) {
    // í˜„ì¬ ìš”ì²­ ì¶”ê°€
    await redis.zadd(key, now, `${now}-${Math.random()}`);
    await redis.expire(key, Math.ceil(windowMs / 1000));
    return true;
  }
  
  return false;
}
```

**ì¥ì :**
- ì •í™•í•œ rate limiting
- burst ë°©ì§€

**ë‹¨ì :**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ (ëª¨ë“  ìš”ì²­ íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥)
- ê³ íŠ¸ë˜í”½ì—ì„œ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥

### 3. í† í° ë²„í‚· (Token Bucket)

**ê°œë…:**
ì¼ì • ì†ë„ë¡œ í† í°ì„ ìƒì„±í•˜ê³ , ìš”ì²­ ì‹œ í† í°ì„ ì†Œë¹„í•©ë‹ˆë‹¤.

```javascript
async function checkRateLimitTokenBucket(userId, capacity = 100, refillRate = 10) {
  const key = `token_bucket:${userId}`;
  
  const bucket = await redis.hgetall(key);
  const now = Date.now() / 1000; // ì´ˆ ë‹¨ìœ„
  
  let tokens = bucket.tokens ? parseFloat(bucket.tokens) : capacity;
  let lastRefill = bucket.lastRefill ? parseFloat(bucket.lastRefill) : now;
  
  // í† í° ë¦¬í•„
  const timePassed = now - lastRefill;
  tokens = Math.min(capacity, tokens + timePassed * refillRate);
  
  if (tokens >= 1) {
    // í† í° ì†Œë¹„
    tokens -= 1;
    await redis.hset(key, 'tokens', tokens.toString(), 'lastRefill', now.toString());
    await redis.expire(key, 3600);
    return true;
  }
  
  return false;
}
```

**ì¥ì :**
- burst íŠ¸ë˜í”½ í—ˆìš© (ë²„í‚·ì— í† í°ì´ ìŒ“ì—¬ ìˆìœ¼ë©´)
- ìœ ì—°í•œ rate limiting

**ë‹¨ì :**
- êµ¬í˜„ ë³µì¡ë„ ë†’ìŒ

### 4. Leaky Bucket (ëˆ„ì¶œ ë²„í‚·)

**ê°œë…:**
ìš”ì²­ì„ ë²„í‚·ì— ë„£ê³ , ì¼ì • ì†ë„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

```javascript
// Redis Listë¥¼ íë¡œ ì‚¬ìš©
async function addRequest(userId, request) {
  const key = `leaky_bucket:${userId}`;
  const queueLength = await redis.lpush(key, JSON.stringify(request));
  await redis.expire(key, 3600);
  
  const maxQueueSize = 100;
  if (queueLength > maxQueueSize) {
    await redis.rpop(key); // ê°€ì¥ ì˜¤ë˜ëœ ìš”ì²­ ì œê±°
    return false; // ê±°ë¶€
  }
  
  return true; // ìˆ˜ë½
}

// ì›Œì»¤ê°€ ì¼ì • ì†ë„ë¡œ ì²˜ë¦¬
setInterval(async () => {
  const users = await redis.keys('leaky_bucket:*');
  
  for (const key of users) {
    const request = await redis.rpop(key);
    if (request) {
      await processRequest(JSON.parse(request));
    }
  }
}, 100); // 100msë§ˆë‹¤ ì²˜ë¦¬
```

---

## ë°°ì¹˜ ì²˜ë¦¬ ë°©ë²•

### ë°°ì¹˜ ì²˜ë¦¬ì˜ í•„ìš”ì„±

**ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤:**
- 100ë§Œ ëª…ì˜ ì‚¬ìš©ìì—ê²Œ ì´ë©”ì¼ ë°œì†¡
- ì „ì²´ ìƒí’ˆ ì •ë³´ ì—…ë°ì´íŠ¸
- ëŒ€ëŸ‰ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜

**ë¬¸ì œ:**
- í•œ ë²ˆì— ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±
- ë°ì´í„°ë² ì´ìŠ¤ ê³¼ë¶€í•˜
- íƒ€ì„ì•„ì›ƒ ë°œìƒ

### 1. í˜ì´ì§€ë„¤ì´ì…˜ ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬

```javascript
async function batchProcessUsers(batchSize = 1000) {
  let offset = 0;
  let hasMore = true;
  
  while (hasMore) {
    // ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¡°íšŒ
    const users = await db.query(
      'SELECT * FROM users LIMIT ? OFFSET ?',
      [batchSize, offset]
    );
    
    if (users.length === 0) {
      hasMore = false;
      break;
    }
    
    // ë°°ì¹˜ ì²˜ë¦¬
    for (const user of users) {
      await processUser(user);
    }
    
    offset += batchSize;
    
    // ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ë¶€í•˜ ë¶„ì‚°ì„ ìœ„í•œ ì§€ì—°
    await sleep(100);
  }
}
```

### 2. ì»¤ì„œ ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬

**ëŒ€ëŸ‰ ë°ì´í„°ì—ì„œ ë” íš¨ìœ¨ì :**

```javascript
async function batchProcessWithCursor(batchSize = 1000) {
  let lastId = 0;
  let hasMore = true;
  
  while (hasMore) {
    const users = await db.query(
      'SELECT * FROM users WHERE id > ? ORDER BY id LIMIT ?',
      [lastId, batchSize]
    );
    
    if (users.length === 0) {
      hasMore = false;
      break;
    }
    
    for (const user of users) {
      await processUser(user);
    }
    
    lastId = users[users.length - 1].id;
  }
}
```

**ì¥ì :**
- OFFSET ì‚¬ìš© ì‹œ ë°œìƒí•˜ëŠ” ì„±ëŠ¥ ì €í•˜ ë°©ì§€
- ì²˜ë¦¬ ì¤‘ ìƒˆ ë°ì´í„° ì¶”ê°€ì—ë„ ì•ˆì •ì 

### 3. Redisë¥¼ í™œìš©í•œ ë°°ì¹˜ ì‘ì—… í

```javascript
// ì‘ì—…ì„ íì— ì¶”ê°€
async function enqueueBatchJobs(userIds) {
  const pipeline = redis.pipeline();
  
  for (const userId of userIds) {
    pipeline.lpush('batch:jobs', JSON.stringify({
      type: 'processUser',
      userId,
      timestamp: Date.now()
    }));
  }
  
  await pipeline.exec();
}

// ì›Œì»¤ê°€ ì‘ì—… ì²˜ë¦¬
async function batchWorker(workerId, concurrency = 10) {
  while (true) {
    // í•œ ë²ˆì— ì—¬ëŸ¬ ì‘ì—… ê°€ì ¸ì˜¤ê¸°
    const jobs = await redis.rpop('batch:jobs', concurrency);
    
    if (jobs.length === 0) {
      await sleep(1000);
      continue;
    }
    
    // ë³‘ë ¬ ì²˜ë¦¬
    await Promise.all(jobs.map(job => {
      const data = JSON.parse(job);
      return processJob(data);
    }));
  }
}

// ì—¬ëŸ¬ ì›Œì»¤ ì‹¤í–‰
for (let i = 0; i < 5; i++) {
  batchWorker(i).catch(console.error);
}
```

### 4. Bull Queueë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë°°ì¹˜ ì²˜ë¦¬

```javascript
const Queue = require('bull');

const batchQueue = new Queue('batch-processing', {
  redis: {
    host: 'localhost',
    port: 6379
  }
});

// ì‘ì—… ì¶”ê°€
async function addBatchJobs(users) {
  const jobs = users.map(user => ({
    name: 'processUser',
    data: { userId: user.id },
    opts: {
      attempts: 3,
      backoff: {
        type: 'exponential',
        delay: 2000
      }
    }
  }));
  
  await batchQueue.addBulk(jobs);
}

// ì‘ì—… ì²˜ë¦¬
batchQueue.process('processUser', 10, async (job) => {
  const { userId } = job.data;
  
  // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
  await job.progress(50);
  
  await processUser(userId);
  
  await job.progress(100);
  
  return { userId, status: 'completed' };
});

// ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
batchQueue.on('completed', (job, result) => {
  console.log(`Job ${job.id} completed:`, result);
});

batchQueue.on('failed', (job, err) => {
  console.error(`Job ${job.id} failed:`, err);
});
```

---

## ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ

### ì‚¬ë¡€ 1: ì „ììƒê±°ë˜ ìƒí’ˆ ì¡°íšŒ API

**ì‹œë‚˜ë¦¬ì˜¤:**
- ìƒí’ˆ ì •ë³´ëŠ” ìì£¼ ë³€ê²½ë˜ì§€ ì•ŠìŒ
- ë™ì¼í•œ ìƒí’ˆì„ ìˆ˜ì²œ ëª…ì´ ë™ì‹œì— ì¡°íšŒ
- ë¹ ë¥¸ ì‘ë‹µ ì†ë„ê°€ ì¤‘ìš”

**êµ¬í˜„:**

```javascript
const express = require('express');
const Redis = require('ioredis');
const mysql = require('mysql2/promise');

const app = express();
const redis = new Redis();
const db = await mysql.createPool({
  host: 'localhost',
  user: 'root',
  database: 'ecommerce'
});

// ìƒí’ˆ ì¡°íšŒ API
app.get('/api/products/:id', async (req, res) => {
  const productId = req.params.id;
  const cacheKey = `product:${productId}`;
  
  try {
    // 1. ìºì‹œ í™•ì¸
    let product = await redis.get(cacheKey);
    
    if (product) {
      console.log('Cache HIT');
      return res.json({
        data: JSON.parse(product),
        cached: true
      });
    }
    
    console.log('Cache MISS');
    
    // 2. DB ì¡°íšŒ
    const [rows] = await db.query(
      'SELECT * FROM products WHERE id = ?',
      [productId]
    );
    
    if (rows.length === 0) {
      return res.status(404).json({ error: 'Product not found' });
    }
    
    product = rows[0];
    
    // 3. ìºì‹œì— ì €ì¥ (1ì‹œê°„ TTL)
    await redis.setex(cacheKey, 3600, JSON.stringify(product));
    
    return res.json({
      data: product,
      cached: false
    });
    
  } catch (error) {
    console.error(error);
    return res.status(500).json({ error: 'Internal server error' });
  }
});

// ìƒí’ˆ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œ ìºì‹œ ë¬´íš¨í™”
app.put('/api/products/:id', async (req, res) => {
  const productId = req.params.id;
  const updates = req.body;
  
  try {
    // DB ì—…ë°ì´íŠ¸
    await db.query(
      'UPDATE products SET name = ?, price = ? WHERE id = ?',
      [updates.name, updates.price, productId]
    );
    
    // ìºì‹œ ë¬´íš¨í™”
    await redis.del(`product:${productId}`);
    
    return res.json({ success: true });
    
  } catch (error) {
    console.error(error);
    return res.status(500).json({ error: 'Internal server error' });
  }
});

app.listen(3000, () => {
  console.log('Server running on port 3000');
});
```

### ì‚¬ë¡€ 2: ì†Œì…œ ë¯¸ë””ì–´ í”¼ë“œ ì‹œìŠ¤í…œ

**ì‹œë‚˜ë¦¬ì˜¤:**
- ì‚¬ìš©ìë³„ë¡œ ë§ì¶¤ í”¼ë“œ ì œê³µ
- ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ í•„ìš”
- ë†’ì€ ì½ê¸° ì„±ëŠ¥ ìš”êµ¬

**êµ¬í˜„:**

```javascript
// í”¼ë“œ ìƒì„± (Fanout on Write ë°©ì‹)
async function publishPost(userId, post) {
  const postId = await savePostToDB(post);
  
  // íŒ”ë¡œì›Œ ëª©ë¡ ì¡°íšŒ
  const followers = await db.query(
    'SELECT follower_id FROM follows WHERE user_id = ?',
    [userId]
  );
  
  // ê° íŒ”ë¡œì›Œì˜ í”¼ë“œì— ì¶”ê°€
  const pipeline = redis.pipeline();
  
  for (const follower of followers) {
    // Sorted Set ì‚¬ìš© (ì ìˆ˜ëŠ” íƒ€ì„ìŠ¤íƒ¬í”„)
    pipeline.zadd(
      `feed:${follower.follower_id}`,
      Date.now(),
      JSON.stringify({ postId, userId, content: post.content })
    );
    
    // í”¼ë“œ í¬ê¸° ì œí•œ (ìµœê·¼ 1000ê°œë§Œ ìœ ì§€)
    pipeline.zremrangebyrank(`feed:${follower.follower_id}`, 0, -1001);
  }
  
  await pipeline.exec();
  
  return postId;
}

// í”¼ë“œ ì¡°íšŒ
app.get('/api/feed', async (req, res) => {
  const userId = req.userId;
  const page = parseInt(req.query.page) || 1;
  const pageSize = 20;
  
  const start = (page - 1) * pageSize;
  const end = start + pageSize - 1;
  
  // Redisì—ì„œ í”¼ë“œ ì¡°íšŒ (ìµœì‹ ìˆœ)
  const feedItems = await redis.zrevrange(
    `feed:${userId}`,
    start,
    end
  );
  
  const posts = feedItems.map(item => JSON.parse(item));
  
  return res.json({
    posts,
    page,
    hasMore: posts.length === pageSize
  });
});
```

### ì‚¬ë¡€ 3: ì‹¤ì‹œê°„ ìˆœìœ„ ì‹œìŠ¤í…œ (ë¦¬ë”ë³´ë“œ)

**ì‹œë‚˜ë¦¬ì˜¤:**
- ê²Œì„ ì ìˆ˜ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
- ìˆœìœ„ ì¡°íšŒê°€ ë¹ˆë²ˆ
- ì •í™•í•œ ìˆœìœ„ ê³„ì‚° í•„ìš”

**êµ¬í˜„:**

```javascript
// ì ìˆ˜ ì—…ë°ì´íŠ¸
app.post('/api/score', async (req, res) => {
  const { userId, score } = req.body;
  
  // Sorted Setì— ì ìˆ˜ ì €ì¥ (ë†’ì€ ì ìˆ˜ê°€ ìš°ì„ )
  await redis.zadd('leaderboard', score, userId);
  
  // ì‚¬ìš©ì ì •ë³´ ìºì‹œ
  await redis.hset(`user:${userId}`, 'score', score, 'updated', Date.now());
  
  // í˜„ì¬ ìˆœìœ„ ì¡°íšŒ
  const rank = await redis.zrevrank('leaderboard', userId);
  
  return res.json({
    score,
    rank: rank + 1 // 0-basedì´ë¯€ë¡œ +1
  });
});

// ìˆœìœ„ ì¡°íšŒ
app.get('/api/leaderboard', async (req, res) => {
  const page = parseInt(req.query.page) || 1;
  const pageSize = 100;
  
  const start = (page - 1) * pageSize;
  const end = start + pageSize - 1;
  
  // ìƒìœ„ ë­ì»¤ ì¡°íšŒ (ì ìˆ˜ í¬í•¨)
  const leaderboard = await redis.zrevrange(
    'leaderboard',
    start,
    end,
    'WITHSCORES'
  );
  
  // ê²°ê³¼ í¬ë§·íŒ…
  const results = [];
  for (let i = 0; i < leaderboard.length; i += 2) {
    const userId = leaderboard[i];
    const score = leaderboard[i + 1];
    
    results.push({
      rank: start + (i / 2) + 1,
      userId,
      score: parseInt(score)
    });
  }
  
  return res.json({ leaderboard: results });
});

// íŠ¹ì • ì‚¬ìš©ì ì£¼ë³€ ìˆœìœ„ ì¡°íšŒ
app.get('/api/leaderboard/around/:userId', async (req, res) => {
  const { userId } = req.params;
  const range = 5; // ìœ„ì•„ë˜ 5ëª…ì”©
  
  // í˜„ì¬ ìˆœìœ„ í™•ì¸
  const rank = await redis.zrevrank('leaderboard', userId);
  
  if (rank === null) {
    return res.status(404).json({ error: 'User not found' });
  }
  
  // ì£¼ë³€ ìˆœìœ„ ì¡°íšŒ
  const start = Math.max(0, rank - range);
  const end = rank + range;
  
  const nearbyPlayers = await redis.zrevrange(
    'leaderboard',
    start,
    end,
    'WITHSCORES'
  );
  
  const results = [];
  for (let i = 0; i < nearbyPlayers.length; i += 2) {
    const playerId = nearbyPlayers[i];
    const score = nearbyPlayers[i + 1];
    
    results.push({
      rank: start + (i / 2) + 1,
      userId: playerId,
      score: parseInt(score),
      isCurrentUser: playerId === userId
    });
  }
  
  return res.json({ leaderboard: results });
});
```

---

## â˜ï¸ AWS ì¸í”„ë¼ë¥¼ í™œìš©í•œ ëŒ€ëŸ‰ API ì²˜ë¦¬

AWSì˜ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì¸í”„ë¼ ë ˆë²¨ì—ì„œ ëŒ€ëŸ‰ API ì²˜ë¦¬ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.

### ğŸ¯ AWS ì„œë¹„ìŠ¤ êµ¬ì„± ê°œìš”

| ì„œë¹„ìŠ¤ | ì—­í•  | ì£¼ìš” ê¸°ëŠ¥ |
|--------|------|----------|
| **ECS** | ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | Auto Scaling, ë°°í¬ ê´€ë¦¬ |
| **RDS Proxy** | DB ì—°ê²° í’€ë§ | Connection ê´€ë¦¬, Failover |
| **ElastiCache** | ì¸ë©”ëª¨ë¦¬ ìºì‹± | Redis í´ëŸ¬ìŠ¤í„°, ê³ ê°€ìš©ì„± |
| **ALB** | ë¡œë“œ ë°¸ëŸ°ì‹± | L7 ë¼ìš°íŒ…, Rate Limiting |

---

### 1ï¸âƒ£ Amazon ECS (Elastic Container Service)

**ğŸ¯ ê°œìš”:** ì»¨í…Œì´ë„ˆí™”ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì™„ì „ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

#### ğŸ“¦ ECSì˜ í•µì‹¬ ê°œë…

**ì•„í‚¤í…ì²˜:**
```
                 ALB
                  â”‚
            â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
            â”‚           â”‚
      ECS Service   ECS Service
            â”‚           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚       â”‚       â”‚   â”‚
  Task1  Task2  Task3  Task4
  (ì»¨í…Œì´ë„ˆ) (ì»¨í…Œì´ë„ˆ) (ì»¨í…Œì´ë„ˆ) (ì»¨í…Œì´ë„ˆ)
```

**ì£¼ìš” êµ¬ì„± ìš”ì†Œ:**
- **í´ëŸ¬ìŠ¤í„° (Cluster)**: íƒœìŠ¤í¬ê°€ ì‹¤í–‰ë˜ëŠ” ë…¼ë¦¬ì  ê·¸ë£¹
- **ì„œë¹„ìŠ¤ (Service)**: íƒœìŠ¤í¬ì˜ ë³µì‚¬ë³¸ì„ ì›í•˜ëŠ” ê°œìˆ˜ë§Œí¼ ìœ ì§€
- **íƒœìŠ¤í¬ (Task)**: í•˜ë‚˜ ì´ìƒì˜ ì»¨í…Œì´ë„ˆ ê·¸ë£¹
- **íƒœìŠ¤í¬ ì •ì˜ (Task Definition)**: ì»¨í…Œì´ë„ˆ ì„¤ì •ì˜ ë¸”ë£¨í”„ë¦°íŠ¸

#### ğŸš€ ECS Auto Scaling ì„¤ì •

**1. Task Definition ì‘ì„±:**

```json
{
  "family": "api-service",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "1024",
  "memory": "2048",
  "containerDefinitions": [
    {
      "name": "api-container",
      "image": "123456789012.dkr.ecr.us-east-1.amazonaws.com/api-service:latest",
      "portMappings": [
        {
          "containerPort": 3000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "NODE_ENV",
          "value": "production"
        },
        {
          "name": "REDIS_HOST",
          "value": "redis.abc123.ng.0001.use1.cache.amazonaws.com"
        }
      ],
      "secrets": [
        {
          "name": "DB_PASSWORD",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:123456789012:secret:db-password"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/api-service",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:3000/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 60
      }
    }
  ]
}
```

**2. Service ì •ì˜ (Terraform ì˜ˆì‹œ):**

```hcl
resource "aws_ecs_service" "api_service" {
  name            = "api-service"
  cluster         = aws_ecs_cluster.main.id
  task_definition = aws_ecs_task_definition.api.arn
  desired_count   = 3
  launch_type     = "FARGATE"

  network_configuration {
    subnets         = var.private_subnets
    security_groups = [aws_security_group.ecs_tasks.id]
    assign_public_ip = false
  }

  load_balancer {
    target_group_arn = aws_lb_target_group.api.arn
    container_name   = "api-container"
    container_port   = 3000
  }

  # Auto Scaling ì„¤ì •
  depends_on = [aws_lb_listener.api]
}

# Auto Scaling Target
resource "aws_appautoscaling_target" "ecs_target" {
  max_capacity       = 10
  min_capacity       = 3
  resource_id        = "service/${aws_ecs_cluster.main.name}/${aws_ecs_service.api_service.name}"
  scalable_dimension = "ecs:service:DesiredCount"
  service_namespace  = "ecs"
}

# CPU ê¸°ë°˜ Auto Scaling
resource "aws_appautoscaling_policy" "ecs_cpu_policy" {
  name               = "cpu-auto-scaling"
  policy_type        = "TargetTrackingScaling"
  resource_id        = aws_appautoscaling_target.ecs_target.resource_id
  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension
  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace

  target_tracking_scaling_policy_configuration {
    predefined_metric_specification {
      predefined_metric_type = "ECSServiceAverageCPUUtilization"
    }
    target_value = 70.0
    scale_in_cooldown  = 300
    scale_out_cooldown = 60
  }
}

# ë©”ëª¨ë¦¬ ê¸°ë°˜ Auto Scaling
resource "aws_appautoscaling_policy" "ecs_memory_policy" {
  name               = "memory-auto-scaling"
  policy_type        = "TargetTrackingScaling"
  resource_id        = aws_appautoscaling_target.ecs_target.resource_id
  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension
  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace

  target_tracking_scaling_policy_configuration {
    predefined_metric_specification {
      predefined_metric_type = "ECSServiceAverageMemoryUtilization"
    }
    target_value = 80.0
  }
}

# ìš”ì²­ ìˆ˜ ê¸°ë°˜ Auto Scaling
resource "aws_appautoscaling_policy" "ecs_request_policy" {
  name               = "request-count-scaling"
  policy_type        = "TargetTrackingScaling"
  resource_id        = aws_appautoscaling_target.ecs_target.resource_id
  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension
  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace

  target_tracking_scaling_policy_configuration {
    predefined_metric_specification {
      predefined_metric_type = "ALBRequestCountPerTarget"
      resource_label         = "${aws_lb.main.arn_suffix}/${aws_lb_target_group.api.arn_suffix}"
    }
    target_value = 1000.0  # íƒ€ê²Ÿë‹¹ 1000 requests
  }
}
```

#### ğŸ¯ ECS ì‹¤ì „ ë°°í¬ ì „ëµ

**Blue-Green ë°°í¬:**

```hcl
resource "aws_ecs_service" "api_service" {
  # ... ê¸°ë³¸ ì„¤ì • ...

  deployment_controller {
    type = "CODE_DEPLOY"
  }
}

resource "aws_codedeploy_app" "api" {
  name             = "api-service"
  compute_platform = "ECS"
}

resource "aws_codedeploy_deployment_group" "api" {
  app_name               = aws_codedeploy_app.api.name
  deployment_group_name  = "api-deployment-group"
  service_role_arn       = aws_iam_role.codedeploy.arn
  deployment_config_name = "CodeDeployDefault.ECSAllAtOnce"

  blue_green_deployment_config {
    terminate_blue_instances_on_deployment_success {
      action                           = "TERMINATE"
      termination_wait_time_in_minutes = 5
    }

    deployment_ready_option {
      action_on_timeout = "CONTINUE_DEPLOYMENT"
    }
  }

  ecs_service {
    cluster_name = aws_ecs_cluster.main.name
    service_name = aws_ecs_service.api_service.name
  }

  load_balancer_info {
    target_group_pair_info {
      prod_traffic_route {
        listener_arns = [aws_lb_listener.api.arn]
      }

      target_group {
        name = aws_lb_target_group.blue.name
      }

      target_group {
        name = aws_lb_target_group.green.name
      }
    }
  }
}
```

**Rolling Update:**

```hcl
resource "aws_ecs_service" "api_service" {
  # ... ê¸°ë³¸ ì„¤ì • ...

  deployment_configuration {
    maximum_percent         = 200
    minimum_healthy_percent = 100
    deployment_circuit_breaker {
      enable   = true
      rollback = true
    }
  }

  # ë°°í¬ ì¤‘ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨ ì‹œ ìë™ ë¡¤ë°±
}
```

#### ğŸ’¡ ECS ì„±ëŠ¥ ìµœì í™”

**1. Task Placement ì „ëµ:**

```hcl
resource "aws_ecs_service" "api_service" {
  # ... ê¸°ë³¸ ì„¤ì • ...

  ordered_placement_strategy {
    type  = "spread"
    field = "attribute:ecs.availability-zone"
  }

  ordered_placement_strategy {
    type  = "binpack"
    field = "memory"
  }

  placement_constraints {
    type       = "memberOf"
    expression = "attribute:instance-type =~ t3.*"
  }
}
```

**2. Task í¬ê¸° ìµœì í™”:**

```javascript
// ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•œ ìµœì  ë¦¬ì†ŒìŠ¤ ê²°ì •
const resourceConfigurations = [
  { cpu: 256,  memory: 512  },  // ì†Œí˜•
  { cpu: 512,  memory: 1024 },  // ì¤‘í˜•
  { cpu: 1024, memory: 2048 },  // ëŒ€í˜•
  { cpu: 2048, memory: 4096 }   // íŠ¹ëŒ€í˜•
];

// ë¶€í•˜ í…ŒìŠ¤íŠ¸ë¡œ ìµœì ê°’ ê²°ì •
// - ìš”ì²­ë‹¹ í‰ê·  CPU ì‚¬ìš©ëŸ‰
// - ìš”ì²­ë‹¹ í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
// - ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìš”ì²­ ìˆ˜
```

**3. Connection Pooling:**

```javascript
// ECS Taskì—ì„œ ì‹¤í–‰ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜
const mysql = require('mysql2/promise');

const pool = mysql.createPool({
  host: process.env.RDS_PROXY_ENDPOINT,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  database: process.env.DB_NAME,
  waitForConnections: true,
  connectionLimit: 10,     // Taskë‹¹ 10ê°œ ì—°ê²°
  queueLimit: 0,
  enableKeepAlive: true,
  keepAliveInitialDelay: 0
});

// Task 10ê°œ Ã— 10 ì—°ê²° = 100ê°œ ì—°ê²°
// RDS Proxyê°€ ì´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬
```

---

### 2ï¸âƒ£ Amazon RDS Proxy

**ğŸ¯ ê°œìš”:** ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ê´€ë¦¬í•˜ê³  í’€ë§í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í™•ì¥ì„±ê³¼ ë³µì›ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

#### âš ï¸ RDS Proxyê°€ í•´ê²°í•˜ëŠ” ë¬¸ì œ

**âŒ ë¬¸ì œ ìƒí™© (RDS Proxy ì—†ì´):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Lambda/ECS Task 100ê°œ ë™ì‹œ ì‹¤í–‰      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ ê°ê° DB ì—°ê²° ìƒì„±
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RDS: max_connections = 100           â”‚
â”‚ ì—°ê²° ìˆ˜ ì´ˆê³¼! âŒ                      â”‚
â”‚ ERROR: Too many connections          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**âœ… í•´ê²° ë°©ë²• (RDS Proxy ì‚¬ìš©):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Lambda/ECS Task 100ê°œ ë™ì‹œ ì‹¤í–‰      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RDS Proxy (Connection Pooling)      â”‚
â”‚ - ì—°ê²° ì¬ì‚¬ìš©                         â”‚
â”‚ - ì§€ëŠ¥ì  ë¼ìš°íŒ…                       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ ì‹¤ì œ DB ì—°ê²°ì€ 10ê°œë§Œ ì‚¬ìš©
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RDS: ì—°ê²° ìˆ˜ 10ê°œ                    â”‚
â”‚ ì •ìƒ ë™ì‘ âœ…                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ’¡ í•µì‹¬ íš¨ê³¼:**
- 100ê°œ ìš”ì²­ â†’ 10ê°œ DB ì—°ê²°ë¡œ ì²˜ë¦¬
- DB ë¶€í•˜ 90% ê°ì†Œ
- ì—°ê²° ì—ëŸ¬ ë°©ì§€

#### ğŸ—ï¸ RDS Proxy êµ¬ì„±

**Terraform ì„¤ì •:**

```hcl
# RDS Proxy ìƒì„±
resource "aws_db_proxy" "main" {
  name                   = "api-rds-proxy"
  engine_family          = "MYSQL"
  auth {
    auth_scheme = "SECRETS"
    iam_auth    = "REQUIRED"
    secret_arn  = aws_secretsmanager_secret.db_credentials.arn
  }
  
  role_arn               = aws_iam_role.rds_proxy.arn
  vpc_subnet_ids         = var.private_subnets
  require_tls            = true

  # Connection Pool ì„¤ì •
  max_connections_percent         = 100
  max_idle_connections_percent    = 50
  connection_borrow_timeout       = 120

  tags = {
    Name = "api-rds-proxy"
  }
}

# Target Group (ì‹¤ì œ RDS ì¸ìŠ¤í„´ìŠ¤)
resource "aws_db_proxy_default_target_group" "main" {
  db_proxy_name = aws_db_proxy.main.name

  connection_pool_config {
    connection_borrow_timeout    = 120
    init_query                   = "SET time_zone = '+00:00'"
    max_connections_percent      = 100
    max_idle_connections_percent = 50
    session_pinning_filters      = ["EXCLUDE_VARIABLE_SETS"]
  }
}

# RDS ì¸ìŠ¤í„´ìŠ¤ ì—°ê²°
resource "aws_db_proxy_target" "main" {
  db_proxy_name          = aws_db_proxy.main.name
  target_group_name      = aws_db_proxy_default_target_group.main.name
  db_instance_identifier = aws_db_instance.main.id
}

# IAM Role for RDS Proxy
resource "aws_iam_role" "rds_proxy" {
  name = "rds-proxy-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "rds.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_role_policy" "rds_proxy_secrets" {
  role = aws_iam_role.rds_proxy.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Action = [
        "secretsmanager:GetSecretValue"
      ]
      Resource = [
        aws_secretsmanager_secret.db_credentials.arn
      ]
    }]
  })
}
```

#### ğŸ’» ì• í”Œë¦¬ì¼€ì´ì…˜ ì—°ë™

**IAM ì¸ì¦ ì‚¬ìš©:**

```javascript
const mysql = require('mysql2/promise');
const AWS = require('aws-sdk');

class RDSProxyConnection {
  constructor() {
    this.signer = new AWS.RDS.Signer({
      region: process.env.AWS_REGION,
      hostname: process.env.RDS_PROXY_ENDPOINT,
      port: 3306,
      username: process.env.DB_USER
    });
  }

  async getConnection() {
    // IAM ì¸ì¦ í† í° ìƒì„± (15ë¶„ ìœ íš¨)
    const token = this.signer.getAuthToken({
      username: process.env.DB_USER
    });

    const connection = await mysql.createConnection({
      host: process.env.RDS_PROXY_ENDPOINT,
      user: process.env.DB_USER,
      password: token,  // IAM í† í°ì„ ë¹„ë°€ë²ˆí˜¸ë¡œ ì‚¬ìš©
      database: process.env.DB_NAME,
      ssl: 'Amazon RDS',
      authPlugins: {
        mysql_clear_password: () => () => token
      }
    });

    return connection;
  }

  async createPool() {
    const pool = mysql.createPool({
      host: process.env.RDS_PROXY_ENDPOINT,
      user: process.env.DB_USER,
      database: process.env.DB_NAME,
      waitForConnections: true,
      connectionLimit: 10,
      queueLimit: 0,
      // IAM ì¸ì¦ í™œì„±í™”
      ssl: 'Amazon RDS',
      // í† í° ê°±ì‹  ë¡œì§
      before: async (connection) => {
        const token = this.signer.getAuthToken({
          username: process.env.DB_USER
        });
        connection.password = token;
      }
    });

    return pool;
  }
}

// ì‚¬ìš© ì˜ˆì‹œ
const rdsProxy = new RDSProxyConnection();
const pool = await rdsProxy.createPool();

// ì¿¼ë¦¬ ì‹¤í–‰
const [rows] = await pool.query('SELECT * FROM users WHERE id = ?', [userId]);
```

**Secrets Manager ì‚¬ìš©:**

```javascript
const AWS = require('aws-sdk');
const mysql = require('mysql2/promise');

const secretsManager = new AWS.SecretsManager({
  region: process.env.AWS_REGION
});

async function getDBCredentials() {
  const secret = await secretsManager.getSecretValue({
    SecretId: process.env.DB_SECRET_ARN
  }).promise();

  return JSON.parse(secret.SecretString);
}

async function createConnection() {
  const credentials = await getDBCredentials();

  const connection = await mysql.createConnection({
    host: process.env.RDS_PROXY_ENDPOINT,
    user: credentials.username,
    password: credentials.password,
    database: credentials.database,
    ssl: 'Amazon RDS'
  });

  return connection;
}
```

#### ğŸ”„ RDS Proxy Failover ì²˜ë¦¬

**ìë™ Failover:**

```javascript
const pool = mysql.createPool({
  host: process.env.RDS_PROXY_ENDPOINT,
  // ... ê¸°íƒ€ ì„¤ì • ...
});

async function executeQueryWithRetry(query, params, maxRetries = 3) {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const [rows] = await pool.query(query, params);
      return rows;
    } catch (error) {
      console.error(`Attempt ${attempt} failed:`, error.message);

      // Failover ê°ì§€
      if (error.code === 'PROTOCOL_CONNECTION_LOST' || 
          error.code === 'ECONNREFUSED') {
        
        if (attempt < maxRetries) {
          // ì§€ìˆ˜ ë°±ì˜¤í”„
          const delay = Math.min(1000 * Math.pow(2, attempt - 1), 10000);
          console.log(`Waiting ${delay}ms before retry...`);
          await new Promise(resolve => setTimeout(resolve, delay));
          continue;
        }
      }

      throw error;
    }
  }
}

// ì‚¬ìš©
try {
  const users = await executeQueryWithRetry(
    'SELECT * FROM users WHERE active = ?',
    [true]
  );
} catch (error) {
  console.error('Query failed after all retries:', error);
}
```

#### ğŸ“Š RDS Proxy ëª¨ë‹ˆí„°ë§

**CloudWatch ë©”íŠ¸ë¦­:**

```javascript
const AWS = require('aws-sdk');
const cloudwatch = new AWS.CloudWatch();

async function monitorRDSProxy() {
  const metrics = [
    'DatabaseConnections',
    'DatabaseConnectionsCurrentlyBorrowed',
    'DatabaseConnectionsCurrentlySessionPinned',
    'DatabaseConnectionsSetupSucceeded',
    'DatabaseConnectionsSetupFailed',
    'QueryDatabaseResponseLatency'
  ];

  const params = {
    Namespace: 'AWS/RDS',
    MetricName: 'DatabaseConnections',
    Dimensions: [
      {
        Name: 'DBProxyName',
        Value: 'api-rds-proxy'
      }
    ],
    StartTime: new Date(Date.now() - 3600000), // 1ì‹œê°„ ì „
    EndTime: new Date(),
    Period: 300, // 5ë¶„
    Statistics: ['Average', 'Maximum']
  };

  const data = await cloudwatch.getMetricStatistics(params).promise();
  
  console.log('RDS Proxy Metrics:', data.Datapoints);
  
  // ê²½ê³  ì„ê³„ê°’ ì²´í¬
  const maxConnections = Math.max(...data.Datapoints.map(d => d.Maximum));
  if (maxConnections > 80) {
    console.warn('High connection count detected:', maxConnections);
    // ì•Œë¦¼ ë°œì†¡ ë˜ëŠ” Auto Scaling íŠ¸ë¦¬ê±°
  }
}

setInterval(monitorRDSProxy, 300000); // 5ë¶„ë§ˆë‹¤
```

#### ğŸ’¡ RDS Proxy ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

**1. Connection Pinning ìµœì†Œí™”:**

```javascript
// âŒ ë‚˜ìœ ì˜ˆ: Session ë³€ìˆ˜ ì‚¬ìš©ìœ¼ë¡œ Pinning ë°œìƒ
await connection.query('SET @user_id = ?', [userId]);
await connection.query('SELECT * FROM orders WHERE user_id = @user_id');

// âœ… ì¢‹ì€ ì˜ˆ: íŒŒë¼ë¯¸í„°ë¡œ ì§ì ‘ ì „ë‹¬
await connection.query(
  'SELECT * FROM orders WHERE user_id = ?',
  [userId]
);
```

**2. Connection Pool í¬ê¸° ì¡°ì •:**

```javascript
// ECS Task ê°œìˆ˜ì— ë”°ë¼ ë™ì  ì¡°ì •
const taskCount = parseInt(process.env.ECS_TASK_COUNT) || 10;
const connectionsPerTask = Math.ceil(100 / taskCount);

const pool = mysql.createPool({
  host: process.env.RDS_PROXY_ENDPOINT,
  connectionLimit: connectionsPerTask,
  // ...
});
```

**3. ì¿¼ë¦¬ ìµœì í™”:**

```javascript
// ì¤€ë¹„ëœ ëª…ë ¹ë¬¸ ì‚¬ìš©
const prepared = await pool.prepare(
  'SELECT * FROM users WHERE email = ? AND active = ?'
);

const [rows] = await prepared.execute(['user@example.com', true]);

// ì¬ì‚¬ìš©
const [rows2] = await prepared.execute(['another@example.com', true]);

// ì •ë¦¬
await prepared.close();
```

---

### 3. Application Load Balancer (ALB)

ALBëŠ” Layer 7ì—ì„œ ë™ì‘í•˜ë©° HTTP/HTTPS íŠ¸ë˜í”½ì„ ì—¬ëŸ¬ ëŒ€ìƒìœ¼ë¡œ ë¶„ì‚°í•©ë‹ˆë‹¤.

#### âš–ï¸ ALB ê³ ê¸‰ ë¼ìš°íŒ…

**ê²½ë¡œ ê¸°ë°˜ ë¼ìš°íŒ…:**

```hcl
resource "aws_lb" "main" {
  name               = "api-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = var.public_subnets

  enable_deletion_protection = true
  enable_http2              = true
  enable_cross_zone_load_balancing = true
}

# API v1 Target Group
resource "aws_lb_target_group" "api_v1" {
  name     = "api-v1-tg"
  port     = 3000
  protocol = "HTTP"
  vpc_id   = var.vpc_id

  health_check {
    enabled             = true
    healthy_threshold   = 2
    unhealthy_threshold = 3
    timeout             = 5
    interval            = 30
    path                = "/health"
    matcher             = "200"
  }

  deregistration_delay = 30

  stickiness {
    type            = "lb_cookie"
    cookie_duration = 86400
    enabled         = true
  }
}

# API v2 Target Group
resource "aws_lb_target_group" "api_v2" {
  name     = "api-v2-tg"
  port     = 3000
  protocol = "HTTP"
  vpc_id   = var.vpc_id
  # ... health check ì„¤ì • ...
}

# Admin Target Group
resource "aws_lb_target_group" "admin" {
  name     = "admin-tg"
  port     = 4000
  protocol = "HTTP"
  vpc_id   = var.vpc_id
  # ... health check ì„¤ì • ...
}

# Listener Rules
resource "aws_lb_listener" "https" {
  load_balancer_arn = aws_lb.main.arn
  port              = "443"
  protocol          = "HTTPS"
  ssl_policy        = "ELBSecurityPolicy-TLS-1-2-2017-01"
  certificate_arn   = var.acm_certificate_arn

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.api_v2.arn
  }
}

# /api/v1/* â†’ API v1
resource "aws_lb_listener_rule" "api_v1" {
  listener_arn = aws_lb_listener.https.arn
  priority     = 100

  action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.api_v1.arn
  }

  condition {
    path_pattern {
      values = ["/api/v1/*"]
    }
  }
}

# /admin/* â†’ Admin
resource "aws_lb_listener_rule" "admin" {
  listener_arn = aws_lb_listener.https.arn
  priority     = 200

  action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.admin.arn
  }

  condition {
    path_pattern {
      values = ["/admin/*"]
    }
  }

  condition {
    source_ip {
      values = ["10.0.0.0/8"]  # ë‚´ë¶€ IPë§Œ í—ˆìš©
    }
  }
}

# Rate Limiting using AWS WAF
resource "aws_wafv2_web_acl" "rate_limit" {
  name  = "api-rate-limit"
  scope = "REGIONAL"

  default_action {
    allow {}
  }

  rule {
    name     = "rate-limit-rule"
    priority = 1

    action {
      block {}
    }

    statement {
      rate_based_statement {
        limit              = 2000
        aggregate_key_type = "IP"
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = "RateLimitRule"
      sampled_requests_enabled   = true
    }
  }

  visibility_config {
    cloudwatch_metrics_enabled = true
    metric_name                = "ApiWebACL"
    sampled_requests_enabled   = true
  }
}

resource "aws_wafv2_web_acl_association" "main" {
  resource_arn = aws_lb.main.arn
  web_acl_arn  = aws_wafv2_web_acl.rate_limit.arn
}
```

#### ğŸ¯ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë¼ìš°íŒ… (Canary ë°°í¬)

```hcl
resource "aws_lb_listener_rule" "canary" {
  listener_arn = aws_lb_listener.https.arn
  priority     = 50

  action {
    type = "forward"
    
    forward {
      target_group {
        arn    = aws_lb_target_group.api_v2.arn
        weight = 90  # 90%
      }

      target_group {
        arn    = aws_lb_target_group.api_v3_canary.arn
        weight = 10  # 10%
      }

      stickiness {
        enabled  = true
        duration = 3600
      }
    }
  }

  condition {
    path_pattern {
      values = ["/api/*"]
    }
  }
}
```

---

### 4. Amazon ElastiCache (ê´€ë¦¬í˜• Redis)

AWSì˜ ê´€ë¦¬í˜• Redis ì„œë¹„ìŠ¤ë¡œ ìš´ì˜ ë¶€ë‹´ì„ ì¤„ì´ë©´ì„œ Redisì˜ ì„±ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ğŸš€ ElastiCache í´ëŸ¬ìŠ¤í„° êµ¬ì„±

```hcl
resource "aws_elasticache_replication_group" "redis" {
  replication_group_id       = "api-redis-cluster"
  replication_group_description = "Redis cluster for API caching"
  
  engine                     = "redis"
  engine_version             = "7.0"
  node_type                  = "cache.r6g.large"
  number_cache_clusters      = 3
  
  port                       = 6379
  parameter_group_name       = aws_elasticache_parameter_group.redis.name
  subnet_group_name          = aws_elasticache_subnet_group.redis.name
  security_group_ids         = [aws_security_group.redis.id]
  
  # ìë™ Failover í™œì„±í™”
  automatic_failover_enabled = true
  multi_az_enabled          = true
  
  # ë°±ì—… ì„¤ì •
  snapshot_retention_limit   = 5
  snapshot_window           = "03:00-05:00"
  
  # ìœ ì§€ë³´ìˆ˜ ìœˆë„ìš°
  maintenance_window        = "sun:05:00-sun:07:00"
  
  # ì „ì†¡ ì¤‘ ì•”í˜¸í™”
  transit_encryption_enabled = true
  auth_token_enabled        = true
  auth_token                = random_password.redis_auth.result
  
  # ì €ì¥ ì‹œ ì•”í˜¸í™”
  at_rest_encryption_enabled = true
  kms_key_id                = aws_kms_key.redis.arn
  
  # ì•Œë¦¼ ì„¤ì •
  notification_topic_arn    = aws_sns_topic.redis_alerts.arn
  
  # Auto Scaling
  auto_minor_version_upgrade = true

  tags = {
    Name        = "api-redis-cluster"
    Environment = "production"
  }
}

# Parameter Group
resource "aws_elasticache_parameter_group" "redis" {
  name   = "redis-params"
  family = "redis7"

  parameter {
    name  = "maxmemory-policy"
    value = "allkeys-lru"
  }

  parameter {
    name  = "timeout"
    value = "300"
  }

  parameter {
    name  = "tcp-keepalive"
    value = "300"
  }
}

# CloudWatch Alarms
resource "aws_cloudwatch_metric_alarm" "redis_cpu" {
  alarm_name          = "redis-high-cpu"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/ElastiCache"
  period              = "120"
  statistic           = "Average"
  threshold           = "75"
  alarm_description   = "This metric monitors redis cpu utilization"
  alarm_actions       = [aws_sns_topic.redis_alerts.arn]

  dimensions = {
    CacheClusterId = aws_elasticache_replication_group.redis.id
  }
}

resource "aws_cloudwatch_metric_alarm" "redis_memory" {
  alarm_name          = "redis-high-memory"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "DatabaseMemoryUsagePercentage"
  namespace           = "AWS/ElastiCache"
  period              = "120"
  statistic           = "Average"
  threshold           = "90"
  alarm_description   = "This metric monitors redis memory usage"
  alarm_actions       = [aws_sns_topic.redis_alerts.arn]

  dimensions = {
    CacheClusterId = aws_elasticache_replication_group.redis.id
  }
}
```

#### ğŸ’» ì• í”Œë¦¬ì¼€ì´ì…˜ ì—°ë™

```javascript
const Redis = require('ioredis');

// ElastiCache Cluster ì—°ê²°
const redis = new Redis.Cluster([
  {
    host: process.env.ELASTICACHE_CONFIG_ENDPOINT,
    port: 6379
  }
], {
  dnsLookup: (address, callback) => callback(null, address),
  redisOptions: {
    tls: {
      checkServerIdentity: () => undefined
    },
    password: process.env.REDIS_AUTH_TOKEN,
    db: 0
  },
  clusterRetryStrategy: (times) => {
    return Math.min(100 * times, 2000);
  },
  enableReadyCheck: true,
  maxRetriesPerRequest: 3
});

redis.on('error', (err) => {
  console.error('Redis error:', err);
});

redis.on('connect', () => {
  console.log('Connected to ElastiCache');
});

module.exports = redis;
```

---

### 5. ì „ì²´ ì•„í‚¤í…ì²˜ í†µí•© ì˜ˆì‹œ

**ëŒ€ëŸ‰ API ì²˜ë¦¬ë¥¼ ìœ„í•œ AWS ì¸í”„ë¼:**

```
                    CloudFront (CDN)
                          â”‚
                          â†“
                   Route 53 (DNS)
                          â”‚
                          â†“
                    AWS WAF (Rate Limiting)
                          â”‚
                          â†“
              Application Load Balancer
                    â”‚         â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                               â”‚
    ECS Service (API)             ECS Service (Admin)
      â”‚   â”‚   â”‚                         â”‚
    Task Task Task                     Task
      â”‚   â”‚   â”‚                         â”‚
      â””â”€â”€â”€â”¼â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚              â”‚
          â†“              â†“
    ElastiCache      RDS Proxy
       (Redis)           â”‚
                         â†“
                    RDS Primary
                         â”‚
                    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                    â”‚         â”‚
              Read Replica  Read Replica
```

**í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬:**

```javascript
// config/aws.js
module.exports = {
  rds: {
    proxyEndpoint: process.env.RDS_PROXY_ENDPOINT,
    database: process.env.DB_NAME,
    user: process.env.DB_USER
  },
  elasticache: {
    configEndpoint: process.env.ELASTICACHE_CONFIG_ENDPOINT,
    authToken: process.env.REDIS_AUTH_TOKEN
  },
  ecs: {
    taskCount: parseInt(process.env.ECS_TASK_COUNT) || 3
  }
};
```

---

## ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ìµœì í™”

### Redis ëª¨ë‹ˆí„°ë§ ì§€í‘œ

#### 1. í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ

```javascript
// Redis INFO ëª…ë ¹ì–´ë¡œ ëª¨ë‹ˆí„°ë§
async function getRedisMetrics() {
  const info = await redis.info();
  
  return {
    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    usedMemory: info.used_memory_human,
    usedMemoryRss: info.used_memory_rss_human,
    memFragmentationRatio: info.mem_fragmentation_ratio,
    
    // ì—°ê²° ì •ë³´
    connectedClients: info.connected_clients,
    rejectedConnections: info.rejected_connections,
    
    // ì²˜ë¦¬ëŸ‰
    opsPerSec: info.instantaneous_ops_per_sec,
    
    // ìºì‹œ íˆíŠ¸ìœ¨
    keyspaceHits: info.keyspace_hits,
    keyspaceMisses: info.keyspace_misses,
    hitRate: (info.keyspace_hits / (info.keyspace_hits + info.keyspace_misses) * 100).toFixed(2) + '%',
    
    // ì§€ì—° ì‹œê°„
    latency: info.latest_fork_usec / 1000 + 'ms'
  };
}

// ì£¼ê¸°ì  ëª¨ë‹ˆí„°ë§
setInterval(async () => {
  const metrics = await getRedisMetrics();
  console.log('Redis Metrics:', metrics);
  
  // ê²½ê³  ì„ê³„ê°’ ì²´í¬
  if (parseFloat(metrics.hitRate) < 80) {
    console.warn('Low cache hit rate:', metrics.hitRate);
  }
  
  if (metrics.connectedClients > 10000) {
    console.warn('High number of connections:', metrics.connectedClients);
  }
}, 60000); // 1ë¶„ë§ˆë‹¤
```

#### 2. ìŠ¬ë¡œìš° ë¡œê·¸ ëª¨ë‹ˆí„°ë§

```bash
# Redis ì„¤ì •
CONFIG SET slowlog-log-slower-than 10000  # 10ms ì´ìƒ ì†Œìš”ë˜ëŠ” ëª…ë ¹ì–´ ë¡œê¹…
CONFIG SET slowlog-max-len 128

# ìŠ¬ë¡œìš° ë¡œê·¸ ì¡°íšŒ
SLOWLOG GET 10
```

```javascript
// ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ìŠ¬ë¡œìš° ë¡œê·¸ í™•ì¸
async function checkSlowQueries() {
  const slowLog = await redis.slowlog('get', 10);
  
  for (const entry of slowLog) {
    console.log({
      id: entry[0],
      timestamp: entry[1],
      duration: entry[2] + 'Î¼s',
      command: entry[3]
    });
  }
}
```

### ì„±ëŠ¥ ìµœì í™” ê¸°ë²•

#### 1. Pipeline ì‚¬ìš©

**ë¬¸ì œ:** ì—¬ëŸ¬ ëª…ë ¹ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ ë„¤íŠ¸ì›Œí¬ ì™•ë³µ ì‹œê°„ì´ ëˆ„ì ë©ë‹ˆë‹¤.

```javascript
// ë¹„íš¨ìœ¨ì 
for (let i = 0; i < 1000; i++) {
  await redis.set(`key:${i}`, `value${i}`);
}
// ì†Œìš” ì‹œê°„: 1ms Ã— 1000 = 1000ms

// Pipeline ì‚¬ìš©
const pipeline = redis.pipeline();
for (let i = 0; i < 1000; i++) {
  pipeline.set(`key:${i}`, `value${i}`);
}
await pipeline.exec();
// ì†Œìš” ì‹œê°„: ~50ms (20ë°° ë¹ ë¦„!)
```

#### 2. ì ì ˆí•œ ë°ì´í„° êµ¬ì¡° ì„ íƒ

```javascript
// âŒ ë¹„íš¨ìœ¨ì : Stringìœ¼ë¡œ JSON ì €ì¥
await redis.set('user:123', JSON.stringify({
  name: 'John',
  email: 'john@example.com',
  age: 30
}));

const user = JSON.parse(await redis.get('user:123'));

// âœ… íš¨ìœ¨ì : Hash ì‚¬ìš©
await redis.hset('user:123', {
  name: 'John',
  email: 'john@example.com',
  age: 30
});

// íŠ¹ì • í•„ë“œë§Œ ì¡°íšŒ ê°€ëŠ¥
const name = await redis.hget('user:123', 'name');
```

#### 3. ë§Œë£Œ ì‹œê°„ ì„¤ì •

**ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€:**

```javascript
// ëª¨ë“  ìºì‹œ í‚¤ì— TTL ì„¤ì •
await redis.setex('temp:data', 3600, data); // 1ì‹œê°„ í›„ ìë™ ì‚­ì œ

// ì„¸ì…˜ ë°ì´í„°
await redis.setex(`session:${sessionId}`, 86400, sessionData); // 24ì‹œê°„

// ì„ì‹œ ì ê¸ˆ
await redis.set(`lock:${resourceId}`, '1', 'EX', 30, 'NX'); // 30ì´ˆ í›„ ìë™ í•´ì œ
```

#### 4. ë©”ëª¨ë¦¬ ìµœì í™”

```bash
# Redis ì„¤ì •
maxmemory 2gb
maxmemory-policy allkeys-lru  # ë©”ëª¨ë¦¬ ì´ˆê³¼ ì‹œ LRU ì •ì±…ìœ¼ë¡œ í‚¤ ì‚­ì œ

# ì••ì¶• ì„¤ì • (ì‘ì€ ë°ì´í„°ëŠ” ì••ì¶•í•˜ì—¬ ì €ì¥)
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
```

---

## ì‹¤ë¬´ ì‚¬ë¡€ ë° íŒ¨í„´

### íŒ¨í„´ 1: ìºì‹œ ì›Œë° (Cache Warming)

**ê°œë…:** ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œ ë¯¸ë¦¬ ìºì‹œë¥¼ ì±„ì›Œì„œ ì´ˆê¸° ìš”ì²­ì˜ ì„±ëŠ¥ ì €í•˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.

```javascript
async function warmupCache() {
  console.log('Starting cache warmup...');
  
  // ì¸ê¸° ìƒí’ˆ ë¯¸ë¦¬ ìºì‹±
  const popularProducts = await db.query(
    'SELECT * FROM products ORDER BY view_count DESC LIMIT 100'
  );
  
  const pipeline = redis.pipeline();
  
  for (const product of popularProducts) {
    pipeline.setex(
      `product:${product.id}`,
      3600,
      JSON.stringify(product)
    );
  }
  
  await pipeline.exec();
  
  console.log('Cache warmup completed');
}

// ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰
warmupCache().catch(console.error);
```

### íŒ¨í„´ 2: ìºì‹œ ìŠ¤íƒ¬í”¼ë“œ ë°©ì§€ (Cache Stampede Prevention)

**Probabilistic Early Expiration:**

```javascript
async function getWithProbabilisticEarlyExpiration(key, fetchFunction, ttl = 3600) {
  const data = await redis.get(key);
  
  if (data) {
    const parsed = JSON.parse(data);
    const expiresAt = parsed.expiresAt;
    const now = Date.now();
    
    // ë§Œë£Œ ì‹œê°„ì´ ê°€ê¹Œì›Œì§€ë©´ í™•ë¥ ì ìœ¼ë¡œ ê°±ì‹ 
    const delta = expiresAt - now;
    const beta = 1; // ì¡°ì • ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°
    
    if (delta * Math.random() < beta) {
      // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê°±ì‹ 
      fetchAndCache(key, fetchFunction, ttl).catch(console.error);
    }
    
    return parsed.value;
  }
  
  // ìºì‹œ ë¯¸ìŠ¤
  return await fetchAndCache(key, fetchFunction, ttl);
}

async function fetchAndCache(key, fetchFunction, ttl) {
  const value = await fetchFunction();
  
  await redis.setex(key, ttl, JSON.stringify({
    value,
    expiresAt: Date.now() + (ttl * 1000)
  }));
  
  return value;
}
```

### íŒ¨í„´ 3: ì„¸ì…˜ ìŠ¤í† ì–´

```javascript
const session = require('express-session');
const RedisStore = require('connect-redis')(session);

app.use(session({
  store: new RedisStore({ client: redis }),
  secret: 'your-secret-key',
  resave: false,
  saveUninitialized: false,
  cookie: {
    maxAge: 86400000, // 24ì‹œê°„
    httpOnly: true,
    secure: process.env.NODE_ENV === 'production'
  }
}));

// ì„¸ì…˜ ì‚¬ìš©
app.get('/api/profile', (req, res) => {
  if (!req.session.userId) {
    return res.status(401).json({ error: 'Unauthorized' });
  }
  
  res.json({ userId: req.session.userId });
});
```

### íŒ¨í„´ 4: ë¶„ì‚° ë½ì„ ì´ìš©í•œ ì¤‘ë³µ ë°©ì§€

```javascript
class RedisLock {
  constructor(redis, key, ttl = 10) {
    this.redis = redis;
    this.key = `lock:${key}`;
    this.ttl = ttl;
    this.lockValue = null;
  }
  
  async acquire() {
    this.lockValue = Math.random().toString(36);
    const result = await this.redis.set(
      this.key,
      this.lockValue,
      'NX',
      'EX',
      this.ttl
    );
    return result === 'OK';
  }
  
  async release() {
    // Lua ìŠ¤í¬ë¦½íŠ¸ë¡œ ì›ìì ìœ¼ë¡œ ì‚­ì œ
    const script = `
      if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
      else
        return 0
      end
    `;
    
    return await this.redis.eval(script, 1, this.key, this.lockValue);
  }
}

// ì‚¬ìš© ì˜ˆì‹œ: ì¤‘ë³µ ê²°ì œ ë°©ì§€
app.post('/api/payment', async (req, res) => {
  const { orderId, amount } = req.body;
  const lock = new RedisLock(redis, `payment:${orderId}`);
  
  try {
    // ë½ íšë“
    const acquired = await lock.acquire();
    if (!acquired) {
      return res.status(409).json({ error: 'Payment already in progress' });
    }
    
    // ê²°ì œ ì²˜ë¦¬
    await processPayment(orderId, amount);
    
    return res.json({ success: true });
    
  } finally {
    // ë½ í•´ì œ
    await lock.release();
  }
});
```

---

## ì£¼ì˜ì‚¬í•­ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. ìºì‹œ ë¬´íš¨í™” ì „ëµ

**ë¬¸ì œ:** ë°ì´í„°ê°€ ë³€ê²½ë˜ì—ˆì„ ë•Œ ìºì‹œë¥¼ ì–´ë–»ê²Œ ì—…ë°ì´íŠ¸í•  ê²ƒì¸ê°€?

**ë°©ë²• 1: Cache Invalidation (ìºì‹œ ë¬´íš¨í™”)**
```javascript
async function updateProduct(productId, data) {
  // DB ì—…ë°ì´íŠ¸
  await db.query('UPDATE products SET ... WHERE id = ?', [productId]);
  
  // ìºì‹œ ì‚­ì œ
  await redis.del(`product:${productId}`);
  
  // ë‹¤ìŒ ìš”ì²­ ì‹œ DBì—ì„œ ìƒˆë¡œ ì½ì–´ì„œ ìºì‹œì— ì €ì¥
}
```

**ë°©ë²• 2: Cache Update (ìºì‹œ ì—…ë°ì´íŠ¸)**
```javascript
async function updateProduct(productId, data) {
  // DB ì—…ë°ì´íŠ¸
  await db.query('UPDATE products SET ... WHERE id = ?', [productId]);
  
  // ìºì‹œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
  await redis.setex(`product:${productId}`, 3600, JSON.stringify(data));
}
```

### 2. Thundering Herd ëŒ€ì‘

**ë¬¸ì œ:** ìºì‹œ ë§Œë£Œ ì‹œ ë™ì‹œ ë‹¤ë°œì ì¸ DB ì ‘ê·¼

**í•´ê²° ë°©ë²•:**
```javascript
async function getDataSafe(key, fetchFunction, ttl = 3600) {
  // 1ì°¨ ìºì‹œ í™•ì¸
  let data = await redis.get(key);
  if (data) return JSON.parse(data);
  
  // ë½ íšë“ ì‹œë„
  const lockKey = `lock:${key}`;
  const lockAcquired = await redis.set(lockKey, '1', 'NX', 'EX', 10);
  
  if (lockAcquired) {
    try {
      // ë”ë¸” ì²´í¬ (ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ ì´ë¯¸ ì—…ë°ì´íŠ¸í–ˆì„ ìˆ˜ ìˆìŒ)
      data = await redis.get(key);
      if (data) return JSON.parse(data);
      
      // DB ì¡°íšŒ ë° ìºì‹œ ì—…ë°ì´íŠ¸
      data = await fetchFunction();
      await redis.setex(key, ttl, JSON.stringify(data));
      
      return data;
    } finally {
      await redis.del(lockKey);
    }
  } else {
    // ë½ì„ íšë“í•˜ì§€ ëª»í•œ ê²½ìš° ëŒ€ê¸° í›„ ì¬ì‹œë„
    await sleep(50);
    return getDataSafe(key, fetchFunction, ttl);
  }
}
```

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬

```javascript
// ì •ê¸°ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
setInterval(async () => {
  const info = await redis.info('memory');
  const usedMemory = parseInt(info.used_memory);
  const maxMemory = parseInt(info.maxmemory);
  
  const usage = (usedMemory / maxMemory * 100).toFixed(2);
  
  console.log(`Redis memory usage: ${usage}%`);
  
  if (usage > 90) {
    console.warn('High memory usage! Consider:');
    console.warn('1. Increasing maxmemory');
    console.warn('2. Adjusting TTL values');
    console.warn('3. Implementing eviction policies');
  }
}, 60000);
```

### 4. ì—°ê²° í’€ ê´€ë¦¬

```javascript
const Redis = require('ioredis');

// ì—°ê²° í’€ ì„¤ì •
const redis = new Redis({
  host: 'localhost',
  port: 6379,
  maxRetriesPerRequest: 3,
  enableReadyCheck: true,
  lazyConnect: true,
  // ì¬ì—°ê²° ì „ëµ
  retryStrategy(times) {
    const delay = Math.min(times * 50, 2000);
    return delay;
  },
  // ì¬ì—°ê²° ì‹œ ì—ëŸ¬ ì²˜ë¦¬
  reconnectOnError(err) {
    const targetError = 'READONLY';
    if (err.message.includes(targetError)) {
      return true; // ì¬ì—°ê²°
    }
    return false;
  }
});

// ì—°ê²° ì´ë²¤íŠ¸ ì²˜ë¦¬
redis.on('connect', () => {
  console.log('Redis connected');
});

redis.on('error', (err) => {
  console.error('Redis error:', err);
});

redis.on('close', () => {
  console.log('Redis connection closed');
});
```

### 5. ë°ì´í„° ì¼ê´€ì„± ë³´ì¥

```javascript
// íŠ¸ëœì­ì…˜ ì‚¬ìš© (MULTI/EXEC)
async function transferPoints(fromUserId, toUserId, points) {
  const multi = redis.multi();
  
  multi.hincrby(`user:${fromUserId}`, 'points', -points);
  multi.hincrby(`user:${toUserId}`, 'points', points);
  
  const results = await multi.exec();
  
  // ê²°ê³¼ í™•ì¸
  for (const [err, result] of results) {
    if (err) {
      throw new Error('Transaction failed');
    }
  }
}
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ğŸ“• Redis ê´€ë ¨

| ë²ˆí˜¸ | ì œëª© | ìœ í˜• | ì„¤ëª… |
|------|------|------|------|
| 1 | [Redis ê³µì‹ ë¬¸ì„œ](https://redis.io/documentation) | ê³µì‹ ë¬¸ì„œ | Redis ì „ë°˜ì ì¸ ê°œìš” |
| 2 | [Redis ëª…ë ¹ì–´ ë ˆí¼ëŸ°ìŠ¤](https://redis.io/commands) | ë ˆí¼ëŸ°ìŠ¤ | ëª¨ë“  ëª…ë ¹ì–´ ìƒì„¸ ì„¤ëª… |
| 3 | [ioredis](https://github.com/luin/ioredis) | ë¼ì´ë¸ŒëŸ¬ë¦¬ | Node.js Redis í´ë¼ì´ì–¸íŠ¸ |
| 4 | [Caching Strategies](https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/) | ì•„í‹°í´ | ìºì‹± ì „ëµ ì„ íƒ |
| 5 | [Redis Best Practices](https://redis.io/topics/best-practices) | ëª¨ë²” ì‚¬ë¡€ | Redis ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­ |
| 6 | [Scaling Redis](https://redis.io/topics/cluster-tutorial) | íŠœí† ë¦¬ì–¼ | ê³ ê°€ìš©ì„± ë° í´ëŸ¬ìŠ¤í„°ë§ |
| 7 | [Performance Optimization](https://redis.io/topics/optimization) | ìµœì í™” | ì„±ëŠ¥ íŠœë‹ ë°©ë²• |
| 8 | [Rate Limiting Patterns](https://redis.io/commands/incr#pattern-rate-limiter) | íŒ¨í„´ | Rate Limiting êµ¬í˜„ |
| 9 | [Distributed Locks](https://redis.io/topics/distlock) | íŒ¨í„´ | ë¶„ì‚° ë½ êµ¬í˜„ |

---

### â˜ï¸ AWS ê´€ë ¨

| ë²ˆí˜¸ | ì œëª© | ì„œë¹„ìŠ¤ | ì„¤ëª… |
|------|------|--------|------|
| 10 | [Amazon ECS ê°œë°œì ê°€ì´ë“œ](https://docs.aws.amazon.com/ecs/) | ECS | ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ |
| 11 | [RDS Proxy ì‚¬ìš© ì„¤ëª…ì„œ](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html) | RDS Proxy | DB ì—°ê²° ê´€ë¦¬ |
| 12 | [ElastiCache for Redis](https://docs.aws.amazon.com/elasticache/) | ElastiCache | ê´€ë¦¬í˜• Redis |
| 13 | [Application Load Balancer](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/) | ALB | L7 ë¡œë“œ ë°¸ëŸ°ì‹± |
| 14 | [AWS WAF ê°œë°œì ê°€ì´ë“œ](https://docs.aws.amazon.com/waf/) | WAF | ì›¹ ë°©í™”ë²½ |
| 15 | [ECS Auto Scaling](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html) | ECS | ì˜¤í†  ìŠ¤ì¼€ì¼ë§ ì„¤ì • |
| 16 | [RDS Proxyì™€ Lambda](https://aws.amazon.com/blogs/compute/using-amazon-rds-proxy-with-aws-lambda/) | í†µí•© | Serverless ì—°ë™ |
| 17 | [Container Insights](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights.html) | CloudWatch | ECS ëª¨ë‹ˆí„°ë§ |

---

### ğŸ¢ ì‹¤ë¬´ ì‚¬ë¡€

| ë²ˆí˜¸ | ê¸°ì—… | ì£¼ì œ | í•µì‹¬ ë‚´ìš© |
|------|------|------|----------|
| 18 | [Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2017/the-infrastructure-behind-twitter-scale) | Redis í™œìš© | ëŒ€ê·œëª¨ Redis ìš´ì˜ ì‚¬ë¡€ |
| 19 | [Instagram](https://instagram-engineering.com/storing-hundreds-of-millions-of-simple-key-value-pairs-in-redis-1091ae80f74c) | Redis ì‚¬ìš© | ìˆ˜ì–µ ê±´ ë°ì´í„° ì €ì¥ |
| 20 | [Stack Overflow](https://nickcraver.com/blog/2019/08/06/stack-overflow-how-we-do-app-caching/) | ìºì‹± ì „ëµ | ì‹¤ì œ ìºì‹± ì•„í‚¤í…ì²˜ |
| 21 | [Netflix](https://netflixtechblog.com/tagged/microservices) | MSA | ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ |
| 22 | [Airbnb](https://medium.com/airbnb-engineering/building-services-at-airbnb-part-1-c4c1d8fa811b) | MSA ì „í™˜ | ëª¨ë†€ë¦¬ìŠ¤ì—ì„œ MSAë¡œ |
| 23 | [Uber](https://eng.uber.com/microservice-architecture/) | í™•ì¥ì„± | ëŒ€ê·œëª¨ í™•ì¥ ì•„í‚¤í…ì²˜ |

---