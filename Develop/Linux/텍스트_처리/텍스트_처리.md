---
title: 텍스트 처리
tags: [linux, text-processing, grep, sed, awk, cut, sort, uniq]
updated: 2025-12-08
---

# 텍스트 처리

## 개요

텍스트 파일을 검색, 필터링, 변환하는 명령어. 로그 분석과 데이터 처리에 필수다.

## grep

패턴으로 텍스트를 검색한다.

### 기본 사용

```bash
grep "pattern" file.txt
grep -i "pattern" file.txt          # 대소문자 무시
grep -v "pattern" file.txt          # 매치되지 않는 줄
grep -n "pattern" file.txt          # 줄 번호 포함
grep -c "pattern" file.txt          # 매치 개수만
grep -l "pattern" *.txt             # 파일명만 출력
grep -r "pattern" /path             # 재귀적 검색
```

### 정규표현식

```bash
grep "^pattern" file.txt            # 줄 시작
grep "pattern$" file.txt            # 줄 끝
grep "p.ttern" file.txt             # .은 임의 문자
grep "p[aeiou]ttern" file.txt       # 문자 클래스
grep "p[0-9]ttern" file.txt         # 숫자
grep -E "pattern1|pattern2" file.txt # 확장 정규표현식
```

`-E` 옵션으로 확장 정규표현식을 사용한다. `egrep`과 동일하다.

### 고급 옵션

```bash
grep -A 3 "pattern" file.txt       # 매치 후 3줄
grep -B 3 "pattern" file.txt       # 매치 전 3줄
grep -C 3 "pattern" file.txt       # 매치 전후 3줄
grep -w "pattern" file.txt         # 단어 단위 매치
grep -f patterns.txt file.txt      # 패턴 파일 사용
```

`-A`, `-B`, `-C`는 로그 분석 시 컨텍스트를 확인할 때 유용하다.

## sed

텍스트 스트림을 편집한다.

### 치환

```bash
sed 's/old/new/' file.txt          # 첫 번째 매치만 치환
sed 's/old/new/g' file.txt         # 모든 매치 치환
sed 's/old/new/2' file.txt         # 2번째 매치만 치환
sed -i 's/old/new/g' file.txt      # 파일 직접 수정
sed -i.bak 's/old/new/g' file.txt  # 백업 파일 생성
```

`-i` 옵션은 파일을 직접 수정한다. 백업을 만들거나 테스트 후 사용한다.

### 삭제

```bash
sed '5d' file.txt                  # 5번째 줄 삭제
sed '1,5d' file.txt                 # 1-5번째 줄 삭제
sed '/pattern/d' file.txt           # 패턴 매치 줄 삭제
sed '/^$/d' file.txt                # 빈 줄 삭제
```

### 추가/삽입

```bash
sed '5a\new line' file.txt         # 5번째 줄 뒤에 추가
sed '5i\new line' file.txt         # 5번째 줄 앞에 삽입
sed '$a\new line' file.txt         # 마지막 줄에 추가
```

### 인쇄

```bash
sed -n '5p' file.txt                 # 5번째 줄만 출력
sed -n '1,5p' file.txt             # 1-5번째 줄 출력
sed -n '/pattern/p' file.txt       # 패턴 매치 줄만 출력
```

`-n` 옵션과 `p` 명령어를 조합하여 특정 줄만 출력한다.

### 다중 명령어

```bash
sed -e 's/old1/new1/' -e 's/old2/new2/' file.txt
sed 's/old1/new1/; s/old2/new2/' file.txt
```

## awk

텍스트를 필드 단위로 처리한다.

### 기본 사용

```bash
awk '{print $1}' file.txt          # 첫 번째 필드 출력
awk '{print $1, $3}' file.txt      # 1, 3번째 필드 출력
awk '{print $NF}' file.txt         # 마지막 필드 출력
awk -F: '{print $1}' file.txt      # 구분자 지정 (:)
```

기본 구분자는 공백이다. `-F`로 구분자를 지정한다.

### 패턴 매칭

```bash
awk '/pattern/ {print}' file.txt
awk '$1 == "value" {print}' file.txt
awk '$3 > 100 {print}' file.txt
```

### BEGIN/END

```bash
awk 'BEGIN {FS=":"} {print $1}' file.txt
awk '{sum+=$1} END {print sum}' file.txt
```

`BEGIN`에서 초기화하고, `END`에서 결과를 출력한다.

### 내장 변수

```bash
awk '{print NR, NF, $0}' file.txt
```

- NR: 현재 줄 번호
- NF: 필드 수
- $0: 전체 줄
- FS: 필드 구분자
- OFS: 출력 필드 구분자

### 예시

```bash
# 로그에서 IP 주소 추출
awk '{print $1}' access.log | sort | uniq -c

# 합계 계산
awk '{sum+=$3} END {print sum}' data.txt

# 평균 계산
awk '{sum+=$3; count++} END {print sum/count}' data.txt
```

## cut

필드를 추출한다.

```bash
cut -d: -f1 /etc/passwd            # 구분자로 필드 추출
cut -f1,3 file.txt                 # 1, 3번째 필드
cut -c1-10 file.txt                # 1-10번째 문자
cut -d',' -f2 file.csv
```

간단한 필드 추출에는 `cut`이 빠르다. 복잡한 처리는 `awk`를 사용한다.

## sort

텍스트를 정렬한다.

```bash
sort file.txt
sort -n file.txt                   # 숫자 정렬
sort -r file.txt                   # 역순 정렬
sort -u file.txt                   # 중복 제거
sort -k2 file.txt                  # 2번째 필드로 정렬
sort -t: -k3 -n /etc/passwd
```

`-n` 옵션 없이 숫자를 정렬하면 문자열로 정렬된다.

## uniq

중복된 줄을 제거한다.

```bash
uniq file.txt                      # 연속된 중복만 제거
uniq -c file.txt                   # 개수 포함
uniq -d file.txt                   # 중복된 줄만
uniq -u file.txt                   # 중복되지 않은 줄만
sort file.txt | uniq               # 모든 중복 제거
```

`uniq`는 정렬된 파일에서만 제대로 동작한다. `sort`와 함께 사용한다.

## wc

줄, 단어, 바이트 수를 센다.

```bash
wc file.txt                        # 줄, 단어, 바이트
wc -l file.txt                     # 줄 수만
wc -w file.txt                     # 단어 수만
wc -c file.txt                     # 바이트 수만
wc -m file.txt                     # 문자 수
```

## head / tail

파일의 앞부분/뒷부분을 출력한다.

```bash
head file.txt                      # 처음 10줄
head -n 20 file.txt
tail file.txt                      # 마지막 10줄
tail -n 20 file.txt
tail -f file.txt                   # 실시간 모니터링
tail -F file.txt                   # 파일 재생성 시에도 모니터링
```

`tail -f`는 로그 파일을 실시간으로 모니터링한다.

## tr

문자를 변환하거나 삭제한다.

```bash
tr 'a-z' 'A-Z' < file.txt          # 소문자를 대문자로
tr -d '\n' < file.txt               # 줄바꿈 삭제
tr -s ' ' < file.txt               # 연속된 공백을 하나로
tr -d '0-9' < file.txt             # 숫자 삭제
```

## paste

파일을 열 단위로 병합한다.

```bash
paste file1.txt file2.txt
paste -d: file1.txt file2.txt       # 구분자 지정
```

## join

두 파일을 공통 필드로 결합한다.

```bash
join file1.txt file2.txt
join -1 2 -2 1 file1.txt file2.txt  # 필드 지정
```

## 로그 분석

로그 파일에서 필요한 정보를 추출한다.

```bash
# 에러 로그만
grep -i error /var/log/app.log

# 특정 시간대
grep "2025-01-01 10:" /var/log/app.log

# IP 주소별 접근 횟수
awk '{print $1}' access.log | sort | uniq -c | sort -rn

# 응답 시간 1초 이상
awk '$NF > 1.0 {print}' access.log
```

로그 분석은 정규표현식을 활용한다. `awk`는 필드 처리에 유용하다.

## 데이터 변환

파일 형식을 변환한다.

```bash
# CSV를 탭으로
sed 's/,/\t/g' file.csv

# 빈 줄 제거
sed '/^$/d' file.txt

# 줄 번호 추가
awk '{print NR, $0}' file.txt
```

`sed`는 간단한 치환에, `awk`는 복잡한 처리에 사용한다.

## 파일 정리

```bash
# 중복 제거
sort file.txt | uniq > unique.txt

# 숫자 정렬
sort -n -k2 file.txt > sorted.txt

# 필드 추출
cut -d: -f1,3 /etc/passwd
```

정렬은 `sort`로 하고, 중복은 `uniq`로 제거한다. `cut`은 간단한 필드 추출에 사용한다.
