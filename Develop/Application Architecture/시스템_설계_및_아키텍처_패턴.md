---
title: 시스템 설계 및 아키텍처 패턴
tags: [system-design, architecture, scalability, load-balancing, caching, distributed-systems]
updated: 2025-11-01
---

# 시스템 설계 및 아키텍처 패턴

## 📋 목차
1. [시스템 설계 기본 원칙](#시스템-설계-기본-원칙)
2. [CAP 정리와 분산 시스템의 트레이드오프](#cap-정리와-분산-시스템의-트레이드오프)
3. [확장 가능한 시스템 설계](#확장-가능한-시스템-설계)
4. [로드 밸런싱 전략](#로드-밸런싱-전략)
5. [분산 락과 동시성 제어](#분산-락과-동시성-제어)
6. [다층 캐싱 전략](#다층-캐싱-전략)
7. [데이터베이스 샤딩 및 파티셔닝](#데이터베이스-샤딩-및-파티셔닝)
8. [대규모 시스템 설계 사례](#대규모-시스템-설계-사례)

### 📌 통합된 기존 파일들
이 문서는 다음 기존 파일들의 내용을 통합한 것입니다:
- **웹 통신의 흐름**: 로드 밸런서, 웹 서버, 애플리케이션 서버 레벨별 처리
- **Nginx 설정**: 로드 밸런싱 전략, 캐싱 설정, 마이크로서비스 아키텍처
- **데이터베이스 샤딩**: 수평/수직 샤딩, 샤딩 키 선택, 쿼리 라우팅
- **DB Proxy**: 연결 관리, 부하 분산, 성능 최적화
- **대량 API 처리**: Redis 활용, 비동기 처리, 부하 분산

---

## 시스템 설계 기본 원칙

### 설계의 핵심 목표

시스템 설계는 비즈니스 요구사항을 만족하면서도 장기적으로 유지보수 가능한 시스템을 만드는 과정입니다. 단순히 코드를 작성하는 것을 넘어, 시스템의 전체적인 구조와 각 컴포넌트 간의 관계를 정의하는 것이 핵심입니다.

#### 1. 단순성 (Simplicity)

복잡한 시스템은 이해하기 어렵고, 디버깅하기 어려우며, 확장하기 어렵습니다. 시스템 설계의 첫 번째 원칙은 가능한 한 단순하게 만드는 것입니다.

**단순성을 위한 접근법:**
- **KISS 원칙**: Keep It Simple, Stupid - 불필요한 복잡성을 피합니다
- **YAGNI 원칙**: You Aren't Gonna Need It - 당장 필요하지 않은 기능은 구현하지 않습니다
- **명확한 책임 분리**: 각 컴포넌트는 하나의 명확한 역할만 담당합니다
- **일관된 패턴 사용**: 비슷한 문제에는 비슷한 해결책을 적용합니다

**예시:**
```
복잡한 설계:
API Gateway → Load Balancer → Service Mesh → Proxy → Cache → App Server → DB

단순한 설계:
Load Balancer → App Server → DB
```

처음부터 복잡한 아키텍처를 도입하기보다는, 필요에 따라 점진적으로 복잡성을 추가하는 것이 바람직합니다.

#### 2. 확장성 (Scalability)

시스템이 성장할 때 처리할 수 있는 부하의 양이 증가할 수 있어야 합니다. 확장성은 두 가지 차원에서 고려해야 합니다.

**수평 확장 (Scale Out):**
- **정의**: 서버의 대수를 늘려서 처리 용량을 증가시키는 방법
- **장점**: 
  - 이론상 무제한 확장 가능
  - 장애 발생 시 영향 범위가 제한적
  - 클라우드 환경에서 비용 효율적
- **단점**:
  - 상태 관리가 복잡함 (세션, 캐시 등)
  - 네트워크 오버헤드 증가
  - 데이터 일관성 유지가 어려움

**수직 확장 (Scale Up):**
- **정의**: 서버의 사양(CPU, 메모리, 디스크)을 업그레이드하는 방법
- **장점**:
  - 구현이 단순함
  - 데이터 일관성 유지가 쉬움
  - 네트워크 오버헤드가 없음
- **단점**:
  - 물리적 한계 존재
  - 단일 장애점(SPOF) 문제
  - 비용이 기하급수적으로 증가

**확장성 패턴:**

| 패턴 | 설명 | 사용 시나리오 |
|------|------|-------------|
| Stateless 설계 | 서버가 상태를 저장하지 않음 | 웹 애플리케이션, API 서버 |
| 데이터 파티셔닝 | 데이터를 여러 노드에 분산 | 대용량 데이터베이스 |
| 읽기 전용 복제본 | 읽기 부하를 여러 노드에 분산 | 읽기 위주 서비스 |
| 비동기 처리 | 시간이 오래 걸리는 작업을 백그라운드에서 처리 | 이메일 발송, 리포트 생성 |

#### 3. 신뢰성 (Reliability)

시스템이 장애 상황에서도 정상적으로 동작하거나 빠르게 복구할 수 있어야 합니다.

**신뢰성 측정 지표:**

```
MTBF (Mean Time Between Failures)
= 전체 운영 시간 / 장애 발생 횟수
→ 값이 클수록 안정적

MTTR (Mean Time To Recovery)
= 총 복구 시간 / 장애 발생 횟수
→ 값이 작을수록 빠른 복구

가용성 = MTBF / (MTBF + MTTR)
```

**신뢰성 향상 방법:**

1. **중복성 (Redundancy)**
   - 핵심 컴포넌트를 여러 개 배치하여 하나가 실패해도 다른 것이 대신함
   - 예: 마스터-슬레이브 데이터베이스, 다중 가용 영역 배포

2. **장애 격리 (Fault Isolation)**
   - 한 컴포넌트의 장애가 전체 시스템으로 확산되지 않도록 방지
   - 예: 서킷 브레이커, 벌크헤드 패턴

3. **자동 복구 (Auto Recovery)**
   - 장애 감지 시 자동으로 복구 작업 수행
   - 예: 헬스체크 기반 자동 재시작, 자동 스케일링

4. **백업 및 복원**
   - 정기적인 데이터 백업과 빠른 복원 절차
   - 예: 시점 복구(Point-in-Time Recovery), 스냅샷

#### 4. 성능 (Performance)

시스템이 요청을 얼마나 빠르게 처리하는지를 나타냅니다.

**성능 지표:**

| 지표 | 설명 | 목표 예시 |
|------|------|---------|
| 응답 시간 | 요청부터 응답까지 걸리는 시간 | P95 < 200ms |
| 처리량 | 단위 시간당 처리하는 요청 수 | 1000 RPS |
| 동시 사용자 | 동시에 처리 가능한 사용자 수 | 10,000명 |
| 리소스 사용률 | CPU, 메모리, 디스크 사용률 | CPU < 70% |

**성능 최적화 전략:**

1. **캐싱**
   - 자주 조회되는 데이터를 빠른 저장소에 보관
   - 데이터베이스 부하 감소, 응답 속도 향상

2. **데이터베이스 최적화**
   - 인덱스 활용, 쿼리 최적화
   - 커넥션 풀 관리

3. **비동기 처리**
   - 시간이 오래 걸리는 작업을 백그라운드에서 처리
   - 사용자 경험 개선

4. **CDN 활용**
   - 정적 콘텐츠를 사용자와 가까운 곳에 배치
   - 네트워크 지연 시간 감소

#### 5. 보안 (Security)

시스템과 데이터를 무단 접근과 공격으로부터 보호합니다.

**보안 계층:**

```
네트워크 보안
├─ 방화벽
├─ DDoS 방어
└─ VPN

애플리케이션 보안
├─ 인증/인가
├─ 입력 검증
└─ SQL 인젝션 방지

데이터 보안
├─ 암호화 (전송 중, 저장)
├─ 접근 제어
└─ 백업 및 복구
```

### 설계 시 고려사항

#### 트레이드오프 이해하기

모든 요구사항을 동시에 완벽하게 만족시킬 수는 없습니다. 설계 시 다양한 트레이드오프를 이해하고 비즈니스 우선순위에 따라 선택해야 합니다.

**일반적인 트레이드오프:**

| 선택 A | vs | 선택 B | 고려사항 |
|--------|-----|--------|---------|
| 일관성 | vs | 가용성 | CAP 정리에 따른 선택 |
| 성능 | vs | 보안 | 암호화는 성능 오버헤드 발생 |
| 단순성 | vs | 유연성 | 추상화 레벨 결정 |
| 개발 속도 | vs | 최적화 | 조기 최적화 vs 빠른 출시 |
| 중복성 | vs | 비용 | 고가용성 vs 인프라 비용 |

#### 점진적 개선

처음부터 완벽한 시스템을 만들 수는 없습니다. 작게 시작하여 점진적으로 개선하는 접근이 필요합니다.

**개선 단계:**

```
1단계: MVP (Minimum Viable Product)
- 핵심 기능만 구현
- 모놀리식 아키텍처
- 단일 데이터베이스

2단계: 성장기
- 캐싱 도입
- 읽기 전용 복제본 추가
- CDN 활용

3단계: 확장기
- 마이크로서비스로 분리
- 데이터베이스 샤딩
- 메시지 큐 도입

4단계: 성숙기
- 서비스 메시 도입
- 다지역 배포
- 완전한 자동화
```

---

## CAP 정리와 분산 시스템의 트레이드오프

### CAP 정리란?

CAP 정리(CAP Theorem)는 2000년 에릭 브루어(Eric Brewer)가 제안한 이론으로, 분산 시스템에서 다음 세 가지 속성을 동시에 모두 만족시킬 수 없다는 것을 증명합니다.

#### 1. Consistency (일관성)

**정의**: 모든 노드가 동시에 같은 데이터를 보여주는 속성입니다.

**특징:**
- 한 노드에서 데이터를 업데이트하면, 즉시 모든 노드에서 동일한 값을 읽을 수 있어야 합니다
- Strong Consistency(강한 일관성)를 의미합니다
- 데이터 정확성이 최우선입니다

**실제 사례:**
```
은행 계좌 시스템:
1. 사용자 A가 서울 ATM에서 잔액 조회: 100만원
2. 사용자 A가 부산 ATM에서 50만원 인출
3. 사용자 A가 다시 서울 ATM에서 잔액 조회: 50만원 (즉시 반영)
```

이 경우 일관성이 보장되지 않으면 두 번 인출할 수 있는 문제가 발생합니다.

#### 2. Availability (가용성)

**정의**: 시스템이 항상 응답하는 속성입니다.

**특징:**
- 모든 요청은 실패하지 않고 응답을 받습니다
- 장애가 발생해도 서비스는 계속 동작합니다
- 응답 속도가 빠르지 않더라도 반드시 응답합니다

**실제 사례:**
```
소셜 미디어 피드:
1. 서버 A가 다운되었지만
2. 사용자는 서버 B에서 피드를 계속 볼 수 있습니다
3. 최신 게시물이 아닐 수 있지만 서비스는 중단되지 않습니다
```

#### 3. Partition Tolerance (분할 내성)

**정의**: 네트워크 분할 상황에서도 시스템이 동작하는 속성입니다.

**특징:**
- 네트워크 장애로 노드 간 통신이 불가능해도 시스템은 계속 동작합니다
- 실제 분산 시스템에서는 네트워크 분할이 필연적으로 발생합니다
- 따라서 P는 선택이 아닌 필수입니다

**실제 사례:**
```
글로벌 서비스:
1. 해저 케이블 장애로 아시아-미국 간 통신 두절
2. 각 지역은 독립적으로 서비스를 계속 제공
3. 네트워크 복구 후 데이터 동기화
```

### CAP 정리의 실제 적용

현실적으로 네트워크 분할은 발생할 수밖에 없으므로, 실제로는 **C와 A 중 하나를 선택**해야 합니다.

#### CP 시스템 (Consistency + Partition Tolerance)

**특징**: 일관성을 보장하지만, 가용성을 희생합니다.

**동작 방식:**
```
네트워크 분할 발생 시:
1. 일부 노드와 통신 불가
2. 데이터 일관성을 보장할 수 없음
3. 서비스 중단 또는 오류 반환 선택
```

**적합한 사용 사례:**
- **금융 시스템**: 계좌 잔액, 거래 내역
- **재고 관리**: 상품 수량, 주문 처리
- **예약 시스템**: 좌석 예약, 호텔 예약
- **인증 시스템**: 사용자 인증, 권한 관리

**대표 기술:**
- **관계형 데이터베이스**: MySQL, PostgreSQL (트랜잭션 기반)
- **HBase**: Hadoop 기반 분산 데이터베이스
- **Redis (특정 설정)**: 동기식 복제 사용 시
- **ZooKeeper**: 분산 코디네이션 서비스

**예시 시나리오:**
```
온라인 티켓 예매 시스템:
- 콘서트 티켓 10,000장 판매
- 네트워크 분할 발생
- 일관성 보장을 위해 일부 지역에서 예매 중단
- "현재 예매가 불가능합니다" 오류 메시지 표시
- 잘못된 중복 판매보다 서비스 중단이 더 나은 선택
```

#### AP 시스템 (Availability + Partition Tolerance)

**특징**: 가용성을 보장하지만, 일시적으로 일관성을 희생합니다.

**동작 방식:**
```
네트워크 분할 발생 시:
1. 일부 노드와 통신 불가
2. 각 노드가 독립적으로 요청 처리
3. 네트워크 복구 후 데이터 동기화 (Eventual Consistency)
```

**적합한 사용 사례:**
- **소셜 미디어**: 게시물, 좋아요, 댓글
- **검색 엔진**: 인덱싱, 검색 결과
- **추천 시스템**: 상품 추천, 콘텐츠 추천
- **로그 수집**: 애플리케이션 로그, 분석 데이터

**대표 기술:**
- **Cassandra**: 분산 NoSQL 데이터베이스
- **DynamoDB**: AWS 관리형 NoSQL
- **Riak**: 분산 키-값 저장소
- **CouchDB**: 문서 기반 NoSQL

**예시 시나리오:**
```
SNS 좋아요 기능:
- 사용자가 게시물에 좋아요 클릭
- 네트워크 분할 발생
- 각 지역 서버가 독립적으로 좋아요 수 증가
- 잠시 동안 지역마다 다른 좋아요 수 표시
- 네트워크 복구 후 실제 좋아요 수로 수렴
- 서비스 중단 없이 계속 사용 가능
```

### 최종 일관성 (Eventual Consistency)

AP 시스템에서 사용하는 일관성 모델로, "언젠가는" 모든 노드가 같은 데이터를 가지게 된다는 개념입니다.

**동작 원리:**
```
1. 초기 상태: 모든 노드가 Value = 10
2. 노드 A에서 Value = 20으로 업데이트
3. 네트워크 분할로 노드 B는 아직 Value = 10
4. 잠시 동안 불일치 상태
5. 네트워크 복구 후 노드 B도 Value = 20으로 동기화
```

**최종 일관성의 특징:**

| 특징 | 설명 |
|------|------|
| Read-your-writes | 자신이 쓴 데이터는 즉시 읽을 수 있음 |
| Monotonic reads | 한 번 읽은 데이터보다 오래된 데이터는 읽지 않음 |
| Monotonic writes | 쓰기 작업의 순서가 보장됨 |
| Writes-follow-reads | 읽은 데이터 이후의 쓰기만 허용 |

### CAP 정리 선택 가이드

시스템의 특성에 따라 적절한 모델을 선택해야 합니다.

| 질문 | CP 선택 | AP 선택 |
|------|---------|---------|
| 데이터 정확성이 최우선인가? | ✓ | |
| 서비스 중단이 허용되는가? | ✓ | |
| 일시적 불일치가 허용되는가? | | ✓ |
| 높은 가용성이 필요한가? | | ✓ |
| 글로벌 분산이 필요한가? | | ✓ |

**의사결정 흐름:**
```
데이터 불일치 시 비즈니스 영향이 큰가?
├─ 예 → CP 시스템 선택
│     예: 금융, 재고, 예약
│
└─ 아니오 → 서비스 중단 시 비즈니스 영향이 큰가?
      ├─ 예 → AP 시스템 선택
      │     예: SNS, 검색, 로그
      │
      └─ 아니오 → CP 또는 AP 중 구현 용이성으로 선택
```

### CAP 정리 실제 구현 예제

#### CP 시스템: 은행 계좌 시스템

**핵심 원리:**
- 모든 복제본에 동기적으로 트랜잭션 적용
- 하나라도 실패하면 전체 롤백
- 네트워크 분할 시 서비스 중단 선택

**구현 개념:**
```typescript
class BankingService {
  async transferMoney(from: string, to: string, amount: number) {
    // 1. 트랜잭션 시작
    await this.db.query('BEGIN');
    
    // 2. 잔액 확인 및 차감 (FOR UPDATE로 락 획득)
    const balance = await this.checkBalance(from);
    if (balance < amount) throw new Error('잔액 부족');
    
    // 3. 계좌 업데이트
    await this.updateAccounts(from, to, amount);
    
    // 4. 모든 복제본에 동기화 (핵심!)
    await this.syncToAllReplicas(from, to, amount);
    
    // 5. 모든 복제본이 성공해야 커밋
    await this.db.query('COMMIT');
  }
  
  async syncToAllReplicas(from: string, to: string, amount: number) {
    const replicas = ['replica1', 'replica2', 'replica3'];
    
    // 모든 복제본에 동시에 적용
    await Promise.all(
      replicas.map(replica => 
        this.applyTransaction(replica, from, to, amount)
      )
    );
    // 하나라도 실패하면 예외 발생 → 전체 롤백
  }
}
```

**동작 시나리오:**
```
정상 상황:
1. 모든 복제본에 트랜잭션 성공 → 커밋
2. 모든 사용자가 동일한 잔액 확인 가능

네트워크 분할 상황:
1. 일부 복제본 통신 불가
2. 일관성 보장 불가 → 트랜잭션 실패
3. 사용자에게 오류 메시지 반환
4. 가용성보다 데이터 정확성 우선
```

#### AP 시스템: 소셜 미디어 피드

**핵심 원리:**
- 각 노드가 독립적으로 요청 처리
- 네트워크 분할 시에도 서비스 계속 제공
- 최종 일관성(Eventual Consistency) 허용

**구현 개념:**
```typescript
class FeedService {
  async getFeed(userId: string) {
    try {
      // 1. 캐시 먼저 확인
      const cached = await this.getFromCache(userId);
      if (cached) return cached;
      
      // 2. 네트워크 분할 상황 체크
      if (this.isPartitioned) {
        // 분할 시: 오래된 캐시라도 반환 (가용성 우선)
        return this.getStaleCache(userId) || [];
      }
      
      // 3. 정상 상황: DB에서 최신 데이터 조회
      return await this.getFeedFromDB(userId);
      
    } catch (error) {
      // 4. 에러 발생해도 캐시된 데이터 반환 (가용성 우선)
      return this.getCachedFeed(userId) || [];
    }
  }
  
  async createPost(userId: string, content: string) {
    const postId = this.generateId();
    
    try {
      if (this.isPartitioned) {
        // 분할 시: 로컬에 저장, 나중에 동기화
        await this.saveLocally(postId, userId, content);
      } else {
        // 정상 시: 즉시 DB에 저장
        await this.saveToDB(postId, userId, content);
      }
      
      // 성공 여부와 상관없이 postId 반환 (가용성 우선)
      return postId;
      
    } catch (error) {
      // 에러 발생해도 postId 반환
      return postId;
    }
  }
}
```

**동작 시나리오:**
```
정상 상황:
1. 모든 노드가 최신 데이터 조회
2. 새 게시물이 모든 노드에 즉시 반영

네트워크 분할 상황:
1. 각 노드가 독립적으로 서비스 제공
2. 오래된 데이터를 보여줄 수 있음 (예: 좋아요 수 불일치)
3. 새 게시물은 로컬에 저장
4. 서비스는 계속 사용 가능

네트워크 복구 후:
1. 로컬에 저장된 데이터 동기화
2. 모든 노드가 최종적으로 같은 상태로 수렴
3. 일시적 불일치는 허용되지만 결국 일관성 확보
```

### CAP 정리 비교 요약

| 시스템 유형 | 선택 | 동작 방식 | 사용 사례 |
|-----------|------|---------|---------|
| **CP 시스템** | 일관성 + 분할 내성 | • 모든 노드 동기화<br>• 분할 시 서비스 중단<br>• 강한 일관성 보장 | • 은행 거래<br>• 재고 관리<br>• 예약 시스템 |
| **AP 시스템** | 가용성 + 분할 내성 | • 독립적 노드 운영<br>• 분할 시에도 서비스 제공<br>• 최종 일관성 허용 | • SNS 피드<br>• 검색 엔진<br>• 로그 수집 |

**핵심 차이점:**
```
데이터 불일치가 발생하면?
├─ CP: 서비스 중단 (503 Error)
└─ AP: 오래된 데이터라도 반환

네트워크 문제가 생기면?
├─ CP: 일관성 보장 불가 → 에러 반환
└─ AP: 각 노드가 독립적으로 동작

복구 시점에는?
├─ CP: 즉시 정확한 데이터
└─ AP: 시간이 지나면서 일관성 확보
```

---

## 확장 가능한 시스템 설계

### 확장성이란?

확장성(Scalability)은 시스템의 부하가 증가할 때 적절히 대응할 수 있는 능력을 의미합니다. 단순히 더 많은 서버를 추가하는 것이 아니라, 비용 효율적으로 성능을 유지하면서 성장할 수 있는 시스템을 설계하는 것이 핵심입니다.

### 확장성의 종류

#### 1. 수평 확장 (Horizontal Scaling / Scale Out)

**개념**: 동일한 사양의 서버를 추가하여 전체 처리 용량을 늘리는 방식입니다.

**작동 원리:**
```
초기: 서버 1대 → 1000 RPS 처리
확장: 서버 5대 → 5000 RPS 처리
```

**적용 사례:**
- **웹 애플리케이션 서버**: Stateless 서버를 여러 대 배포
- **데이터베이스 읽기 복제본**: 읽기 전용 슬레이브 추가
- **캐시 서버**: Redis/Memcached 클러스터
- **메시지 큐**: Kafka 파티션 추가

**장점:**
- **이론상 무제한 확장**: 서버를 계속 추가할 수 있습니다
- **장애 격리**: 한 서버의 장애가 전체에 영향을 주지 않습니다
- **점진적 확장**: 필요한 만큼만 추가하여 비용 최적화
- **클라우드 친화적**: Auto Scaling과 잘 어울립니다

**단점:**
- **상태 관리 복잡성**: 세션, 캐시 등의 상태를 공유해야 합니다
- **데이터 동기화**: 여러 노드 간 데이터 일관성 유지가 어렵습니다
- **네트워크 오버헤드**: 노드 간 통신 비용이 발생합니다
- **복잡한 배포**: 여러 서버에 동시 배포가 필요합니다

**구현 고려사항:**
```
1. Stateless 설계
   - 서버에 상태를 저장하지 않음
   - 모든 상태는 외부 저장소(DB, 캐시)에 보관

2. 세션 관리
   - Sticky Session (세션 affinity)
   - Session Clustering
   - 외부 세션 저장소 (Redis)

3. 로드 밸런싱
   - Round Robin
   - Least Connections
   - IP Hash

4. 데이터 파티셔닝
   - Sharding
   - Replication
```

#### 2. 수직 확장 (Vertical Scaling / Scale Up)

**개념**: 기존 서버의 사양을 업그레이드하여 처리 능력을 향상시키는 방식입니다.

**작동 원리:**
```
초기: 4 Core CPU, 8GB RAM → 1000 RPS 처리
확장: 16 Core CPU, 64GB RAM → 4000 RPS 처리
```

**적용 사례:**
- **데이터베이스 마스터**: 쓰기 성능 향상
- **레거시 애플리케이션**: 코드 변경 없이 성능 향상
- **연산 집약적 작업**: 머신러닝, 데이터 분석
- **단일 프로세스 애플리케이션**: 멀티프로세싱이 어려운 경우

**장점:**
- **구현 단순성**: 코드 변경 없이 즉시 적용 가능
- **데이터 일관성**: 단일 노드이므로 동기화 불필요
- **낮은 네트워크 오버헤드**: 노드 간 통신이 없습니다
- **관리 용이성**: 하나의 서버만 관리하면 됩니다

**단점:**
- **물리적 한계**: CPU, 메모리에는 최대치가 존재합니다
- **단일 장애점(SPOF)**: 서버가 다운되면 전체 서비스 중단
- **비용 비효율**: 사양이 높아질수록 가격이 기하급수적으로 증가
- **다운타임**: 업그레이드 시 서비스 중단 필요

**비용 곡선:**
```
수직 확장 비용:
2 Core → 4 Core: 2배
4 Core → 8 Core: 3배
8 Core → 16 Core: 5배
16 Core → 32 Core: 10배
```

#### 확장 전략 비교 매트릭스

| 기준 | 수평 확장 | 수직 확장 |
|------|---------|---------|
| **최대 확장 한계** | 무제한 | 하드웨어 한계 존재 |
| **비용 효율성** | 선형적 증가 | 기하급수적 증가 |
| **구현 난이도** | 높음 (아키텍처 변경 필요) | 낮음 (사양만 증가) |
| **가용성** | 높음 (다중 노드) | 낮음 (SPOF) |
| **데이터 일관성** | 복잡함 | 단순함 |
| **적합한 상황** | 장기 성장 계획 | 단기 해결책 |

#### 하이브리드 확장 전략

실제 프로덕션 환경에서는 두 가지 전략을 조합하여 사용합니다.

**일반적인 패턴:**
```
1단계: 수직 확장으로 시작
   - 빠른 구현
   - 초기 비용 절감
   
2단계: 수평 확장 준비
   - Stateless 아키텍처로 리팩토링
   - 로드 밸런서 도입
   
3단계: 수평 확장 적용
   - 서버 대수 증가
   - Auto Scaling 설정
   
4단계: 수직 + 수평 혼합
   - 각 노드를 적절한 사양으로 유지
   - 필요에 따라 노드 추가
```

**예시: 전자상거래 플랫폼**
```
웹 서버: 수평 확장 (여러 대의 중간 사양 서버)
└─ 트래픽 변동이 크므로 Auto Scaling 적용

데이터베이스:
├─ 마스터: 수직 확장 (고사양 단일 서버)
│   └─ 쓰기 성능이 중요하고 일관성 필요
└─ 슬레이브: 수평 확장 (여러 대의 읽기 전용 서버)
    └─ 읽기 부하 분산

캐시: 수평 확장 (Redis Cluster)
└─ 데이터 파티셔닝으로 메모리 확장
```

### 2. 시스템 설계 원칙

#### 단일 책임 원칙 (Single Responsibility)
```javascript
// ❌ 잘못된 예시: 여러 책임을 가진 클래스
class UserService {
  createUser(userData) { /* 사용자 생성 */ }
  sendEmail(email) { /* 이메일 발송 */ }
  logActivity(activity) { /* 활동 로깅 */ }
  validatePassword(password) { /* 비밀번호 검증 */ }
}

// ✅ 올바른 예시: 단일 책임을 가진 클래스들
class UserService {
  createUser(userData) { /* 사용자 생성만 담당 */ }
}

class EmailService {
  sendEmail(email) { /* 이메일 발송만 담당 */ }
}

class ActivityLogger {
  logActivity(activity) { /* 로깅만 담당 */ }
}

class PasswordValidator {
  validatePassword(password) { /* 비밀번호 검증만 담당 */ }
}
```

#### 느슨한 결합 (Loose Coupling)
```javascript
// ❌ 강한 결합
class OrderService {
  constructor() {
    this.emailService = new EmailService(); // 직접 의존
    this.paymentService = new PaymentService(); // 직접 의존
  }
}

// ✅ 느슨한 결합 (의존성 주입)
class OrderService {
  constructor(emailService, paymentService) {
    this.emailService = emailService;
    this.paymentService = paymentService;
  }
}

// 사용 시
const emailService = new EmailService();
const paymentService = new PaymentService();
const orderService = new OrderService(emailService, paymentService);
```

#### 높은 응집성 (High Cohesion)
```javascript
// ✅ 높은 응집성: 관련된 기능들이 함께 모여있음
class UserProfileManager {
  // 사용자 프로필과 관련된 모든 기능
  updateProfile(userId, profileData) { }
  getProfile(userId) { }
  validateProfile(profileData) { }
  uploadAvatar(userId, imageData) { }
  deleteProfile(userId) { }
}
```

### 3. 마이크로서비스 아키텍처 패턴

#### API Gateway 패턴
```javascript
// API Gateway 구현 예시
class APIGateway {
  constructor() {
    this.services = {
      user: new UserService(),
      product: new ProductService(),
      order: new OrderService()
    };
  }

  async routeRequest(path, method, data) {
    const [service, endpoint] = this.parsePath(path);
    
    if (!this.services[service]) {
      throw new Error(`Service ${service} not found`);
    }

    // 인증/인가 체크
    await this.authenticate(data.token);
    
    // 서비스로 라우팅
    return await this.services[service][endpoint](data);
  }

  parsePath(path) {
    const parts = path.split('/').filter(p => p);
    return [parts[1], parts[2]]; // /api/user/profile -> ['user', 'profile']
  }
}
```

#### Circuit Breaker 패턴
```javascript
class CircuitBreaker {
  constructor(threshold = 5, timeout = 60000) {
    this.failureThreshold = threshold;
    this.timeout = timeout;
    this.failureCount = 0;
    this.lastFailureTime = null;
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
  }

  async execute(operation) {
    if (this.state === 'OPEN') {
      if (Date.now() - this.lastFailureTime > this.timeout) {
        this.state = 'HALF_OPEN';
      } else {
        throw new Error('Circuit breaker is OPEN');
      }
    }

    try {
      const result = await operation();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }

  onSuccess() {
    this.failureCount = 0;
    this.state = 'CLOSED';
  }

  onFailure() {
    this.failureCount++;
    this.lastFailureTime = Date.now();
    
    if (this.failureCount >= this.failureThreshold) {
      this.state = 'OPEN';
    }
  }
}
```

---

## 로드 밸런싱 전략

### 로드 밸런싱이란?

로드 밸런싱(Load Balancing)은 들어오는 네트워크 트래픽을 여러 서버에 분산시켜 시스템의 가용성과 성능을 향상시키는 기술입니다. 단일 서버에 부하가 집중되는 것을 방지하고, 서버 장애 시에도 서비스를 지속할 수 있도록 합니다.

### 로드 밸런서의 역할

#### 1. 트래픽 분산
여러 서버에 요청을 균등하게 또는 적절한 알고리즘에 따라 분산합니다.

#### 2. 헬스 체크
백엔드 서버의 상태를 주기적으로 확인하여, 장애가 발생한 서버로는 트래픽을 보내지 않습니다.

```
헬스 체크 방식:
- TCP 연결 확인
- HTTP 응답 코드 확인 (200 OK)
- 특정 엔드포인트 호출 (/health, /ping)
- 응답 시간 측정
```

#### 3. 세션 유지
특정 사용자의 요청을 같은 서버로 라우팅하여 세션 일관성을 유지합니다.

#### 4. SSL/TLS 종료
HTTPS 복호화를 로드 밸런서에서 처리하여 백엔드 서버의 부담을 줄입니다.

### 로드 밸런서의 종류

#### 1. L4 로드 밸런서 (Transport Layer)

**특징:**
- OSI 4계층(전송 계층)에서 동작
- IP 주소와 포트 번호만 확인
- 빠른 처리 속도
- 패킷 내용을 확인하지 않음

**작동 방식:**
```
클라이언트 → [L4 LB] → 서버
              ↓
         IP:Port 기반
         라우팅 결정
```

**장점:**
- 처리 속도가 매우 빠름
- 하드웨어 기반 구현 가능
- 낮은 레이턴시

**단점:**
- 패킷 내용 기반 라우팅 불가
- 쿠키나 헤더 기반 라우팅 불가
- 세밀한 제어 어려움

**사용 사례:**
- 고성능이 필요한 경우
- 단순한 분산 로직
- TCP/UDP 프로토콜

#### 2. L7 로드 밸런서 (Application Layer)

**특징:**
- OSI 7계층(애플리케이션 계층)에서 동작
- HTTP 헤더, 쿠키, URL 경로 확인
- 콘텐츠 기반 라우팅 가능
- 더 높은 레이턴시

**작동 방식:**
```
클라이언트 → [L7 LB] → 서버
              ↓
      HTTP 헤더/URL 분석
         라우팅 결정
```

**장점:**
- 콘텐츠 기반 라우팅
- URL 경로별 분산 가능
- A/B 테스팅 용이
- 캐싱, 압축 등 추가 기능

**단점:**
- L4보다 느림
- 더 많은 리소스 필요
- 복잡한 설정

**사용 사례:**
- 마이크로서비스 아키텍처
- URL 기반 라우팅
- 카나리 배포
- API Gateway

#### L4 vs L7 비교

| 항목 | L4 로드 밸런서 | L7 로드 밸런서 |
|------|--------------|--------------|
| **계층** | Transport (4계층) | Application (7계층) |
| **판단 기준** | IP, Port | HTTP 헤더, URL, 쿠키 |
| **속도** | 매우 빠름 | 상대적으로 느림 |
| **기능** | 기본적 | 고급 기능 다수 |
| **비용** | 저렴 | 상대적으로 비싸 |
| **사용 예** | NLB, HAProxy | ALB, Nginx |

### 로드 밸런싱 알고리즘

#### 1. Round Robin (라운드 로빈)

**개념**: 요청을 순차적으로 돌아가며 각 서버에 균등하게 분배합니다.

```
요청 순서: 1 → 2 → 3 → 1 → 2 → 3 ...
서버 1: ■ ■ ■
서버 2: ■ ■ ■
서버 3: ■ ■ ■
```

**장점:**
- 구현이 매우 간단
- 모든 서버에 균등하게 분산
- 추가 상태 관리 불필요

**단점:**
- 서버 성능 차이 무시
- 요청 처리 시간 차이 무시
- 일부 서버 과부하 가능

**적합한 경우:**
- 모든 서버 사양이 동일할 때
- 요청 처리 시간이 비슷할 때
- 단순한 분산이 필요할 때

#### 2. Least Connections (최소 연결)

**개념**: 현재 연결 수가 가장 적은 서버로 요청을 보냅니다.

```
서버 1: 연결 5개 → 
서버 2: 연결 3개 → 선택!
서버 3: 연결 7개 →
```

**장점:**
- 서버 부하를 동적으로 고려
- 처리 시간이 다른 요청에 효과적
- 실시간 부하 분산

**단점:**
- 연결 수 추적 오버헤드
- 구현이 상대적으로 복잡
- 연결 수 ≠ 실제 부하

**적합한 경우:**
- 요청 처리 시간이 불규칙할 때
- WebSocket 같은 지속 연결
- 서버 성능이 다를 때

#### 3. Weighted Round Robin (가중치 기반)

**개념**: 서버 성능에 따라 다른 가중치를 부여하여 분배합니다.

```
서버 1 (가중치 3): ■ ■ ■
서버 2 (가중치 2): ■ ■
서버 3 (가중치 1): ■
```

**장점:**
- 서버 성능 차이 반영
- 유연한 트래픽 제어
- 점진적 배포 가능

**단점:**
- 가중치 설정 어려움
- 정적 설정의 한계
- 실시간 부하 반영 안 됨

**적합한 경우:**
- 서버 사양이 다를 때
- 카나리 배포 (10% 트래픽만)
- 특정 서버 우선 처리

#### 4. Least Response Time (최소 응답 시간)

**개념**: 평균 응답 시간이 가장 짧은 서버로 요청을 보냅니다.

```
서버 1: 평균 100ms
서버 2: 평균 80ms  → 선택!
서버 3: 평균 150ms
```

**장점:**
- 실제 서버 성능 반영
- 사용자 경험 최적화
- 동적 부하 적응

**단점:**
- 응답 시간 측정 오버헤드
- 초기 데이터 부족 문제
- 순간적 변동에 민감

**적합한 경우:**
- 성능이 중요한 서비스
- 서버 위치가 분산된 경우
- 실시간 반응이 필요할 때

#### 5. IP Hash (세션 유지)

**개념**: 클라이언트 IP를 기반으로 동일 서버로 라우팅합니다.

```
Client A (IP: 1.2.3.4) → Hash → 서버 1
Client B (IP: 5.6.7.8) → Hash → 서버 2
Client A (IP: 1.2.3.4) → Hash → 서버 1 (동일)
```

**장점:**
- 세션 유지 가능
- 추가 세션 저장소 불필요
- 구현이 간단

**단점:**
- 부하 분산이 불균등할 수 있음
- 서버 추가/제거 시 세션 손실
- NAT 환경에서 문제 발생

**적합한 경우:**
- 세션 기반 애플리케이션
- Stateful 서비스
- 외부 세션 저장소 없을 때

### 로드 밸런싱 알고리즘 비교

| 알고리즘 | 복잡도 | 세션 유지 | 부하 고려 | 사용 사례 |
|---------|-------|---------|---------|---------|
| Round Robin | 낮음 | ✗ | ✗ | 동일 사양 서버 |
| Least Connections | 중간 | ✗ | ✓ | 지속 연결 |
| Weighted | 중간 | ✗ | 부분적 | 다른 사양 서버 |
| Response Time | 높음 | ✗ | ✓ | 성능 중심 |
| IP Hash | 낮음 | ✓ | ✗ | 세션 유지 |

### 2. Nginx 로드 밸런싱 설정

```nginx
# nginx.conf
upstream backend {
    # 라운드 로빈 (기본값)
    server 127.0.0.1:3001;
    server 127.0.0.1:3002;
    
    # 가중치 기반
    server 127.0.0.1:3003 weight=3;
    server 127.0.0.1:3004 weight=1;
    
    # 최소 연결 수 기반
    least_conn;
    server 127.0.0.1:3005;
    server 127.0.0.1:3006;
    
    # IP 해시 기반 (세션 유지)
    ip_hash;
    server 127.0.0.1:3007;
    server 127.0.0.1:3008;
    
    # 헬스 체크
    server 127.0.0.1:3009 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;
    server_name api.example.com;
    
    location / {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # 타임아웃 설정
        proxy_connect_timeout 5s;
        proxy_send_timeout 10s;
        proxy_read_timeout 10s;
    }
}
```

### 3. AWS 로드 밸런싱

#### Application Load Balancer (ALB)
```yaml
# ALB 설정 예시
apiVersion: v1
kind: Service
metadata:
  name: nodejs-app-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 3000
    protocol: TCP
  selector:
    app: nodejs-app
```

---

## 분산 락과 동시성 제어

### 분산 락이란?

분산 락(Distributed Lock)은 여러 서버에 분산된 프로세스들이 공유 자원에 동시에 접근하는 것을 제어하기 위한 메커니즘입니다. 단일 서버 환경에서는 프로세스 간 락으로 충분하지만, 분산 환경에서는 네트워크를 통한 락 관리가 필요합니다.

**필요한 상황:**
```
상황: 재고 차감 기능
├─ 문제: 여러 서버에서 동시에 재고 감소
│   서버 A: 재고 10 읽음 → 9로 업데이트
│   서버 B: 재고 10 읽음 → 9로 업데이트  (동시)
│   결과: 재고가 8이 되어야 하는데 9가 됨
│
└─ 해결: 분산 락 사용
    서버 A: 락 획득 → 재고 10 읽음 → 9로 업데이트 → 락 해제
    서버 B: 락 대기 → 락 획득 → 재고 9 읽음 → 8로 업데이트 → 락 해제
    결과: 올바르게 8이 됨
```

### Redis 기반 분산 락

Redis는 분산 락 구현에 가장 많이 사용되는 솔루션입니다.

#### 핵심 원리

**1. 락 획득 (Acquire)**
```
Redis 명령: SET lock:product:123 uuid123 PX 30000 NX

lock:product:123  → 락 키 (상품 123번의 락)
uuid123          → 고유 값 (내가 획득한 락임을 식별)
PX 30000         → 30초 후 자동 만료 (데드락 방지)
NX               → 키가 없을 때만 설정 (원자적 연산)
```

**2. 락 해제 (Release)**
```lua
-- Lua 스크립트로 원자적 해제
if redis.call("GET", KEYS[1]) == ARGV[1] then
  return redis.call("DEL", KEYS[1])
else
  return 0
end

설명: 내가 획득한 락만 해제 가능 (다른 프로세스의 락 해제 방지)
```

**3. 락 연장 (Extend)**
```lua
-- 작업이 오래 걸릴 때 TTL 연장
if redis.call("GET", KEYS[1]) == ARGV[1] then
  return redis.call("PEXPIRE", KEYS[1], ARGV[2])
else
  return 0
end
```

#### 구현 개념

```typescript
class DistributedLock {
  async acquire(key: string, ttl: number) {
    const lockValue = this.generateUniqueId();
    
    // SET NX PX로 원자적 락 획득
    const result = await redis.set(key, lockValue, 'PX', ttl, 'NX');
    
    if (result === 'OK') {
      return { success: true, lockValue };
    }
    return { success: false };
  }
  
  async release(key: string, lockValue: string) {
    // Lua 스크립트로 안전한 해제
    const script = `
      if redis.call("GET", KEYS[1]) == ARGV[1] then
        return redis.call("DEL", KEYS[1])
      else
        return 0
      end
    `;
    return await redis.eval(script, 1, key, lockValue);
  }
}

// 사용 예시
const lock = await distributedLock.acquire('product:123', 10000);
if (lock.success) {
  try {
    // 임계 영역: 재고 감소
    await decreaseStock(123, 1);
  } finally {
    await distributedLock.release('product:123', lock.lockValue);
  }
}
```

### 분산 락 구현 시 고려사항

#### 1. 데드락 방지

**문제:**
```
프로세스가 락을 획득한 후 죽으면?
→ 락이 영원히 해제되지 않음
```

**해결:**
```
TTL (Time To Live) 설정
- 락에 만료 시간 설정
- 프로세스가 죽어도 자동 해제
- 권장: 30초~1분
```

#### 2. 락 재진입 (Reentrant Lock)

```
같은 프로세스가 같은 락을 두 번 획득할 수 있는가?

일반 분산 락: 불가능 (데드락 발생)
재진입 락: 가능 (카운터 방식)

구현:
├─ 락 값에 카운터 포함
└─ 같은 프로세스면 카운터만 증가
```

#### 3. Redlock 알고리즘

단일 Redis 인스턴스의 문제점:
```
Redis 서버 장애 시 락 기능 전체 중단
→ Single Point of Failure (SPOF)
```

Redlock 해결책:
```
1. 여러 독립적인 Redis 인스턴스 사용 (보통 5개)
2. 과반수(3개 이상)에서 락 획득 성공해야 인정
3. 한두 개 서버 장애에도 락 기능 유지

Redis 1 ✓
Redis 2 ✓
Redis 3 ✓  → 3/5 성공, 락 획득!
Redis 4 ✗
Redis 5 ✗
```

### 분산 락 대안 및 비교

| 방식 | 장점 | 단점 | 사용 시기 |
|------|------|------|----------|
| **Redis** | • 빠름<br>• 구현 간단 | • SPOF<br>• 네트워크 의존 | 일반적인 경우 |
| **Redlock** | • 고가용성<br>• SPOF 없음 | • 복잡함<br>• 비용 증가 | 높은 안정성 필요 |
| **ZooKeeper** | • 강한 일관성<br>• 안정적 | • 느림<br>• 무거움 | 분산 코디네이션 |
| **DB (SELECT FOR UPDATE)** | • 추가 인프라 불필요 | • 느림<br>• DB 부하 | 트랜잭션 필요 |
| **Etcd** | • 강한 일관성<br>• Kubernetes 친화적 | • 학습 곡선 | K8s 환경 |

---

## 다층 캐싱 전략

### 1. 다층 캐시 아키텍처

```typescript
// src/multi-layer-cache/MultiLayerCache.ts
import Redis from 'ioredis';
import { LRUCache } from 'lru-cache';

export interface CacheOptions {
  l1MaxSize?: number;
  l1Ttl?: number;
  l2Ttl?: number;
  l2Prefix?: string;
  enableL1?: boolean;
  enableL2?: boolean;
}

export interface CacheItem {
  value: any;
  timestamp: number;
  ttl: number;
}

export class MultiLayerCache {
  private l1Cache: LRUCache<string, CacheItem>;
  private l2Cache: Redis;
  private options: Required<CacheOptions>;

  constructor(redis: Redis, options: CacheOptions = {}) {
    this.options = {
      l1MaxSize: 1000,
      l1Ttl: 300000, // 5분
      l2Ttl: 3600000, // 1시간
      l2Prefix: 'cache:',
      enableL1: true,
      enableL2: true,
      ...options
    };

    // L1 캐시 (메모리) 초기화
    this.l1Cache = new LRUCache<string, CacheItem>({
      max: this.options.l1MaxSize,
      ttl: this.options.l1Ttl,
      updateAgeOnGet: true,
      updateAgeOnHas: true
    });

    this.l2Cache = redis;
  }

  // 캐시에서 데이터 조회
  async get<T>(key: string): Promise<T | null> {
    // L1 캐시에서 먼저 확인
    if (this.options.enableL1) {
      const l1Item = this.l1Cache.get(key);
      if (l1Item && !this.isExpired(l1Item)) {
        console.log(`L1 cache hit: ${key}`);
        return l1Item.value;
      }
    }

    // L2 캐시에서 확인
    if (this.options.enableL2) {
      try {
        const l2Key = this.getL2Key(key);
        const l2Value = await this.l2Cache.get(l2Key);
        
        if (l2Value) {
          const item: CacheItem = JSON.parse(l2Value);
          
          if (!this.isExpired(item)) {
            console.log(`L2 cache hit: ${key}`);
            
            // L1 캐시에 저장
            if (this.options.enableL1) {
              this.l1Cache.set(key, item);
            }
            
            return item.value;
          } else {
            // 만료된 데이터 삭제
            await this.l2Cache.del(l2Key);
          }
        }
      } catch (error) {
        console.error(`L2 cache error for key ${key}:`, error);
      }
    }

    console.log(`Cache miss: ${key}`);
    return null;
  }

  // 캐시에 데이터 저장
  async set(key: string, value: any, ttl?: number): Promise<void> {
    const item: CacheItem = {
      value,
      timestamp: Date.now(),
      ttl: ttl || this.options.l1Ttl
    };

    // L1 캐시에 저장
    if (this.options.enableL1) {
      this.l1Cache.set(key, item);
    }

    // L2 캐시에 저장
    if (this.options.enableL2) {
      try {
        const l2Key = this.getL2Key(key);
        const l2Ttl = Math.floor((ttl || this.options.l2Ttl) / 1000); // Redis는 초 단위
        await this.l2Cache.setex(l2Key, l2Ttl, JSON.stringify(item));
      } catch (error) {
        console.error(`L2 cache set error for key ${key}:`, error);
      }
    }
  }

  // 캐시에서 데이터 삭제
  async del(key: string): Promise<void> {
    // L1 캐시에서 삭제
    if (this.options.enableL1) {
      this.l1Cache.delete(key);
    }

    // L2 캐시에서 삭제
    if (this.options.enableL2) {
      try {
        const l2Key = this.getL2Key(key);
        await this.l2Cache.del(l2Key);
      } catch (error) {
        console.error(`L2 cache delete error for key ${key}:`, error);
      }
    }
  }

  // 캐시 무효화 (패턴 기반)
  async invalidatePattern(pattern: string): Promise<void> {
    // L1 캐시에서 패턴 매칭 삭제
    if (this.options.enableL1) {
      const keys = Array.from(this.l1Cache.keys());
      const matchingKeys = keys.filter(key => this.matchesPattern(key, pattern));
      
      matchingKeys.forEach(key => {
        this.l1Cache.delete(key);
      });
    }

    // L2 캐시에서 패턴 매칭 삭제
    if (this.options.enableL2) {
      try {
        const l2Pattern = this.getL2Key(pattern);
        const keys = await this.l2Cache.keys(l2Pattern);
        
        if (keys.length > 0) {
          await this.l2Cache.del(...keys);
        }
      } catch (error) {
        console.error(`L2 cache pattern invalidation error:`, error);
      }
    }
  }

  // 캐시 워밍업
  async warmup(keyValuePairs: Array<{ key: string; value: any; ttl?: number }>): Promise<void> {
    console.log(`Starting cache warmup for ${keyValuePairs.length} items`);
    
    const warmupPromises = keyValuePairs.map(async ({ key, value, ttl }) => {
      await this.set(key, value, ttl);
    });

    await Promise.all(warmupPromises);
    console.log('Cache warmup completed');
  }

  // 캐시 통계
  getStats() {
    return {
      l1: {
        size: this.l1Cache.size,
        maxSize: this.options.l1MaxSize,
        hitRate: this.calculateHitRate()
      },
      l2: {
        enabled: this.options.enableL2
      }
    };
  }

  // L2 캐시 키 생성
  private getL2Key(key: string): string {
    return `${this.options.l2Prefix}${key}`;
  }

  // 만료 확인
  private isExpired(item: CacheItem): boolean {
    return Date.now() - item.timestamp > item.ttl;
  }

  // 패턴 매칭
  private matchesPattern(key: string, pattern: string): boolean {
    const regex = new RegExp(pattern.replace(/\*/g, '.*'));
    return regex.test(key);
  }

  // 히트율 계산
  private calculateHitRate(): number {
    // 실제 구현에서는 히트/미스 카운터를 유지해야 함
    return 0.85; // 예시 값
  }
}

// 캐시 무효화 전략
export class CacheInvalidationStrategy {
  private cache: MultiLayerCache;
  private invalidationRules: Map<string, string[]> = new Map();

  constructor(cache: MultiLayerCache) {
    this.cache = cache;
  }

  // 무효화 규칙 등록
  registerRule(entityType: string, cacheKeys: string[]): void {
    this.invalidationRules.set(entityType, cacheKeys);
  }

  // 엔티티 변경 시 관련 캐시 무효화
  async invalidateOnEntityChange(entityType: string, entityId: string): Promise<void> {
    const rules = this.invalidationRules.get(entityType);
    
    if (rules) {
      const invalidationPromises = rules.map(rule => {
        const pattern = rule.replace('{id}', entityId);
        return this.cache.invalidatePattern(pattern);
      });

      await Promise.all(invalidationPromises);
      console.log(`Cache invalidated for ${entityType}:${entityId}`);
    }
  }

  // 시간 기반 무효화
  async invalidateByTime(ttl: number): Promise<void> {
    // TTL 기반 자동 만료는 Redis와 LRU 캐시에서 자동 처리됨
    console.log(`Time-based invalidation set for ${ttl}ms`);
  }
}

// 캐시 워밍업 전략
export class CacheWarmupStrategy {
  private cache: MultiLayerCache;
  private dataSource: any; // 데이터 소스 (DB, API 등)

  constructor(cache: MultiLayerCache, dataSource: any) {
    this.cache = cache;
    this.dataSource = dataSource;
  }

  // 인기 데이터 워밍업
  async warmupPopularData(): Promise<void> {
    console.log('Starting popular data warmup...');
    
    try {
      // 인기 사용자 데이터
      const popularUsers = await this.dataSource.getPopularUsers(100);
      const userWarmupData = popularUsers.map(user => ({
        key: `user:${user.id}`,
        value: user,
        ttl: 3600000 // 1시간
      }));

      // 인기 상품 데이터
      const popularProducts = await this.dataSource.getPopularProducts(200);
      const productWarmupData = popularProducts.map(product => ({
        key: `product:${product.id}`,
        value: product,
        ttl: 1800000 // 30분
      }));

      // 인기 카테고리 데이터
      const categories = await this.dataSource.getCategories();
      const categoryWarmupData = categories.map(category => ({
        key: `category:${category.id}`,
        value: category,
        ttl: 7200000 // 2시간
      }));

      // 모든 데이터 워밍업
      await Promise.all([
        this.cache.warmup(userWarmupData),
        this.cache.warmup(productWarmupData),
        this.cache.warmup(categoryWarmupData)
      ]);

      console.log('Popular data warmup completed');
    } catch (error) {
      console.error('Popular data warmup failed:', error);
    }
  }

  // 예측적 워밍업
  async predictiveWarmup(userId: string): Promise<void> {
    console.log(`Starting predictive warmup for user ${userId}`);
    
    try {
      // 사용자 행동 패턴 분석
      const userBehavior = await this.dataSource.getUserBehavior(userId);
      
      // 추천 상품 워밍업
      const recommendedProducts = await this.dataSource.getRecommendations(userId);
      const recommendationData = recommendedProducts.map(product => ({
        key: `recommendation:${userId}:${product.id}`,
        value: product,
        ttl: 1800000 // 30분
      }));

      // 사용자 관심사 기반 카테고리 워밍업
      const interestCategories = await this.dataSource.getUserInterests(userId);
      const interestData = interestCategories.map(category => ({
        key: `interest:${userId}:${category.id}`,
        value: category,
        ttl: 3600000 // 1시간
      }));

      await Promise.all([
        this.cache.warmup(recommendationData),
        this.cache.warmup(interestData)
      ]);

      console.log(`Predictive warmup completed for user ${userId}`);
    } catch (error) {
      console.error(`Predictive warmup failed for user ${userId}:`, error);
    }
  }

  // 스케줄된 워밍업
  startScheduledWarmup(): void {
    // 매일 새벽 2시에 인기 데이터 워밍업
    const schedule = require('node-schedule');
    
    schedule.scheduleJob('0 2 * * *', async () => {
      console.log('Starting scheduled warmup...');
      await this.warmupPopularData();
    });

    // 매 시간마다 예측적 워밍업 (활성 사용자 대상)
    schedule.scheduleJob('0 * * * *', async () => {
      console.log('Starting hourly predictive warmup...');
      const activeUsers = await this.dataSource.getActiveUsers(1000);
      
      const warmupPromises = activeUsers.map(user => 
        this.predictiveWarmup(user.id)
      );
      
      await Promise.all(warmupPromises);
    });
  }
}

// 사용 예시
const redis = new Redis({
  host: 'localhost',
  port: 6379
});

const cache = new MultiLayerCache(redis, {
  l1MaxSize: 2000,
  l1Ttl: 300000, // 5분
  l2Ttl: 3600000, // 1시간
  enableL1: true,
  enableL2: true
});

// 캐시 무효화 전략 설정
const invalidationStrategy = new CacheInvalidationStrategy(cache);
invalidationStrategy.registerRule('user', [
  'user:{id}',
  'user:{id}:profile',
  'user:{id}:preferences'
]);
invalidationStrategy.registerRule('product', [
  'product:{id}',
  'product:{id}:details',
  'product:{id}:reviews'
]);

// 캐시 워밍업 전략 설정
const dataSource = {
  getPopularUsers: async (limit: number) => { /* 구현 */ },
  getPopularProducts: async (limit: number) => { /* 구현 */ },
  getCategories: async () => { /* 구현 */ },
  getUserBehavior: async (userId: string) => { /* 구현 */ },
  getRecommendations: async (userId: string) => { /* 구현 */ },
  getUserInterests: async (userId: string) => { /* 구현 */ },
  getActiveUsers: async (limit: number) => { /* 구현 */ }
};

const warmupStrategy = new CacheWarmupStrategy(cache, dataSource);

// 캐시 사용 예시
async function getUserData(userId: string) {
  // 캐시에서 먼저 확인
  let userData = await cache.get(`user:${userId}`);
  
  if (!userData) {
    // 캐시 미스 시 데이터베이스에서 조회
    userData = await dataSource.getUserById(userId);
    
    // 캐시에 저장
    await cache.set(`user:${userId}`, userData, 3600000); // 1시간
  }
  
  return userData;
}

// 사용자 정보 업데이트 시 캐시 무효화
async function updateUser(userId: string, userData: any) {
  // 데이터베이스 업데이트
  await dataSource.updateUser(userId, userData);
  
  // 관련 캐시 무효화
  await invalidationStrategy.invalidateOnEntityChange('user', userId);
}

// 애플리케이션 시작 시 워밍업
async function initializeCache() {
  await warmupStrategy.warmupPopularData();
  warmupStrategy.startScheduledWarmup();
}

// 캐시 통계 모니터링
setInterval(() => {
  const stats = cache.getStats();
  console.log('Cache Stats:', stats);
}, 60000); // 1분마다
```

### 2. 캐시 계층 구조

```
L1: 애플리케이션 캐시 (메모리)
L2: 분산 캐시 (Redis)
L3: CDN 캐시
L4: 데이터베이스 캐시
```

### 2. CDN (Content Delivery Network)

#### CloudFront 설정
```javascript
// CDN 캐싱 전략
const cdnConfig = {
  // 정적 자산 캐싱
  staticAssets: {
    cachePolicy: 'CachingOptimized',
    ttl: 31536000, // 1년
    headers: ['Accept-Encoding']
  },
  
  // API 응답 캐싱
  apiResponses: {
    cachePolicy: 'CachingDisabled',
    ttl: 0,
    headers: ['Authorization', 'Content-Type']
  },
  
  // 동적 콘텐츠 캐싱
  dynamicContent: {
    cachePolicy: 'CachingOptimizedForCompression',
    ttl: 3600, // 1시간
    headers: ['Accept-Encoding', 'Accept-Language']
  }
};
```

### 3. Application Cache (Redis)

#### 캐시 전략 구현
```javascript
class CacheManager {
  constructor(redisClient) {
    this.redis = redisClient;
    this.defaultTTL = 3600; // 1시간
  }

  // Cache-Aside 패턴
  async get(key) {
    try {
      const cached = await this.redis.get(key);
      if (cached) {
        return JSON.parse(cached);
      }
      return null;
    } catch (error) {
      console.error('Cache get error:', error);
      return null;
    }
  }

  async set(key, value, ttl = this.defaultTTL) {
    try {
      await this.redis.setex(key, ttl, JSON.stringify(value));
    } catch (error) {
      console.error('Cache set error:', error);
    }
  }

  // Write-Through 패턴
  async writeThrough(key, value, ttl = this.defaultTTL) {
    // 1. 데이터베이스에 저장
    await this.saveToDatabase(value);
    
    // 2. 캐시에 저장
    await this.set(key, value, ttl);
  }

  // Write-Behind 패턴
  async writeBehind(key, value, ttl = this.defaultTTL) {
    // 1. 캐시에 먼저 저장
    await this.set(key, value, ttl);
    
    // 2. 비동기로 데이터베이스에 저장
    setImmediate(() => {
      this.saveToDatabase(value).catch(console.error);
    });
  }

  // Cache-Aside 패턴 구현
  async getOrSet(key, fetchFunction, ttl = this.defaultTTL) {
    // 1. 캐시에서 조회
    let value = await this.get(key);
    
    if (value === null) {
      // 2. 캐시에 없으면 데이터베이스에서 조회
      value = await fetchFunction();
      
      // 3. 캐시에 저장
      if (value !== null) {
        await this.set(key, value, ttl);
      }
    }
    
    return value;
  }
}
```

### 4. Database Cache

#### 쿼리 결과 캐싱
```javascript
class DatabaseCache {
  constructor(redisClient, dbConnection) {
    this.redis = redisClient;
    this.db = dbConnection;
  }

  async executeQuery(query, params, ttl = 300) {
    const cacheKey = this.generateCacheKey(query, params);
    
    // 캐시에서 조회
    let result = await this.redis.get(cacheKey);
    
    if (result) {
      return JSON.parse(result);
    }
    
    // 데이터베이스에서 조회
    result = await this.db.query(query, params);
    
    // 캐시에 저장
    await this.redis.setex(cacheKey, ttl, JSON.stringify(result));
    
    return result;
  }

  generateCacheKey(query, params) {
    const queryHash = require('crypto')
      .createHash('md5')
      .update(query + JSON.stringify(params))
      .digest('hex');
    
    return `query:${queryHash}`;
  }
}
```

---

## 데이터베이스 샤딩 및 파티셔닝

### 1. 샤딩 전략

#### 수평 샤딩 (Horizontal Sharding)
```javascript
class HorizontalSharding {
  constructor(shardCount) {
    this.shardCount = shardCount;
    this.shards = new Array(shardCount).fill(null).map(() => ({
      connection: null,
      data: new Map()
    }));
  }

  // 해시 기반 샤딩
  getShardId(key) {
    const hash = this.hashFunction(key);
    return hash % this.shardCount;
  }

  hashFunction(str) {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash;
    }
    return Math.abs(hash);
  }

  async insert(key, value) {
    const shardId = this.getShardId(key);
    const shard = this.shards[shardId];
    
    shard.data.set(key, value);
    console.log(`Inserted ${key} into shard ${shardId}`);
  }

  async get(key) {
    const shardId = this.getShardId(key);
    const shard = this.shards[shardId];
    
    return shard.data.get(key);
  }
}
```

#### 수직 샤딩 (Vertical Sharding)
```javascript
class VerticalSharding {
  constructor() {
    this.shards = {
      userProfile: new Map(),    // 사용자 프로필 정보
      userActivity: new Map(),   // 사용자 활동 로그
      userSettings: new Map()    // 사용자 설정
    };
  }

  async insertUserProfile(userId, profile) {
    this.shards.userProfile.set(userId, profile);
  }

  async insertUserActivity(userId, activity) {
    if (!this.shards.userActivity.has(userId)) {
      this.shards.userActivity.set(userId, []);
    }
    this.shards.userActivity.get(userId).push(activity);
  }

  async insertUserSettings(userId, settings) {
    this.shards.userSettings.set(userId, settings);
  }

  async getUserData(userId) {
    const profile = this.shards.userProfile.get(userId);
    const activities = this.shards.userActivity.get(userId) || [];
    const settings = this.shards.userSettings.get(userId);

    return {
      profile,
      activities,
      settings
    };
  }
}
```

### 2. 파티셔닝 전략

#### 범위 기반 파티셔닝
```sql
-- 날짜 기반 파티셔닝
CREATE TABLE user_activities (
    id BIGINT,
    user_id BIGINT,
    activity_type VARCHAR(50),
    created_at TIMESTAMP,
    data JSONB
) PARTITION BY RANGE (created_at);

-- 월별 파티션 생성
CREATE TABLE user_activities_2024_01 PARTITION OF user_activities
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE user_activities_2024_02 PARTITION OF user_activities
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
```

#### 해시 기반 파티셔닝
```sql
-- 사용자 ID 기반 해시 파티셔닝
CREATE TABLE users (
    id BIGINT,
    username VARCHAR(50),
    email VARCHAR(100),
    created_at TIMESTAMP
) PARTITION BY HASH (id);

-- 4개 파티션 생성
CREATE TABLE users_0 PARTITION OF users
    FOR VALUES WITH (modulus 4, remainder 0);

CREATE TABLE users_1 PARTITION OF users
    FOR VALUES WITH (modulus 4, remainder 1);

CREATE TABLE users_2 PARTITION OF users
    FOR VALUES WITH (modulus 4, remainder 2);

CREATE TABLE users_3 PARTITION OF users
    FOR VALUES WITH (modulus 4, remainder 3);
```

---

## 실제 대규모 시스템 설계 사례

### 1. 트위터 스타일 시스템

#### 시스템 요구사항
```
- 사용자: 1억 명
- 트윗: 초당 6,000개 작성
- 타임라인: 초당 300,000개 조회
- 팔로워: 평균 200명
```

#### 아키텍처 설계
```javascript
// 트위터 스타일 시스템 아키텍처
class TwitterLikeSystem {
  constructor() {
    this.userService = new UserService();
    this.tweetService = new TweetService();
    this.timelineService = new TimelineService();
    this.followService = new FollowService();
  }

  // 트윗 작성
  async postTweet(userId, content) {
    // 1. 트윗 저장
    const tweet = await this.tweetService.createTweet(userId, content);
    
    // 2. 팔로워들의 타임라인에 추가 (비동기)
    this.updateFollowersTimeline(userId, tweet);
    
    return tweet;
  }

  // 팔로워 타임라인 업데이트
  async updateFollowersTimeline(userId, tweet) {
    const followers = await this.followService.getFollowers(userId);
    
    // 배치 처리로 타임라인 업데이트
    const batchSize = 1000;
    for (let i = 0; i < followers.length; i += batchSize) {
      const batch = followers.slice(i, i + batchSize);
      
      // 비동기로 처리
      setImmediate(() => {
        this.timelineService.addToTimelines(batch, tweet);
      });
    }
  }

  // 타임라인 조회
  async getTimeline(userId, page = 1, limit = 20) {
    return await this.timelineService.getTimeline(userId, page, limit);
  }
}
```

#### 데이터 모델
```javascript
// 사용자 모델
class User {
  constructor(id, username, email, createdAt) {
    this.id = id;
    this.username = username;
    this.email = email;
    this.createdAt = createdAt;
    this.followersCount = 0;
    this.followingCount = 0;
  }
}

// 트윗 모델
class Tweet {
  constructor(id, userId, content, createdAt) {
    this.id = id;
    this.userId = userId;
    this.content = content;
    this.createdAt = createdAt;
    this.likesCount = 0;
    this.retweetsCount = 0;
  }
}

// 타임라인 모델
class Timeline {
  constructor(userId, tweetId, createdAt) {
    this.userId = userId;
    this.tweetId = tweetId;
    this.createdAt = createdAt;
  }
}
```

### 2. 넷플릭스 스타일 시스템

#### 시스템 요구사항
```
- 사용자: 2억 명
- 동시 스트리밍: 1,000만 명
- 콘텐츠: 15,000개 영화/시리즈
- 글로벌 서비스
```

#### 아키텍처 설계
```javascript
// 넷플릭스 스타일 시스템 아키텍처
class NetflixLikeSystem {
  constructor() {
    this.userService = new UserService();
    this.contentService = new ContentService();
    this.recommendationService = new RecommendationService();
    this.cdnService = new CDNService();
    this.analyticsService = new AnalyticsService();
  }

  // 콘텐츠 스트리밍
  async streamContent(userId, contentId, quality) {
    // 1. 사용자 인증 및 권한 확인
    const user = await this.userService.getUser(userId);
    if (!user.hasAccess(contentId)) {
      throw new Error('Access denied');
    }

    // 2. CDN에서 최적 서버 선택
    const cdnServer = await this.cdnService.getOptimalServer(user.location);
    
    // 3. 스트리밍 URL 생성
    const streamUrl = await this.cdnService.generateStreamUrl(contentId, quality, cdnServer);
    
    // 4. 분석 데이터 수집
    this.analyticsService.trackStreamingStart(userId, contentId, quality);
    
    return {
      streamUrl,
      quality,
      cdnServer
    };
  }

  // 추천 시스템
  async getRecommendations(userId) {
    const user = await this.userService.getUser(userId);
    const watchHistory = await this.analyticsService.getWatchHistory(userId);
    
    return await this.recommendationService.getRecommendations(user, watchHistory);
  }
}
```

#### CDN 최적화
```javascript
class CDNOptimizer {
  constructor() {
    this.regions = {
      'us-east': ['server1', 'server2', 'server3'],
      'us-west': ['server4', 'server5', 'server6'],
      'europe': ['server7', 'server8', 'server9'],
      'asia': ['server10', 'server11', 'server12']
    };
  }

  async getOptimalServer(userLocation) {
    const region = this.getRegion(userLocation);
    const servers = this.regions[region];
    
    // 서버 상태 확인 및 최적 서버 선택
    const serverStats = await Promise.all(
      servers.map(server => this.getServerStats(server))
    );
    
    // CPU 사용률이 가장 낮은 서버 선택
    const optimalServer = serverStats.reduce((min, current) => 
      current.cpuUsage < min.cpuUsage ? current : min
    );
    
    return optimalServer.name;
  }

  getRegion(location) {
    // 위치 기반 리전 결정 로직
    if (location.country === 'US') {
      return location.state === 'CA' ? 'us-west' : 'us-east';
    } else if (location.continent === 'Europe') {
      return 'europe';
    } else {
      return 'asia';
    }
  }
}
```

### 3. 시스템 모니터링 및 알림

```javascript
class SystemMonitor {
  constructor() {
    this.metrics = {
      responseTime: [],
      errorRate: [],
      throughput: [],
      cpuUsage: [],
      memoryUsage: []
    };
  }

  // 메트릭 수집
  collectMetrics() {
    setInterval(() => {
      this.metrics.responseTime.push(this.getAverageResponseTime());
      this.metrics.errorRate.push(this.getErrorRate());
      this.metrics.throughput.push(this.getThroughput());
      this.metrics.cpuUsage.push(this.getCpuUsage());
      this.metrics.memoryUsage.push(this.getMemoryUsage());
      
      // 임계값 확인
      this.checkThresholds();
    }, 60000); // 1분마다
  }

  // 임계값 확인 및 알림
  checkThresholds() {
    const currentErrorRate = this.metrics.errorRate[this.metrics.errorRate.length - 1];
    const currentResponseTime = this.metrics.responseTime[this.metrics.responseTime.length - 1];
    
    if (currentErrorRate > 0.05) { // 5% 이상
      this.sendAlert('High error rate detected', { errorRate: currentErrorRate });
    }
    
    if (currentResponseTime > 2000) { // 2초 이상
      this.sendAlert('High response time detected', { responseTime: currentResponseTime });
    }
  }

  sendAlert(message, data) {
    console.log(`ALERT: ${message}`, data);
    // 실제로는 Slack, PagerDuty 등으로 전송
  }
}
```

---

## 결론

시스템 설계는 단순히 코드를 작성하는 것을 넘어, 비즈니스 요구사항과 기술적 제약 사이의 균형을 찾는 과정입니다. 완벽한 시스템은 존재하지 않으며, 모든 설계 결정에는 트레이드오프가 따릅니다.

### 핵심 원칙

1. **단순함에서 시작하기**: 복잡성은 필요할 때 추가합니다
2. **측정 가능한 목표 설정**: SLA, SLO를 명확히 정의합니다
3. **점진적 개선**: 한 번에 모든 것을 완벽하게 만들려 하지 않습니다
4. **장애를 염두에 둔 설계**: 장애는 필연적으로 발생합니다
5. **비용 효율성 고려**: 과도한 엔지니어링을 피합니다

### 실무 적용 로드맵

**1단계: 소규모 시스템 (사용자 수 천 명)**
- 모놀리식 아키텍처
- 단일 데이터베이스
- 기본 모니터링
- 수동 배포

**2단계: 중규모 시스템 (사용자 수 만 명)**
- 로드 밸런서 도입
- 데이터베이스 읽기 복제본
- Redis 캐싱
- CI/CD 파이프라인

**3단계: 대규모 시스템 (사용자 수 십만~백만 명)**
- 마이크로서비스 아키텍처
- 데이터베이스 샤딩
- CDN 활용
- 메시지 큐
- 고급 모니터링 (APM, 분산 추적)

**4단계: 초대규모 시스템 (사용자 수 천만 명 이상)**
- 다지역 배포
- 서비스 메시 도입
- 카오스 엔지니어링
- 자동화된 장애 대응
- 머신러닝 기반 예측

### 지속적인 학습

시스템 설계는 끊임없이 진화하는 분야입니다. 새로운 기술과 패턴이 계속 등장하며, 각 조직의 상황에 맞는 최적의 솔루션은 다를 수 있습니다. 다른 팀의 사례를 학습하고, 실험하며, 자신의 경험을 문서화하는 것이 중요합니다.

---

## 참고 자료

- **Designing Data-Intensive Applications** (Martin Kleppmann)
- **Building Microservices** (Sam Newman)
- **System Design Primer**: https://github.com/donnemartin/system-design-primer
- **AWS Well-Architected Framework**: https://aws.amazon.com/architecture/well-architected/
