---
title: 메시지 큐 및 분산 락
tags: [backend, messaging, rabbitmq, kafka, sqs, mysql, innodb, lock, deadlock, redis, distributed-lock]
updated: 2025-12-23
---

# 메시지 큐 및 분산 락

## 목차

1. 범위
2. 메시지 큐
3. 데이터베이스 락
4. 분산 락
5. 운영에서 자주 터지는 케이스
6. 관측과 장애 대응
7. 테스트

---

## 범위

이 문서는 “메시지 큐로 비동기 처리 파이프라인을 만든다”와 “동시성 충돌을 락으로 막는다”를 한 문서에서 다룹니다.

- 메시지 큐는 처리량과 장애 격리를 담당합니다.
- DB 락은 같은 데이터에 대한 동시 수정 충돌을 막습니다.
- 분산 락은 “여러 프로세스/서버가 같은 자원 하나를 동시에 건드린다”가 전제가 될 때만 의미가 있습니다.

코드는 최소로 넣고, 운영에서 결정해야 하는 지점과 사고가 나는 지점을 중심으로 정리합니다.

---

## 메시지 큐

### 메시지 큐를 쓰는 이유

동기 호출 체인이 길어질수록 장애 전파가 빨라집니다.  
메시지 큐를 넣으면 호출자와 처리자가 분리되고, 처리 지연을 큐가 흡수합니다.

실무에서 메시지 큐를 도입하는 순간부터 생기는 문제는 대부분 “전달 보장”과 “중복 처리”입니다.

---

### 전달 보장 모델

메시지 큐는 아래 중 하나로 귀결됩니다.

- at-most-once: 중복은 없는데 유실이 날 수 있습니다.
- at-least-once: 유실은 줄이는데 중복이 생깁니다.
- exactly-once: 문서에는 많이 나오지만, 시스템 전체에서 보장하려면 제약이 큽니다.

운영에서는 at-least-once를 전제로 설계하는 경우가 많습니다.  
중복 처리를 소비자 쪽에서 막는 형태로 마감합니다.

---

### 중복 처리

중복은 여러 원인으로 발생합니다.

- 소비자가 처리 완료 전에 죽어서 ack를 못 하고 재전달
- 처리 시간보다 visibility timeout(또는 ack timeout)이 짧아서 재전달
- 네트워크 단절로 ack가 유실되었는데 실제 처리는 끝난 상태
- 퍼블리셔 재시도 로직이 메시지 ID 없이 동작

중복을 허용하지 않는 작업(재고 차감, 포인트 적립)은 멱등성을 강제해야 합니다.

멱등성 키를 만드는 방식은 보통 3가지입니다.

- 비즈니스 키 기반: `orderId + eventType`
- 이벤트 ID 기반: 메시지에 `eventId`를 넣고 소비자가 저장
- DB 유니크 인덱스 기반: 처리 기록 테이블에 `event_id` 유니크

“처리 기록 테이블”은 꼭 TTL이 필요합니다.  
TTL이 없으면 몇 달 지나서 테이블이 병목이 됩니다.

---

### 순서 보장

“순서 보장”은 생각보다 비용이 큽니다.

- FIFO를 쓰면 처리량이 떨어지는 경우가 있습니다.
- 파티션 키(또는 메시지 그룹) 설계가 틀리면 한 키에 몰려 큐가 막힙니다.
- 순서가 필요한 범위를 과하게 잡으면 병렬성이 사라집니다.

실무에서는 “전체 순서”가 아니라 “주문 단위 순서”, “객실 단위 순서”처럼 범위를 줄여 잡습니다.

---

### 재시도와 DLQ

재시도는 두 레이어에서 발생합니다.

- 큐 레벨 재시도: 소비 실패 시 재전달
- 애플리케이션 레벨 재시도: 외부 API 호출 실패 시 재시도

둘을 같이 쓰면 재시도 폭발이 나기 쉽습니다.  
애플리케이션 레벨 재시도를 넣는다면 큐 레벨 재시도 횟수는 줄이는 편이 낫습니다.

DLQ는 “나중에 보자”로 끝나는 경우가 많습니다.  
DLQ가 쌓이기 시작하면 이미 데이터 정합성이 깨졌을 가능성이 큽니다.

DLQ 운영에서 중요한 것은 “왜 실패했는지 분류”입니다.

- 포맷 불일치: 소비자 배포 순서 문제, 스키마 버전 처리 누락
- 외부 의존성 장애: 결제, 이메일, 문자
- 데이터 조건 실패: 이미 취소된 주문을 다시 처리
- 리소스 병목: DB 락 대기, 커넥션 고갈

DLQ는 “재처리 버튼”이 아니라 “실패 원인 분석 버퍼”로 봐야 합니다.

---

### 소비자 병렬성과 백프레셔

소비자는 보통 “스레드/프로세스 늘리면 된다”로 시작합니다.  
운영에서는 아래가 병목이 됩니다.

- DB 커넥션 수
- 외부 API rate limit
- CPU보다 IO가 지배적인 작업의 동시성 과다
- 같은 핫키에 대한 락 경합

prefetch/batch size를 키우면 처리량이 늘기도 하지만, 실패 시 재처리 단위가 커집니다.  
배치 단위가 커질수록 “부분 실패” 처리가 필요해집니다.

---

### RabbitMQ / Kafka / SQS 관점 정리

RabbitMQ는 라우팅과 큐 조합이 편합니다.  
운영에서 자주 걸리는 포인트는 ack 관리, prefetch, 소비자 장애 시 재전달, TTL/DLX 구성입니다.

Kafka는 로그 스트림에 가깝습니다.  
리플레이가 자연스럽고, 소비자 그룹 기준으로 스케일이 됩니다.  
운영 포인트는 파티션 키 설계, consumer lag, 리밸런싱 시 처리 지연, 오프셋 커밋 타이밍입니다.

SQS는 관리 부담이 적습니다.  
운영 포인트는 visibility timeout, DLQ maxReceiveCount, 배치 처리, 장기 적체 시 oldest message age입니다.

제품 비교가 목적이면 세부 비교표가 더 길어지는데, 이 문서에서는 “무엇을 보고 운영해야 하는지”까지만 다룹니다.

---

## 데이터베이스 락

### SELECT에서 락이 생기는 조건

읽기라고 해서 락이 없는 건 아닙니다.

- `SELECT ... FOR UPDATE`: 배타 락을 잡고 수정 가능 상태로 만듭니다.
- `SELECT ... LOCK IN SHARE MODE`(MySQL 8에서는 `FOR SHARE`가 더 많이 보입니다): 공유 락을 잡고 다른 트랜잭션의 수정을 막습니다.

핫 테이블에서 이 구문이 늘어나면 “CPU는 멀쩡한데 TPS가 갑자기 죽는” 상황이 자주 나옵니다.

---

### InnoDB에서 락이 커지는 패턴

운영에서 자주 보는 케이스입니다.

1) 인덱스를 못 타는 조건으로 `FOR UPDATE`를 걸었을 때  
   행 락이라고 생각하고 썼는데, 실제로는 범위 락(갭/넥스트키)이 넓게 잡히는 경우가 있습니다.

2) 같은 테이블을 다른 순서로 락 잡는 트랜잭션이 섞였을 때  
   데드락이 터집니다.

3) 트랜잭션이 길어졌을 때  
   락 유지 시간이 길어지고 대기열이 생깁니다. “조회 후 외부 API 호출” 같은 흐름이 대표적입니다.

---

### 격리 수준과 락의 관계

MySQL InnoDB 기준으로 자주 부딪히는 부분만 적습니다.

- READ COMMITTED  
  범위 락이 줄어드는 방향이라 경합이 완화되는 경우가 있습니다.  
  같은 트랜잭션에서 같은 SELECT를 해도 결과가 바뀔 수 있어, 로직이 그걸 전제로 짜여 있어야 합니다.

- REPEATABLE READ  
  MySQL 기본값입니다. 넥스트키 락과 맞물려 락 범위가 커지는 케이스가 나옵니다.  
  “존재 여부 확인 후 INSERT” 패턴에서 갭 락 때문에 막히는 상황을 자주 봅니다.

- SERIALIZABLE  
  성능 희생이 큽니다. 운영에서 기본값으로 쓰는 경우는 드뭅니다.

격리 수준 조정은 최후 수단에 가깝습니다.  
대부분은 쿼리 조건과 인덱스, 트랜잭션 길이 문제에서 출발합니다.

---

### 데드락

데드락은 “둘 다 락을 잡고 있는데 서로가 가진 락을 기다린다” 상태입니다.  
InnoDB는 데드락을 감지하면 한 트랜잭션을 죽입니다.

운영에서 중요한 건 “데드락은 에러로 끝나지 않는다”입니다.  
죽은 트랜잭션이 실패한 비즈니스 작업을 재시도해야 합니다.

데드락이 자주 생기는 구조는 보통 이렇습니다.

- 동일 테이블 여러 행을 업데이트
- 업데이트 순서가 요청마다 다름
- 트랜잭션이 길어서 락 유지가 오래감

해결은 “순서 통일”이 제일 많이 먹힙니다.

- 항상 작은 ID부터 락을 잡습니다.
- 정렬 기준이 하나로 고정되어야 합니다.
- 복합 키면 정렬 키도 같이 고정해야 합니다.

---

### 락 대기 시간과 타임아웃

`innodb_lock_wait_timeout`은 “락 대기 최대 시간”입니다.  
이 값이 길면 장애가 오래 끌고, 짧으면 실패가 늘어납니다.

운영에서는 “짧게 실패시키고 애플리케이션에서 재시도”가 더 관리 가능한 경우가 많습니다.  
단, 재시도가 무조건 좋은 건 아닙니다. 같은 락 경합을 더 키울 수 있습니다.

`NOWAIT`, `SKIP LOCKED`는 상황을 명확히 나눕니다.

- NOWAIT: 락을 못 잡으면 즉시 실패, 호출자가 다른 흐름을 선택해야 합니다.
- SKIP LOCKED: 락 걸린 행을 건너뜁니다. 워커/배치에서 자주 씁니다.

`SKIP LOCKED`는 “정확히 모든 데이터를 한 번씩 처리해야 한다”에는 맞지 않습니다.  
처리 누락을 별도로 보정하는 설계가 필요합니다.

---

### 락 성능 문제를 만드는 대표 패턴

- 핫 로우: 한 행을 모든 요청이 건드리는 구조(시퀀스 테이블, 단일 카운터)
- 테이블 스캔 + FOR UPDATE: 인덱스 미스
- 긴 트랜잭션: 조회 후 외부 호출, 파일 IO, 대기
- 배치 업데이트: 너무 큰 단위로 한 번에 변경

핫 로우는 락이 아니라 “구조 변경”이 필요합니다.  
샤딩 카운터, 적재 후 집계, 메시지로 직렬화 같은 형태가 더 현실적입니다.

---

## 분산 락

### 분산 락이 필요한 경우

다음 조건이 동시에 성립할 때만 분산 락을 봅니다.

- 여러 서버가 같은 자원을 수정
- 자원을 한 번에 하나만 처리해야 함
- DB 트랜잭션만으로 해결이 안 됨

예시는 이런 쪽입니다.

- 같은 주문을 두 워커가 동시에 처리할 수 있는 구조
- 스케줄러가 여러 인스턴스에서 동시에 돌 수 있는 구조
- 외부 API가 “동일 키 중복 호출 금지” 제약이 강함

반대로, DB에서 유니크 제약이나 조건부 업데이트로 해결되면 분산 락은 안 쓰는 편이 낫습니다.

---

### Redis 기반 락

가장 흔한 구현은 `SET key value NX PX ttl` 입니다.  
여기서 사고가 많이 납니다.

- TTL이 짧으면 작업 중 락이 풀리고 다른 프로세스가 들어옵니다.
- TTL이 길면 장애 시 자원이 오래 막힙니다.
- 작업 시간이 들쭉날쭉하면 TTL 설정이 애매해집니다.
- GC pause, 이벤트 루프 stall 때문에 갱신이 늦어지는 케이스가 나옵니다.

락 해제는 반드시 “내가 잡은 락만 해제”해야 합니다.  
값 비교 후 삭제가 필요하고, Lua 스크립트로 원자 처리합니다.

Redis 락으로 “정확히 한 번 처리”를 기대하면 사고가 납니다.  
Redis는 분산 합의 시스템이 아닙니다.

운영에서 Redis 락을 쓰면, 실패 시 어떤 상태로 롤백되는지가 먼저 정해져 있어야 합니다.

---

### 펜싱 토큰

Redis 락의 대표적인 구멍은 “락이 만료된 뒤에도 이전 작업이 계속 진행”입니다.  
이 경우 새 작업과 옛 작업이 동시에 DB를 건드릴 수 있습니다.

이 문제를 줄이는 방식이 펜싱 토큰입니다.

- 락을 잡을 때 증가하는 토큰을 함께 받습니다.
- DB 업데이트 시 토큰 조건을 붙입니다.
- 낮은 토큰의 업데이트는 거절됩니다.

이 구조는 “DB가 최종 권위”인 전제가 있어야 성립합니다.

---

### Redlock

Redlock은 여러 Redis 노드에 락을 잡아 쿼럼으로 판단하는 방식으로 소개됩니다.  
현장에서 Redlock로 사고를 막아냈다는 케이스보다, 구성 복잡도만 늘린 케이스를 더 자주 봤습니다.

- 네트워크 분할, 노드 지연 같은 상황에서 판단이 흔들릴 수 있습니다.
- “락을 잡았다고 믿었는데”가 가장 위험합니다.

멀티 노드 Redis 락이 필요할 정도면, 요구사항 자체를 다시 보는 편이 낫습니다.  
DB의 조건부 업데이트, 유니크 제약, 작업 큐 직렬화가 더 단순하게 끝나는 경우가 많습니다.

---

### DB 기반 분산 락

테이블에 유니크 키를 걸고 `INSERT`로 락을 잡는 방식은 단순합니다.

- 단일 DB가 단일 권위
- 트랜잭션으로 정합성 관리가 쉬움
- 장애 시 정리(만료) 로직이 필요

운영에서 자주 놓치는 부분은 “만료”입니다.  
만료 컬럼만 두고 청소 작업이 없으면 락이 영구히 남습니다.

DB 기반 락은 DB 부하를 올릴 수 있습니다.  
핫키 락이 많으면 이 방식도 병목이 됩니다.

---

## 운영에서 자주 터지는 케이스

### 1) 큐 적체가 시작되었는데 소비자는 정상처럼 보이는 경우

원인은 대체로 2가지로 좁혀집니다.

- 외부 의존성 지연: 결제/메일/푸시
- DB 락 대기: 소비자가 DB에서 멈춰 있고, 애플리케이션 로그는 조용함

“소비자 로그가 없다”가 정상은 아닙니다.  
락 대기, 커넥션 대기 상태면 애플리케이션 코드가 실행되지 않습니다.

---

### 2) 중복 메시지로 재고/포인트가 깨지는 경우

중복 처리가 되지 않는 작업은 메시지 큐에서 사고가 납니다.  
소비자 장애, 재시도는 언젠가 발생합니다.

해결은 결국 멱등성입니다.  
멱등성 키를 DB 유니크로 막는 패턴이 가장 단순하게 유지되는 편입니다.

---

### 3) 데드락이 특정 시간대에만 터지는 경우

트래픽이 늘어나면서 “락 획득 순서가 섞이는 요청”이 늘어난 경우가 많습니다.

- 배치 + 실시간 요청이 같은 테이블을 갱신
- 서로 다른 API가 같은 테이블을 다른 순서로 갱신

데드락은 로그만 보고 원인을 단정하기 어렵습니다.  
InnoDB deadlock 로그로 “어떤 인덱스/어떤 레코드”에서 막혔는지 확인해야 합니다.

---

## 관측과 장애 대응

### 메시지 큐 관측 포인트

- 큐 길이(대기 메시지 수)
- oldest message age(가장 오래된 메시지)
- 소비 처리량(초당 처리 건수)
- DLQ 유입률
- 소비자 에러율

큐 길이만 보고 판단하면 늦습니다.  
oldest message age가 증가하는 순간부터 사용자 영향이 시작될 수 있습니다.

---

### DB 락 관측 포인트

- 락 대기 시간 증가
- 데드락 발생 횟수 증가
- 슬로우 쿼리에서 `FOR UPDATE` 등장
- 커넥션 풀 대기 증가

MySQL 기준으로는 아래가 자주 쓰입니다.

```sql
SHOW ENGINE INNODB STATUS;
```

deadlock 로그는 보통 여기에 나옵니다.  
운영 환경에서는 수집 주기와 보관이 필요합니다.

---

### 분산 락 관측 포인트

- 락 획득 실패율
- 락 대기 시간
- TTL 만료로 인한 재진입 징후
- 락 키별 상위 N(핫키)

락 키별 통계를 안 남기면 “왜 느린지”가 안 보입니다.  
특정 상품, 특정 주문, 특정 객실에 경합이 몰리는 케이스가 많습니다.

---

## 테스트

### 메시지 큐

- 소비자 프로세스를 강제로 죽이고 재전달이 발생하는지 확인합니다.
- visibility timeout(또는 ack timeout)을 일부러 짧게 두고 중복이 생기는지 확인합니다.
- DLQ로 보내는 경로가 실제로 동작하는지 확인합니다.
- 스키마 버전이 바뀐 메시지를 흘려서 소비자가 어떻게 반응하는지 확인합니다.

### DB 락

- 동일 자원에 동시 요청을 걸어 락 대기와 처리 지연을 재현합니다.
- 데드락을 의도적으로 만들어 “재시도 로직이 안전한지” 확인합니다.
- 인덱스가 빠진 `FOR UPDATE`가 실제로 어떤 범위를 잠그는지 확인합니다.

### 분산 락

- 작업 시간이 TTL을 넘는 케이스를 일부러 만들고 데이터가 깨지는지 확인합니다.
- 락 획득 실패 시 애플리케이션이 어떤 상태로 종료되는지 확인합니다.
- 락 해제가 누락되었을 때 만료 청소가 복구되는지 확인합니다.

---
