# AWS S3 (Simple Storage Service) 💾

## 📋 개요
Amazon S3는 인터넷을 위한 객체 스토리지 서비스입니다. 쉽게 말해서, 인터넷에 연결된 거대한 하드디스크라고 생각하면 됩니다. 

**객체 스토리지란?**
- 파일을 객체(Object)라는 단위로 저장하는 방식
- 각 파일은 고유한 이름(키)과 메타데이터를 가짐
- 폴더 대신 버킷(Bucket)이라는 컨테이너에 저장

**실제 사용 예시**: Netflix는 S3를 사용하여 전 세계 사용자들에게 영화와 TV 프로그램을 스트리밍합니다. 매일 수백만 건의 요청을 처리하면서도 99.999999999%의 내구성을 유지합니다.

---

## 🔑 핵심 개념

### 객체(Object)와 버킷(Bucket)
**객체(Object)**
- S3에 저장되는 파일의 기본 단위
- 파일 자체 + 메타데이터(파일 정보)로 구성
- 최소 0바이트, 최대 5TB까지 저장 가능

**버킷(Bucket)**
- 객체들을 담는 컨테이너
- 전 세계에서 유일한 이름을 가져야 함
- 리전(지역)을 선택하여 생성

```javascript
// JavaScript로 S3 객체 구조 이해하기
const s3Object = {
  key: "images/profile/2024/user123.jpg",  // 파일 경로 및 이름
  size: 1024,                              // 파일 크기 (바이트)
  lastModified: "2024-03-20T10:00:00Z",    // 마지막 수정 시간
  etag: "d41d8cd98f00b204e9800998ecf8427e", // 파일 고유 식별자
  storageClass: "STANDARD",                // 저장 클래스
  metadata: {                              // 사용자 정의 메타데이터
    contentType: "image/jpeg",
    author: "user123"
  }
};
```

---

## 🛡️ 내구성과 가용성

### 내구성(Durability)
- **99.999999999% (11개의 9)** 내구성
- 1,000,000개의 파일 중 1개만 손실될 확률
- 연간 0.000000001%의 데이터 손실 가능성

### 가용성(Availability)
- **99.99%** 가용성
- 월간 다운타임이 52.56분 이하
- 여러 가용 영역에 자동 복제

**가용 영역(Availability Zone)이란?**
- AWS 데이터센터 내의 격리된 물리적 위치
- 각 리전에는 여러 개의 가용 영역이 존재
- 하나의 가용 영역에 문제가 생겨도 다른 영역에서 서비스 제공

---

## 📦 스토리지 클래스

### S3 Standard
**언제 사용하나요?**
- 자주 접근하는 데이터
- 웹사이트 이미지, 동영상, 문서 등

**특징**
- 가장 높은 가용성과 성능
- 가격: $0.023/GB/월 (us-east-1 기준)

### S3 Intelligent-Tiering
**언제 사용하나요?**
- 접근 패턴이 예측하기 어려운 데이터
- 사용자 업로드 파일, 로그 데이터 등

**특징**
- 자동으로 최적의 스토리지 티어 선택
- 모니터링 비용 없음

### S3 Standard-IA (Infrequent Access)
**언제 사용하나요?**
- 자주 접근하지 않는 데이터
- 백업 파일, 재해 복구 데이터

**특징**
- Standard보다 40% 저렴
- 최소 30일 보관 필요

### S3 One Zone-IA
**언제 사용하나요?**
- 재생성 가능한 데이터
- 보조 백업

**특징**
- 단일 가용 영역에만 저장
- Standard-IA보다 20% 저렴

### S3 Glacier
**언제 사용하나요?**
- 장기 보관이 필요한 데이터
- 규제 준수 데이터, 장기 백업

**특징**
- 검색 시간: 분~시간
- 가격: $0.004/GB/월

### S3 Glacier Deep Archive
**언제 사용하나요?**
- 7년 이상 보관해야 하는 데이터
- 법적 보관 의무 데이터

**특징**
- 가장 저렴한 옵션
- 검색 시간: 12시간
- 가격: $0.00099/GB/월

---

## 🔐 보안 기능

### 서버 측 암호화 (SSE)
**SSE-S3**: AWS가 관리하는 키로 암호화
**SSE-KMS**: AWS KMS(Key Management Service)로 관리하는 키로 암호화
**SSE-C**: 고객이 제공하는 키로 암호화

### 접근 제어
**IAM 정책**: 사용자별 접근 권한 관리
**버킷 정책**: 버킷 레벨의 접근 제어
**ACL**: 객체별 세밀한 접근 제어
**VPC 엔드포인트**: 프라이빗 네트워크에서만 접근
**MFA 삭제**: 다중 인증을 통한 삭제 보호

```javascript
// IAM 정책 예시
const iamPolicy = {
  Version: "2012-10-17",
  Statement: [
    {
      Effect: "Allow",
      Action: [
        "s3:GetObject",    // 파일 읽기
        "s3:PutObject"     // 파일 쓰기
      ],
      Resource: "arn:aws:s3:::my-bucket/*"
    }
  ]
};
```

---

## 📊 데이터 관리

### 수명 주기 정책
파일의 나이에 따라 자동으로 다른 스토리지 클래스로 이동

```javascript
// 수명 주기 정책 예시
const lifecyclePolicy = {
  Rules: [
    {
      ID: "Move to Glacier",
      Status: "Enabled",
      Transitions: [
        {
          Days: 90,                    // 90일 후
          StorageClass: "GLACIER"      // Glacier로 이동
        }
      ]
    }
  ]
};
```

### 버전 관리
- 파일의 모든 버전을 유지
- 실수로 삭제된 파일 복구 가능
- 이전 버전으로 되돌리기 가능

### 크로스 리전 복제
- 다른 리전에 자동 복제
- 지연 시간 최소화
- 규제 준수

---

## 🎯 주요 사용 사례

### 데이터 레이크
대규모 데이터를 저장하고 분석하는 중앙 저장소

```javascript
// AWS SDK for JavaScript v3 사용 예시
import { S3Client, PutObjectCommand } from "@aws-sdk/client-s3";
import { createReadStream } from "fs";

const s3Client = new S3Client({ region: "us-east-1" });

async function uploadToDataLake(filePath, bucketName, key) {
  const fileStream = createReadStream(filePath);
  
  const command = new PutObjectCommand({
    Bucket: bucketName,
    Key: key,
    Body: fileStream,
    Metadata: {
      uploadedBy: "data-pipeline",
      timestamp: new Date().toISOString()
    }
  });
  
  try {
    await s3Client.send(command);
    console.log(`파일 업로드 완료: ${key}`);
  } catch (error) {
    console.error("업로드 실패:", error);
  }
}

// 사용 예시
uploadToDataLake(
  "./data.csv",
  "my-data-lake",
  "raw/2024/03/20/data.csv"
);
```

### 백업 및 복구
- 데이터 백업 자동화
- 재해 복구 솔루션
- 크로스 리전 복제

### 정적 웹사이트 호스팅
HTML, CSS, JavaScript 파일을 직접 호스팅

```javascript
// 정적 웹사이트 설정 예시
const websiteConfiguration = {
  IndexDocument: {
    Suffix: "index.html"    // 기본 페이지
  },
  ErrorDocument: {
    Key: "error.html"       // 에러 페이지
  }
};
```

### 미디어 스토리지
이미지, 비디오, 오디오 파일 저장 및 처리

```javascript
// 이미지 처리 예시
import { S3Client, GetObjectCommand } from "@aws-sdk/client-s3";
import sharp from "sharp";

async function processImage(bucketName, imageKey) {
  const s3Client = new S3Client({ region: "us-east-1" });
  
  // S3에서 이미지 가져오기
  const getCommand = new GetObjectCommand({
    Bucket: bucketName,
    Key: imageKey
  });
  
  const response = await s3Client.send(getCommand);
  const imageBuffer = await response.Body.transformToByteArray();
  
  // 이미지 리사이즈
  const resizedImage = await sharp(imageBuffer)
    .resize(800, 600)
    .jpeg({ quality: 80 })
    .toBuffer();
  
  return resizedImage;
}
```

### 로그 저장
서버 로그, 애플리케이션 로그, 감사 로그 저장

---

## 📝 모범 사례

### 버킷 명명 규칙
- 전역적으로 고유한 이름 사용
- DNS 호환 이름 (소문자, 숫자, 하이픈만)
- 3-63자 길이

```javascript
// 좋은 버킷 이름 예시
const goodBucketNames = [
  "mycompany-prod-logs-2024",
  "user-uploads-dev",
  "backup-data-east1"
];

// 피해야 할 버킷 이름
const badBucketNames = [
  "MyCompany_Logs",     // 대문자, 언더스코어 사용
  "my-bucket",          // 너무 일반적
  "a"                   // 너무 짧음
];
```

### 보안 모범 사례
- 최소 권한 원칙 적용
- 암호화 활성화
- 정기적인 보안 감사

### 비용 최적화
- 적절한 스토리지 클래스 선택
- 수명 주기 정책 설정
- 불필요한 데이터 정리

### 성능 최적화
- 멀티파트 업로드 사용 (대용량 파일)
- 적절한 키 이름 구조 사용
- CloudFront와 함께 사용

```javascript
// 멀티파트 업로드 예시
import { S3Client, CreateMultipartUploadCommand, UploadPartCommand, CompleteMultipartUploadCommand } from "@aws-sdk/client-s3";

async function uploadLargeFile(filePath, bucketName, key) {
  const s3Client = new S3Client({ region: "us-east-1" });
  const fileSize = fs.statSync(filePath).size;
  const partSize = 5 * 1024 * 1024; // 5MB
  
  // 멀티파트 업로드 시작
  const createCommand = new CreateMultipartUploadCommand({
    Bucket: bucketName,
    Key: key
  });
  
  const { UploadId } = await s3Client.send(createCommand);
  
  // 파일을 청크로 나누어 업로드
  const parts = [];
  const fileStream = createReadStream(filePath);
  let partNumber = 1;
  
  for await (const chunk of fileStream) {
    const uploadPartCommand = new UploadPartCommand({
      Bucket: bucketName,
      Key: key,
      UploadId,
      PartNumber: partNumber,
      Body: chunk
    });
    
    const { ETag } = await s3Client.send(uploadPartCommand);
    parts.push({ ETag, PartNumber: partNumber });
    partNumber++;
  }
  
  // 멀티파트 업로드 완료
  const completeCommand = new CompleteMultipartUploadCommand({
    Bucket: bucketName,
    Key: key,
    UploadId,
    MultipartUpload: { Parts: parts }
  });
  
  await s3Client.send(completeCommand);
  console.log("대용량 파일 업로드 완료");
}
```

---

## ⚠️ 제한 사항

| 항목 | 제한 |
|------|------|
| 단일 객체 크기 | 최대 5TB |
| 버킷당 객체 수 | 무제한 |
| 버킷 이름 길이 | 3-63자 |
| 버킷 정책 크기 | 20KB |
| 초당 요청 제한 | 3,500 PUT/COPY/POST/DELETE<br>5,500 GET/HEAD |

---

## 💰 가격 정책

### 스토리지 비용 (us-east-1 기준)
- **Standard**: $0.023/GB/월
- **Standard-IA**: $0.0125/GB/월
- **One Zone-IA**: $0.01/GB/월
- **Glacier**: $0.004/GB/월
- **Glacier Deep Archive**: $0.00099/GB/월

### 요청 비용
- **GET 요청**: $0.0004/1,000건
- **PUT 요청**: $0.005/1,000건
- **DELETE 요청**: 무료

### 데이터 전송 비용
- **인바운드**: 무료
- **아웃바운드**: $0.09/GB (첫 1TB)

---

## 📚 추가 학습 자료

- [AWS S3 공식 문서](https://docs.aws.amazon.com/s3/)
- [AWS S3 개발자 가이드](https://docs.aws.amazon.com/s3/index.html)
- [AWS SDK for JavaScript v3](https://docs.aws.amazon.com/sdk-for-javascript/v3/developer-guide/)

---

## 🎯 결론

AWS S3는 확장 가능하고 안전한 객체 스토리지 서비스입니다. 적절한 설정과 모범 사례를 따르면 비용 효율적이고 안전한 데이터 스토리지 솔루션을 구축할 수 있습니다.

S3를 처음 사용하는 경우, AWS S3 콘솔에서 제공하는 "Getting Started" 가이드를 참고하세요. 또한 AWS S3 문서와 함께 AWS S3 개발자 가이드를 읽어보는 것을 추천합니다.
